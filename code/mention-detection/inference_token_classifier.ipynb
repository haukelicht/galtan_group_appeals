{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "from types import SimpleNamespace\n",
    "\n",
    "args = SimpleNamespace()\n",
    "\n",
    "args.input_file = '../../data/manifestos/all_manifesto_sentences_translated.tsv'\n",
    "args.id_col = 'sentence_id'\n",
    "args.text_col = 'text_mt_m2m_100_1.2b'\n",
    "args.metadata_cols = 'country_iso3c'\n",
    "\n",
    "args.model_path = '../../results/classifiers/group-mention-detection_batch-02/best_model/'\n",
    "args.batch_size = 64\n",
    "\n",
    "args.output_file = '../../data/labeled/manifesto_sentences_predicted_group_mentions.jsonl'\n",
    "args.return_spanlevel = True\n",
    "\n",
    "args.test = False\n",
    "args.verbose = True\n",
    "\n",
    "args.metadata_cols = [c.strip() for c in args.metadata_cols.split(',')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "from utils.io import write_jsonlines\n",
    "\n",
    "import torch\n",
    "from transformers import AutoTokenizer, AutoModelForTokenClassification, pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "processing 436971 sentences\n"
     ]
    }
   ],
   "source": [
    "# read the input file\n",
    "sep = None\n",
    "if args.input_file.endswith('.tsv') or args.input_file.endswith('.tab'):\n",
    "    sep = '\\t'\n",
    "elif args.input_file.endswith('.csv'):\n",
    "    sep = ','\n",
    "else:\n",
    "    raise ValueError('input file must be a tab-separated (.tsv, .tab) or comma-separated (.csv) file')\n",
    "\n",
    "df = pd.read_csv(args.input_file, sep=sep)\n",
    "\n",
    "# remove empty text rows\n",
    "df = df[df[args.text_col].notna()]\n",
    "\n",
    "if args.test:\n",
    "    n_ = args.batch_size*10\n",
    "    if n_ < len(df):\n",
    "        df = df.sample(n=n_, random_state=42)\n",
    "\n",
    "if args.verbose: print(f'processing {len(df)} sentences')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "using device: mps\n"
     ]
    }
   ],
   "source": [
    "device = 'cuda:0' if torch.cuda.is_available() else 'mps' if torch.backends.mps.is_available() else 'cpu'\n",
    "device = torch.device(device)\n",
    "if args.verbose: print('using device:', str(device))\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(args.model_path, use_fast=True, add_prefix_space=True)\n",
    "model = AutoModelForTokenClassification.from_pretrained(args.model_path)\n",
    "\n",
    "# construct the pipeline\n",
    "classifier = pipeline(\n",
    "    task='ner', \n",
    "    model=model, \n",
    "    tokenizer=tokenizer,\n",
    "    aggregation_strategy='simple',\n",
    "    device=device,\n",
    "    batch_size=args.batch_size\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicting labels for 436971 inputs\n"
     ]
    }
   ],
   "source": [
    "if args.verbose: print(f'Predicting labels for {len(df)} inputs')\n",
    "preds = classifier(df[args.text_col].to_list())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "# add predicted spans to the dataframe\n",
    "df['spans'] = [\n",
    "    [\n",
    "        [span['start'], span['end'], span['entity_group']]\n",
    "        for span in spans\n",
    "    ]\n",
    "    for spans in preds \n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing text and predicted labels in JSONL format to ../../data/labeled/manifesto_sentences_predicted_group_mentions.jsonl\n"
     ]
    }
   ],
   "source": [
    "if args.verbose: print(f'Writing text and predicted labels in JSONL format to {args.output_file}')\n",
    "\n",
    "lines = []\n",
    "for _, d in df.iterrows():\n",
    "    out = {\n",
    "        'id': d[args.id_col],\n",
    "        'text': d[args.text_col],\n",
    "        'labels': d['spans'],\n",
    "        'metadata': {c: d[c] for c in args.metadata_cols},\n",
    "    }\n",
    "    lines.append(out)\n",
    "\n",
    "os.makedirs(os.path.dirname(args.output_file), exist_ok=True)\n",
    "write_jsonlines(lines, args.output_file, overwrite=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing span-level predictions in TSV format to ../../data/labeled/manifesto_sentences_predicted_group_mentions_spans.tsv\n"
     ]
    }
   ],
   "source": [
    "# unnesting data frame to span level\n",
    "if args.return_spanlevel:\n",
    "    # get relevant columns\n",
    "    df = df[[args.id_col, args.text_col] + args.metadata_cols + ['spans']]\n",
    "    # get span index (within text unit)\n",
    "    df.loc[:, 'span_nr'] = df.spans.apply(lambda x: list(range(len(x))))\n",
    "    # explode nested list of spans to span level (like tidyr::unnest_longer in R)\n",
    "    df = df.explode(['spans', 'span_nr'])\n",
    "\n",
    "    # drop inputs with no predicted spans\n",
    "    df = df[~df.spans.isna()]\n",
    "\n",
    "    df['span_nr'] = df.span_nr+1\n",
    "    df.rename(columns={args.text_col: 'sentence_text'}, inplace=True)\n",
    "    # get the span label and text (a.k.a 'mention')\n",
    "    df['label'] = df.apply(lambda r: r.spans[2], axis=1)\n",
    "    df['text'] = df.apply(lambda r: r.sentence_text[r.spans[0]:r.spans[1]], axis=1)\n",
    "\n",
    "    # bring the colums in the right order\n",
    "    df = df[args.metadata_cols + [args.id_col, 'sentence_text', 'span_nr', 'label', 'text']]\n",
    "\n",
    "    args.output_file = args.output_file.replace('.jsonl', '_spans.tsv')\n",
    "    if args.verbose: print(f'Writing span-level predictions in TSV format to {args.output_file}')\n",
    "    df.to_csv(args.output_file, sep='\\t', index=False, encoding='utf-8')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "galtan_group_appeals",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
