{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TODOS\n",
    "\n",
    "- [ ] repliate for botg group types\n",
    "- [ ] put stuff in utils\n",
    "- [ ] also tray k-means and select the one with better eval scores\n",
    "- [x] check which embedding model used for relevance ranking => `intfloat/multilingual-e5-large-instruct`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "\n",
    "from dataclasses import dataclass\n",
    "from typing import List, Literal, Union\n",
    "\n",
    "import torch.nn.functional as F\n",
    "\n",
    "import torch\n",
    "from transformers import AutoTokenizer, AutoModel\n",
    "import math\n",
    "\n",
    "from tqdm.auto import tqdm\n",
    "\n",
    "import gc\n",
    "import torch\n",
    "\n",
    "\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "# for topic modeling\n",
    "## dimensionality reduction\n",
    "from umap import UMAP \n",
    "## clustering\n",
    "from sklearn.cluster import KMeans\n",
    "from hdbscan import HDBSCAN \n",
    "## bag-of-words topic representations\n",
    "from nltk.tokenize import word_tokenize\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from bertopic.vectorizers import ClassTfidfTransformer\n",
    "\n",
    "from bertopic import BERTopic # <== topic modeling\n",
    "from bertopic.representation import KeyBERTInspired\n",
    "\n",
    "\n",
    "from datetime import datetime\n",
    "# function to get a timstamp\n",
    "ts = lambda: datetime.now().strftime(\"%Y-%m-%d %H-%M-%S\")\n",
    "log = lambda msg: print(f'[{ts()}] {msg}')\n",
    "\n",
    "\n",
    "from typing import Union, List, Literal, Tuple, Dict\n",
    "from numpy.typing import NDArray\n",
    "\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "from utils.io import read_jsonlines\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_path = os.path.join('..', '..')\n",
    "data_path = os.path.join(base_path, 'data', 'annotations')\n",
    "SEED = 42"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "jobs = [nm for nm in os.listdir(data_path) if nm.startswith('group-mention-annotation-batch-')]\n",
    "\n",
    "fps = [os.path.join(data_path, job, 'review_annotations.jsonl') for job in jobs]\n",
    "\n",
    "parse_entry = lambda x: {k: x[k] for k in ['id', 'text', 'label']}\n",
    "data = [parse_entry(line) for fp in fps for line in read_jsonlines(fp)]\n",
    "\n",
    "def parse_annotation(text, annotation, keep_text: bool):\n",
    "    out = {\n",
    "        'start': annotation[0],\n",
    "        'end': annotation[1],\n",
    "        'type': annotation[2],\n",
    "        'mention': text[annotation[0]:annotation[1]]\n",
    "    }\n",
    "    if keep_text:\n",
    "        out['text'] = text\n",
    "    return out\n",
    "    \n",
    "\n",
    "def unnest_sequence_annotations(data, **kwargs):\n",
    "    return [\n",
    "        {'text_id': line['id'], 'mention_nr': i+1} | parse_annotation(line['text'], lab, **kwargs)\n",
    "        for line in data \n",
    "        for i, lab in enumerate(line['label'])\n",
    "    ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text_id</th>\n",
       "      <th>mention_nr</th>\n",
       "      <th>start</th>\n",
       "      <th>end</th>\n",
       "      <th>type</th>\n",
       "      <th>mention</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>11110_198809-390636</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>12</td>\n",
       "      <td>social group</td>\n",
       "      <td>parents</td>\n",
       "      <td>Give parents the right to become municipal day...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>11110_199109-390960</td>\n",
       "      <td>1</td>\n",
       "      <td>44</td>\n",
       "      <td>51</td>\n",
       "      <td>social group</td>\n",
       "      <td>society</td>\n",
       "      <td>Therefore, we oppose the despolitisation of so...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>11110_199109-390960</td>\n",
       "      <td>2</td>\n",
       "      <td>55</td>\n",
       "      <td>81</td>\n",
       "      <td>organizational group</td>\n",
       "      <td>multinational corporations</td>\n",
       "      <td>Therefore, we oppose the despolitisation of so...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>11110_199109-390960</td>\n",
       "      <td>3</td>\n",
       "      <td>200</td>\n",
       "      <td>238</td>\n",
       "      <td>social group</td>\n",
       "      <td>party leaders or officials in Brussels</td>\n",
       "      <td>Therefore, we oppose the despolitisation of so...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>11110_199109-390940</td>\n",
       "      <td>1</td>\n",
       "      <td>62</td>\n",
       "      <td>113</td>\n",
       "      <td>social group</td>\n",
       "      <td>a society for survival in prosperity and well-...</td>\n",
       "      <td>It is only within the ecological framework tha...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               text_id  mention_nr  start  end                  type  \\\n",
       "0  11110_198809-390636           1      5   12          social group   \n",
       "1  11110_199109-390960           1     44   51          social group   \n",
       "2  11110_199109-390960           2     55   81  organizational group   \n",
       "3  11110_199109-390960           3    200  238          social group   \n",
       "4  11110_199109-390940           1     62  113          social group   \n",
       "\n",
       "                                             mention  \\\n",
       "0                                            parents   \n",
       "1                                            society   \n",
       "2                         multinational corporations   \n",
       "3             party leaders or officials in Brussels   \n",
       "4  a society for survival in prosperity and well-...   \n",
       "\n",
       "                                                text  \n",
       "0  Give parents the right to become municipal day...  \n",
       "1  Therefore, we oppose the despolitisation of so...  \n",
       "2  Therefore, we oppose the despolitisation of so...  \n",
       "3  Therefore, we oppose the despolitisation of so...  \n",
       "4  It is only within the ecological framework tha...  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.DataFrame(unnest_sequence_annotations(data, keep_text=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "examples = df[df.type == 'social group']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_memory(device: Union[str, torch.device]):\n",
    "    gc.collect()\n",
    "    if str(device) == 'cuda':\n",
    "        torch.cuda.empty_cache()\n",
    "    elif str(device) == 'mps':\n",
    "        torch.mps.empty_cache()\n",
    "    else:\n",
    "        pass\n",
    "\n",
    "@dataclass\n",
    "class E5SentenceEmbedder:\n",
    "    model_name: str = 'intfloat/multilingual-e5-base'\n",
    "    device: Literal['cuda', 'mps', 'cpu'] = 'cuda' if torch.cuda.is_available() else 'mps' if torch.backends.mps.is_available() else 'cpu'\n",
    "\n",
    "    def __post_init__(self):\n",
    "        self.tokenizer = AutoTokenizer.from_pretrained(self.model_name)\n",
    "        self.model = AutoModel.from_pretrained(self.model_name)\n",
    "        self.model.to(self.device);\n",
    "\n",
    "    @staticmethod\n",
    "    def _average_pool(last_hidden_states: torch.Tensor, attention_mask: torch.Tensor) -> torch.Tensor:\n",
    "        \"\"\"\n",
    "        Source: https://huggingface.co/intfloat/multilingual-e5-base\n",
    "        \"\"\"\n",
    "        last_hidden = last_hidden_states.masked_fill(~attention_mask[..., None].bool(), 0.0)\n",
    "        return last_hidden.sum(dim=1) / attention_mask.sum(dim=1)[..., None]\n",
    "    \n",
    "    def encode(self, texts: List[str], batch_size: int=16, normalize: bool=True) -> torch.Tensor:\n",
    "        \"\"\"\n",
    "        Source: based on https://huggingface.co/intfloat/multilingual-e5-base\n",
    "        \"\"\"\n",
    "        # Each input text should start with \"passage: \", even for non-English texts.\n",
    "        # For tasks other than retrieval, you can simply use the \"query: \" prefix.\n",
    "        texts = ['query: ' + text if not text.lower().startswith('query: ') else text for text in texts]\n",
    "\n",
    "        embeddings = []\n",
    "        n_ = len(texts)\n",
    "        for i in tqdm(range(0, n_, batch_size), total=math.ceil(n_/batch_size)):\n",
    "            batch_dict = self.tokenizer(texts[i:min(i+batch_size, n_)], max_length=512, padding=True, truncation=True, return_tensors='pt')\n",
    "            with torch.no_grad():\n",
    "                outputs = self.model(**batch_dict.to(self.model.device))\n",
    "            tmp = self._average_pool(outputs.last_hidden_state, batch_dict['attention_mask']).half().cpu()\n",
    "            embeddings.append(tmp)\n",
    "            del tmp\n",
    "            clean_memory(str(self.device))\n",
    "        embeddings = torch.cat(embeddings, dim=0)\n",
    "        \n",
    "        # normalize embeddings\n",
    "        if normalize:\n",
    "            embeddings = F.normalize(embeddings, p=2, dim=1)\n",
    "\n",
    "        return embeddings\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tune_bertopic_model(docs: List[str], embeddings: NDArray, min_cluster_size: int, seed: int=42):\n",
    "\n",
    "    # dimensionality reduction\n",
    "    umap_model = UMAP(\n",
    "        n_neighbors=30, \n",
    "        n_components=50,\n",
    "        min_dist=0.0, \n",
    "        metric='cosine', \n",
    "        random_state=seed\n",
    "    )\n",
    "\n",
    "    # clustering\n",
    "    cluster_model = HDBSCAN(\n",
    "        min_cluster_size=min_cluster_size,\n",
    "        metric='euclidean', # <== default\n",
    "        cluster_selection_method='eom', # <== default\n",
    "        prediction_data=True # <== required (default)\n",
    "    )\n",
    "\n",
    "    # word vectorization\n",
    "    vectorizer_model = CountVectorizer(\n",
    "        max_df=0.85, \n",
    "        min_df=2, \n",
    "        tokenizer=lambda x: word_tokenize(x, language='english'),\n",
    "    )\n",
    "\n",
    "    # topic BoW representation\n",
    "    ctfidf_model = ClassTfidfTransformer(reduce_frequent_words=True)\n",
    "\n",
    "    topic_model = BERTopic(\n",
    "\n",
    "        # components\n",
    "        embedding_model=E5SentenceEmbedder(device='mps'),\n",
    "        umap_model=umap_model,\n",
    "        hdbscan_model=cluster_model,\n",
    "        vectorizer_model=vectorizer_model,\n",
    "        ctfidf_model=ctfidf_model,\n",
    "        representation_model=KeyBERTInspired(top_n_words=10),\n",
    "        \n",
    "        # parameters\n",
    "        nr_topics=None, # <== I've removed this to avoid merging topics after estimation\n",
    "        calculate_probabilities=False, # WARNING: this would slow down BERTopic significantly at large amounts of data (>100_000 documents)\n",
    "        top_n_words=10,\n",
    "\n",
    "        verbose=False\n",
    "    )\n",
    "\n",
    "    np.random.seed(seed) # <== set seed for reproducibility\n",
    "    topics, probs = topic_model.fit_transform(docs, embeddings=embeddings)\n",
    "\n",
    "    return topic_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gensim.corpora as corpora\n",
    "from gensim.models.coherencemodel import CoherenceModel\n",
    "\n",
    "def compute_coherece(\n",
    "        model: BERTopic, \n",
    "        docs: Union[pd.Series, List[str]], \n",
    "        coherence_metric: Literal['u_mass', 'c_v', 'c_uci', 'c_npmi']='c_v',\n",
    "        exclude_outlier_topic: bool=True,\n",
    "    ) -> Tuple[Dict[str, Union[float, Dict[int, float]]], CoherenceModel]:\n",
    "    \"\"\"\n",
    "    Compute coherence scores for a BERTopic model.\n",
    "\n",
    "    Parameters:\n",
    "        model (BERTopic): The BERTopic model.\n",
    "        docs (Union[pd.Series, List[str]]): The documents to compute coherence on.\n",
    "            Must be a pandas Series or a list of strings.\n",
    "        coherence_metric (Literal['u_mass', 'c_v', 'c_uci', 'c_npmi'], optional): The coherence metric to use. \n",
    "            Allowed values are 'u_mass', 'c_v', 'c_uci', 'c_npmi' (see https://radimrehurek.com/gensim/models/coherencemodel.html)\n",
    "            Defaults to 'c_v'.\n",
    "\n",
    "    Returns:\n",
    "        Tuple[Dict[str, Union[float, Dict[int, float]]], CoherenceModel]: \n",
    "           A tuple containing the coherence scores and the coherence model.\n",
    "            - scores (Dict[str, Union[float, Dict[int, float]]]): The coherence scores.\n",
    "                - overall (float): The overall coherence score.\n",
    "                - by_topic (Dict[int, float]): The coherence score for each topic.\n",
    "            - coherence_model (CoherenceModel): The coherence model object.\n",
    "\n",
    "    \"\"\"\n",
    "    topic_words = [\n",
    "        [word for word, _ in words] # for top-n words words in topic\n",
    "        for tid, words in model.topic_representations_.items() # iterate over topics\n",
    "        if (tid > -1 if exclude_outlier_topic else True)\n",
    "    ]\n",
    "\n",
    "    topics = model.topics_\n",
    "    if exclude_outlier_topic:\n",
    "        docs = [doc for doc, tid in zip(docs, topics) if tid > -1]\n",
    "        topics = [tid for tid in topics if tid > -1]\n",
    "\n",
    "    # extract vectorizer and analyzer from BERTopic\n",
    "    vectorizer = model.vectorizer_model\n",
    "    analyzer = vectorizer.build_analyzer()\n",
    "\n",
    "    if isinstance(docs, list):\n",
    "        docs = np.array(docs)\n",
    "    cleaned_docs = model._preprocess_text(docs)\n",
    "    toks = [analyzer(doc) for doc in cleaned_docs]\n",
    "\n",
    "    topics = [tid for tid, toks_ in zip(topics, toks) if len(toks_) > 0]\n",
    "    toks = [t for t in toks if len(t) > 0]\n",
    "\n",
    "    # pre-process documents\n",
    "    documents = pd.DataFrame({\"Document\": toks, \"ID\": range(len(toks)), \"Topic\": topics})\n",
    "    documents_per_topic = documents.groupby(['Topic'], as_index=False).agg({'Document': 'sum'})\n",
    "\n",
    "    # extract features for Topic Coherence evaluation\n",
    "    # words = vectorizer.get_feature_names_out()\n",
    "    tokens = documents_per_topic.Document.to_list()\n",
    "    dictionary = corpora.Dictionary(tokens)\n",
    "    corpus = [dictionary.doc2bow(token) for token in tokens]\n",
    "\n",
    "    # compile coherence model\n",
    "    coherence_model = CoherenceModel(\n",
    "        topics=topic_words, \n",
    "        texts=tokens, \n",
    "        corpus=corpus,\n",
    "        dictionary=dictionary, \n",
    "        coherence=coherence_metric\n",
    "    )\n",
    "\n",
    "    # evaluate coherence\n",
    "    scores = {\n",
    "        'overall': coherence_model.get_coherence(),\n",
    "        'by_topic': {tid: c for tid, c in enumerate(coherence_model.get_coherence_per_topic())}\n",
    "    }\n",
    "    \n",
    "    return scores, coherence_model\n",
    "\n",
    "\n",
    "from sklearn.metrics import (\n",
    "    silhouette_score, # <== compute overall, corpus-level score\n",
    "    silhouette_samples # <== compute sample/document-level scores\n",
    ")\n",
    "\n",
    "def compute_silhouette_scores(model: BERTopic, seed):\n",
    "    overall = silhouette_score(\n",
    "        X=model.umap_model.embedding_, \n",
    "        labels=model.topics_, \n",
    "        sample_size=None, \n",
    "        random_state=seed\n",
    "    )\n",
    "    by_topic = silhouette_samples(X=model.umap_model.embedding_, labels=model.topics_)\n",
    "    by_topic = pd.DataFrame({'topic': model.topics_, 'silhouette_score': by_topic})\n",
    "    by_topic = by_topic.groupby('topic').agg(['mean', 'std'])\n",
    "    # remove stacked columns\n",
    "    by_topic.columns = by_topic.columns.droplevel(0)\n",
    "    by_topic.reset_index(inplace=True)\n",
    "    out = {\n",
    "        'overall': overall,\n",
    "        'by_topic': by_topic\n",
    "    }\n",
    "    return out\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import torch\n",
    "if torch.backends.mps.is_available():\n",
    "    os.environ['TOKENIZERS_PARALLELISM'] = 'false'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2024-09-02 19-33-28] fitting model with min. cluster size = 5\n",
      "[2024-09-02 19-33-51] fitting model with min. cluster size = 8\n",
      "[2024-09-02 19-34-14] fitting model with min. cluster size = 10\n",
      "[2024-09-02 19-34-41] fitting model with min. cluster size = 15\n",
      "[2024-09-02 19-35-10] fitting model with min. cluster size = 30\n",
      "[2024-09-02 19-35-38] fitting model with min. cluster size = 50\n",
      "[2024-09-02 19-36-06] fitting model with min. cluster size = 75\n",
      "[2024-09-02 19-36-32] fitting model with min. cluster size = 100\n"
     ]
    }
   ],
   "source": [
    "embedder = E5SentenceEmbedder(device='mps')\n",
    "embeddings = embedder.encode(examples.mention.to_list(), batch_size=32).numpy()\n",
    "mentions = examples.mention.to_list()\n",
    "\n",
    "min_cluster_sizes = [5, 8, 10, 15, 30, 50, 75, 100]\n",
    "results = {}\n",
    "for mcs in min_cluster_sizes:\n",
    "    log(f'fitting model with min. cluster size = {mcs}')\n",
    "    topic_model = tune_bertopic_model(docs=mentions, embeddings=embeddings, min_cluster_size=mcs)\n",
    "    results[mcs] = {}\n",
    "    results[mcs]['coherence'], _ = compute_coherece(topic_model, mentions)\n",
    "    results[mcs]['silhouette'] = compute_silhouette_scores(topic_model, seed=42)\n",
    "    results[mcs]['n_clusters'] = len(set(topic_model.topics_))\n",
    "    results[mcs]['share_outlier_docs'] = topic_model.get_topic_freq(-1)/len(mentions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_results(res):\n",
    "    out = {\n",
    "        'coherence_overall': res['coherence']['overall'],\n",
    "    }\n",
    "    tmp = np.array(list(res['coherence']['by_topic'].values()))\n",
    "    out['coherence_topic_mean'], out['coherence_topic_std'] = tmp.mean(), tmp.std()\n",
    "\n",
    "    out['silhouette_overall'] = res['silhouette']['overall']\n",
    "    tmp = res['silhouette']['by_topic']\n",
    "    tmp = tmp.loc[tmp.topic != -1, 'mean']\n",
    "    out['silhouette_topic_mean'], out['silhouette_topic_std'] = tmp.mean(), tmp.std()\n",
    "\n",
    "    out['n_clusters'] = res['n_clusters']\n",
    "    out['share_outlier_docs'] = res['share_outlier_docs']\n",
    "\n",
    "    return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>5</th>\n",
       "      <th>8</th>\n",
       "      <th>10</th>\n",
       "      <th>15</th>\n",
       "      <th>30</th>\n",
       "      <th>50</th>\n",
       "      <th>75</th>\n",
       "      <th>100</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>coherence_overall</th>\n",
       "      <td>0.618425</td>\n",
       "      <td>0.603573</td>\n",
       "      <td>0.608943</td>\n",
       "      <td>0.614598</td>\n",
       "      <td>0.548584</td>\n",
       "      <td>0.575422</td>\n",
       "      <td>0.488649</td>\n",
       "      <td>0.463737</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>coherence_topic_mean</th>\n",
       "      <td>0.618425</td>\n",
       "      <td>0.603573</td>\n",
       "      <td>0.608943</td>\n",
       "      <td>0.614598</td>\n",
       "      <td>0.548584</td>\n",
       "      <td>0.575422</td>\n",
       "      <td>0.488649</td>\n",
       "      <td>0.463737</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>coherence_topic_std</th>\n",
       "      <td>0.176533</td>\n",
       "      <td>0.192988</td>\n",
       "      <td>0.181990</td>\n",
       "      <td>0.191670</td>\n",
       "      <td>0.178124</td>\n",
       "      <td>0.142821</td>\n",
       "      <td>0.165014</td>\n",
       "      <td>0.133129</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>silhouette_overall</th>\n",
       "      <td>0.466847</td>\n",
       "      <td>0.471584</td>\n",
       "      <td>0.506012</td>\n",
       "      <td>0.497499</td>\n",
       "      <td>0.382972</td>\n",
       "      <td>0.284968</td>\n",
       "      <td>0.253242</td>\n",
       "      <td>0.176193</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>silhouette_topic_mean</th>\n",
       "      <td>0.727877</td>\n",
       "      <td>0.771430</td>\n",
       "      <td>0.785583</td>\n",
       "      <td>0.799151</td>\n",
       "      <td>0.812837</td>\n",
       "      <td>0.816776</td>\n",
       "      <td>0.848728</td>\n",
       "      <td>0.769265</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>silhouette_topic_std</th>\n",
       "      <td>0.166053</td>\n",
       "      <td>0.159360</td>\n",
       "      <td>0.169240</td>\n",
       "      <td>0.171609</td>\n",
       "      <td>0.178668</td>\n",
       "      <td>0.188743</td>\n",
       "      <td>0.223755</td>\n",
       "      <td>0.228073</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>n_clusters</th>\n",
       "      <td>194.000000</td>\n",
       "      <td>140.000000</td>\n",
       "      <td>109.000000</td>\n",
       "      <td>78.000000</td>\n",
       "      <td>44.000000</td>\n",
       "      <td>27.000000</td>\n",
       "      <td>12.000000</td>\n",
       "      <td>7.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>share_outlier_docs</th>\n",
       "      <td>0.173856</td>\n",
       "      <td>0.189465</td>\n",
       "      <td>0.170171</td>\n",
       "      <td>0.177542</td>\n",
       "      <td>0.234338</td>\n",
       "      <td>0.313028</td>\n",
       "      <td>0.241058</td>\n",
       "      <td>0.337308</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                              5           8           10         15   \\\n",
       "coherence_overall        0.618425    0.603573    0.608943   0.614598   \n",
       "coherence_topic_mean     0.618425    0.603573    0.608943   0.614598   \n",
       "coherence_topic_std      0.176533    0.192988    0.181990   0.191670   \n",
       "silhouette_overall       0.466847    0.471584    0.506012   0.497499   \n",
       "silhouette_topic_mean    0.727877    0.771430    0.785583   0.799151   \n",
       "silhouette_topic_std     0.166053    0.159360    0.169240   0.171609   \n",
       "n_clusters             194.000000  140.000000  109.000000  78.000000   \n",
       "share_outlier_docs       0.173856    0.189465    0.170171   0.177542   \n",
       "\n",
       "                             30         50         75        100  \n",
       "coherence_overall       0.548584   0.575422   0.488649  0.463737  \n",
       "coherence_topic_mean    0.548584   0.575422   0.488649  0.463737  \n",
       "coherence_topic_std     0.178124   0.142821   0.165014  0.133129  \n",
       "silhouette_overall      0.382972   0.284968   0.253242  0.176193  \n",
       "silhouette_topic_mean   0.812837   0.816776   0.848728  0.769265  \n",
       "silhouette_topic_std    0.178668   0.188743   0.223755  0.228073  \n",
       "n_clusters             44.000000  27.000000  12.000000  7.000000  \n",
       "share_outlier_docs      0.234338   0.313028   0.241058  0.337308  "
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame([parse_results(res) for res in results.values()], index=results.keys()).T\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# extract the metrics into a data frame\n",
    "metrics_df = pd.concat(\n",
    "    [\n",
    "        pd.DataFrame(results).T.coherence.apply(lambda d: np.mean(list(d['by_topic'].values()))),\n",
    "        pd.DataFrame(metrics).T.coherence.apply(lambda d: np.std(list(d['by_topic'].values()))),\n",
    "        pd.DataFrame(metrics).T.silhouette.apply(lambda d: d['overall']),\n",
    "        pd.DataFrame(metrics).T.silhouette.apply(lambda d: d['by_topic']['mean'].mean()),\n",
    "        pd.DataFrame(metrics).T.silhouette.apply(lambda d: d['by_topic']['mean'].std()),\n",
    "        pd.DataFrame(metrics).T.imbalance.apply(lambda d: np.mean([v for v in d.values() if v > 0])),\n",
    "        pd.DataFrame(metrics).T.imbalance.apply(lambda d: np.std([v for v in d.values() if v > 0])),\n",
    "        pd.DataFrame(metrics).T.entropy.apply(lambda d: np.mean(list(d.values()))),\n",
    "        pd.DataFrame(metrics).T.entropy.apply(lambda d: np.std(list(d.values()))),\n",
    "        pd.DataFrame(metrics).T.crosslingual_consistency.apply(lambda d: np.mean(list(d['averages'].values()))),\n",
    "        pd.DataFrame(metrics).T.crosslingual_consistency.apply(lambda d: np.std(list(d['averages'].values())))\n",
    "    ],\n",
    "    axis=1,\n",
    "    keys=\n",
    "        ['coherence_mean', 'coherence_std'] + \\\n",
    "        ['silhouette_overall', 'silhouette_mean', 'silhouette_std'] + \\\n",
    "        ['lanuage_imbalance_mean', 'lanuage_imbalance_std'] + \\\n",
    "        ['language_entropy_mean', 'language_entropy_std'] + \\\n",
    "        ['crosslingual_consistency_mean', 'crosslingual_consistency_std']\n",
    ")\n",
    "metrics_df.T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "import warnings\n",
    "def show_examples(topic_id, n = 10):\n",
    "    topic_words = [w for w, _ in topic_model.get_topic(topic_id) if w.strip() != '']\n",
    "    print('Topic words:', *topic_words[:n], sep='\\n  - ')\n",
    "    # for w in topic_words: print(f'  \"{w}\"')\n",
    "    exs = list(set([m.strip().lower() for t, m in zip(topics, examples.mention) if t == topic_id]))\n",
    "    if n > len(exs):\n",
    "        n = len(exs)\n",
    "        warnings.warn('WARNING: fewer unique mentions then selected sample size. setting n='+str(n))\n",
    "    exs = random.Random(42).sample(exs, n)\n",
    "    print()\n",
    "    print('example mentions:', *exs, sep='\\n  - ')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "show_examples(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "show_examples(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "show_examples(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "show_examples(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "show_examples(4)\n",
    "# note: shows need for mutlilabel classification scheme"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "show_examples(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "show_examples(6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "show_examples(7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "show_examples(8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "show_examples(9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "show_examples(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "show_examples(11)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "show_examples(12)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "show_examples(13)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "show_examples(14)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "show_examples(15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "show_examples(16)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "show_examples(17)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "show_examples(98)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "show_examples(8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "topic_model.get_topic_freq()['Count'].plot(kind='hist', figsize=(5, 3))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_, representative_docs, _, repr_doc_ids = \\\n",
    "    topic_model._extract_representative_docs(\n",
    "        c_tf_idf=topic_model.c_tf_idf_,\n",
    "        documents=pd.DataFrame({\n",
    "            'Document': examples.mention.to_list(),\n",
    "            'Topic': topics,\n",
    "            'ID': range(len(topics))\n",
    "        }),\n",
    "        topics=topic_model.topic_representations_,\n",
    "        nr_samples=len(examples),\n",
    "        nr_repr_docs=len(examples),\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "topic_model.representative_docs_[5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "topic_id = 5\n",
    "\n",
    "list(set([examples.mention.to_list()[i].strip().lower() for i in repr_doc_ids[topic_id]]))[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tmp = pd.DataFrame([(tid-1, i, r) for tid, idxs in enumerate(repr_doc_ids) for r, i in enumerate(idxs)])\n",
    "tmp.columns = ['topic', 'idx', 'rank']\n",
    "mentions = examples.mention.str.strip().str.lower().tolist()\n",
    "tmp['mention'] = tmp.idx.apply(lambda i: mentions[i])\n",
    "tmp = tmp.groupby(['topic', 'mention']).agg({'rank': 'median'}).reset_index()\n",
    "tmp['rank'] = tmp['rank'].astype(int)\n",
    "tmp.sort_values(['topic', 'rank'], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "representative_docs = {tid: list(d.mention) for tid, d in tmp.groupby('topic').head(10).groupby('topic').agg({'mention': lambda x: x}).iterrows()}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "coherence_scores, _ = compute_coherece(topic_model, examples.mention, coherence_metric='c_v')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# visualize\n",
    "def plot_topic_coherence_scores(scores, add_overall=True):\n",
    "    coherences_df = pd.DataFrame(\n",
    "        scores['by_topic'].values(), \n",
    "        index=range(len(scores['by_topic'])), \n",
    "        columns=['coherence']\n",
    "    )\n",
    "    # create new plot\n",
    "    plt.figure(figsize=(7, 5))\n",
    "    coherences_df.sort_values(by='coherence', inplace=True)\n",
    "    coherences_df['coherence'].plot(kind='barh')\n",
    "    if add_overall:\n",
    "        # draw a vertical line at the overall coherence score\n",
    "        plt.axvline(scores['overall'], color='red', linestyle='--')\n",
    "    plt.xlim(0, 1)\n",
    "    plt.show()\n",
    "\n",
    "plot_topic_coherence_scores(coherence_scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import (\n",
    "    silhouette_score, # <== compute overall, corpus-level score\n",
    "    silhouette_samples # <== compute sample/document-level scores\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# corpus level\n",
    "overall_silhouette_score = silhouette_score(\n",
    "    X=topic_model.umap_model.embedding_, \n",
    "    labels=topic_model.topics_, \n",
    "    sample_size=None, # <== None means do not subsample observations\n",
    "    random_state=42 # <== only used to make subsampling reproducible (if applied)\n",
    ")\n",
    "overall_silhouette_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "silhouette_scores = silhouette_samples(X=topic_model.umap_model.embedding_, labels=topic_model.topics_)\n",
    "\n",
    "# mean and standard deviation of silhouette scores by topic\n",
    "silhouette_scores_by_topic = pd.DataFrame({'topic': topic_model.topics_, 'silhouette_score': silhouette_scores})\n",
    "silhouette_scores_by_topic = silhouette_scores_by_topic.groupby('topic').agg(['mean', 'std'])\n",
    "# remove stacked columns\n",
    "silhouette_scores_by_topic.columns = silhouette_scores_by_topic.columns.droplevel(0)\n",
    "silhouette_scores_by_topic.reset_index(inplace=True)\n",
    "silhouette_scores_by_topic.sort_values(by='mean', inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "silhouette_scores_by_topic.to_dict(orient='records')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tid = 70\n",
    "print('size:', topic_model.get_topic_freq(tid))\n",
    "print([w for w, s in topic_model.get_topic(tid) if w.strip() != ''])\n",
    "representative_docs[tid]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "\n",
    "# plot a boxplot (along x-axis) by topic (y-axis)\n",
    "plt.figure(figsize=(7, 5))\n",
    "sns.boxplot(x=topic_model.topics_, y=silhouette_scores, fliersize=.2)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "multilingual",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
