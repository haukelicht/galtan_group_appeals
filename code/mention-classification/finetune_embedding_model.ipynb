{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/hlicht/miniforge3/envs/galtan_group_appeals/lib/python3.11/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import random\n",
    "from itertools import product\n",
    "\n",
    "from sklearn.metrics import pairwise_distances\n",
    "from sklearn.model_selection import StratifiedGroupKFold\n",
    "\n",
    "from datasets import Dataset, DatasetDict\n",
    "\n",
    "from sentence_transformers import (\n",
    "    SentenceTransformer, \n",
    "    SentenceTransformerTrainingArguments,\n",
    "    SentenceTransformerTrainer, \n",
    "    losses,\n",
    "    SentenceTransformerModelCardData\n",
    ")\n",
    "from sentence_transformers.evaluation import TripletEvaluator\n",
    "from transformers import EarlyStoppingCallback"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## load and prepare the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_path = '../../data/annotations/group_mention_categorization'\n",
    "fp = os.path.join(data_path, 'consolidated_annotations.tsv')\n",
    "df = pd.read_csv(fp, sep='\\t')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "449"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "attributes = ['universal_attributes', 'non-economic_attributes', 'economic_attributes']\n",
    "df = df[df.q_id.isin(attributes)]\n",
    "df.loc[:, 'attribute'] = df.q_id.str.removesuffix('_attributes')\n",
    "attributes = [a.removesuffix('_attributes') for a in attributes]\n",
    "\n",
    "texts_df = df[['mention_id', 'text', 'mention']].drop_duplicates()\n",
    "len(texts_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.loc[df['category'].isna(), 'category'] = ''\n",
    "df['attribute_combination'] = df['attribute'] + \": \" + df['category']\n",
    "\n",
    "# pivoting the DataFrame\n",
    "df_wide = df.pivot_table(index=['mention_id', 'mention'], columns='attribute_combination', values='label', aggfunc='first').reset_index()\n",
    "df_wide.columns.name = None\n",
    "df_wide.fillna('No', inplace=True)\n",
    "\n",
    "cols = df_wide.columns[2:].to_list()\n",
    "\n",
    "df_wide.loc[:, cols] = df_wide[cols].map(lambda x: 1 if x == 'Yes' else 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "labels\n",
       "(universal,)                                                                                                             55\n",
       "(economic: occupation/profession,)                                                                                       54\n",
       "(non-economic: shared values/mentalities,)                                                                               41\n",
       "(non-economic: nationality,)                                                                                             37\n",
       "(non-economic: age,)                                                                                                     30\n",
       "(economic: income/wealth/economic status,)                                                                               28\n",
       "(economic: employment status,)                                                                                           18\n",
       "(non-economic: age, non-economic: family)                                                                                13\n",
       "(non-economic: family,)                                                                                                  12\n",
       "(non-economic: health,)                                                                                                   9\n",
       "(economic: class membership,)                                                                                             8\n",
       "(non-economic: crime,)                                                                                                    8\n",
       "(economic: education level,)                                                                                              7\n",
       "(economic: ecology of group,)                                                                                             7\n",
       "(economic: class membership, economic: employment status)                                                                 6\n",
       "(non-economic: place/location,)                                                                                           6\n",
       "(non-economic: gender/sexuality,)                                                                                         6\n",
       "(economic: ecology of group, non-economic: shared values/mentalities)                                                     5\n",
       "(non-economic: nationality, non-economic: shared values/mentalities)                                                      4\n",
       "(economic: employment status, non-economic: nationality)                                                                  4\n",
       "(economic: occupation/profession, non-economic: health)                                                                   4\n",
       "(economic: occupation/profession, non-economic: nationality)                                                              4\n",
       "(economic: class membership, economic: employment status, economic: occupation/profession)                                4\n",
       "(non-economic: other,)                                                                                                    3\n",
       "(economic: education level, non-economic: age, non-economic: family)                                                      3\n",
       "(economic: ecology of group, economic: occupation/profession)                                                             3\n",
       "(economic: class membership, economic: income/wealth/economic status)                                                     3\n",
       "(economic: employment status, economic: occupation/profession, non-economic: ethnicity)                                   2\n",
       "(non-economic: age, non-economic: nationality)                                                                            2\n",
       "(economic: income/wealth/economic status, non-economic: age)                                                              2\n",
       "(economic: class membership, non-economic: shared values/mentalities)                                                     2\n",
       "(economic: income/wealth/economic status, non-economic: age, non-economic: family)                                        2\n",
       "(economic: employment status, non-economic: age, non-economic: family, non-economic: shared values/mentalities)           2\n",
       "(non-economic: nationality, non-economic: place/location)                                                                 2\n",
       "(non-economic: ethnicity,)                                                                                                2\n",
       "(non-economic: age, non-economic: family, non-economic: shared values/mentalities)                                        2\n",
       "(economic: class membership, economic: employment status, non-economic: nationality)                                      2\n",
       "(non-economic: age, non-economic: crime)                                                                                  2\n",
       "(economic: education level, non-economic: age, non-economic: shared values/mentalities)                                   2\n",
       "(economic: occupation/profession, non-economic: shared values/mentalities)                                                2\n",
       "()                                                                                                                        2\n",
       "(economic: income/wealth/economic status, non-economic: family)                                                           2\n",
       "(non-economic: ethnicity, non-economic: nationality, non-economic: religion, non-economic: shared values/mentalities)     2\n",
       "(economic: occupation/profession, non-economic: gender/sexuality)                                                         2\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_wide['labels'] = df_wide[cols].apply(lambda r: tuple([c[:-2] if c.endswith(': ') else c for c in cols if r[c]==1]), axis=1)\n",
    "cnts = df_wide['labels'].value_counts()\n",
    "cnts[cnts>1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## construct contastive triplets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "471020"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# use Jaccard distance to compute similarity between rows' label vectors\n",
    "sims = pairwise_distances(df_wide[cols].values.astype(bool), metric='jaccard')\n",
    "\n",
    "# gather triplets\n",
    "triplets = []\n",
    "for i, row in enumerate(sims):\n",
    "\n",
    "    mention = df_wide.mention.iloc[i]\n",
    "    label = df_wide.labels.iloc[i]\n",
    "    # labels = df_wide[cols].iloc[i].values\n",
    "\n",
    "    # get positives\n",
    "    positive_idxs = np.where(row==0.0)[0].tolist() # get hard positives (all labels in common)\n",
    "    positive_idxs.remove(i) # remove self\n",
    "    if len(positive_idxs) == 0:\n",
    "        continue\n",
    "    positives = df_wide.iloc[positive_idxs, 1] # get mentions\n",
    "    positives = positives[positives!=mention] # note: remove duplicates\n",
    "    positives = positives.to_list()\n",
    "\n",
    "    # get negatives\n",
    "    negative_idxs = np.where(row==1.0)[0].tolist() # get hard negatives (no labels in common)\n",
    "    negatives = df_wide.iloc[negative_idxs, 1] # get mentions\n",
    "    negatives = negatives[negatives!=mention] # note: remove duplicates (unlikely but as a sanity check)\n",
    "    negatives = negatives.to_list()\n",
    "\n",
    "    # balance proportions\n",
    "    negatives = random.Random(42).sample(negatives, len(positives))\n",
    "\n",
    "    triplets.extend([(mention, p, n, label) for p, n in product(positives, negatives, repeat=1)])\n",
    "\n",
    "len(triplets)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## split into train, dev, and test folds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/hlicht/miniforge3/envs/galtan_group_appeals/lib/python3.11/site-packages/sklearn/model_selection/_split.py:950: UserWarning: The least populated class in y has only 2 members, which is less than n_splits=10.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "sgk_folder = StratifiedGroupKFold(n_splits=10, shuffle=True, random_state=42)\n",
    "\n",
    "anchors = list(map(lambda x: x[0], triplets))\n",
    "labels = list(map(lambda x: x[-1], triplets))\n",
    "label_strs = list(map(lambda labs: '; '.join(list(labs)), labels))\n",
    "idxs = [idxs for _, idxs in sgk_folder.split(triplets, label_strs, groups=anchors)]\n",
    "# NOTE: the warning is expected because some label combinations are unique to single mentions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "features = ['anchors', 'positives', 'negatives', 'labels']\n",
    "df_train = pd.DataFrame([triplets[i] for tmp in idxs[2:] for i in tmp], columns=features)\n",
    "df_test = pd.DataFrame([triplets[i] for i in idxs[0]], columns=features)\n",
    "df_dev = pd.DataFrame([triplets[i] for i in idxs[1]], columns=features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/_c/cm0nk6y92rz2l6ct3npgw9tr0000gn/T/ipykernel_35876/1740564962.py:8: DeprecationWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  df_train = df_train.groupby('r_').apply(lambda x: x.sample(frac=1, random_state=42)).reset_index(drop=True)\n"
     ]
    }
   ],
   "source": [
    "# NOTE: to ensure that the model sees diverse examples, we shuffle the data in a way that prioritizes diversity\n",
    "\n",
    "# within groups defined by 'labels' column, create row_number indicator (which comes first is random due to prior shuffling)\n",
    "df_train['r_'] = df_train.groupby('labels').cumcount()\n",
    "# now make all first ccourences of a label combination first ...\n",
    "df_train.sort_values(['r_'], inplace=True)\n",
    "# ... and only shuffle within\n",
    "df_train = df_train.groupby('r_').apply(lambda x: x.sample(frac=1, random_state=42)).reset_index(drop=True)\n",
    "\n",
    "# same for dev\n",
    "df_dev['r_'] = df_dev.groupby('labels').cumcount()\n",
    "df_dev = df_dev.sort_values(['r_']).reset_index(drop=True)\n",
    "\n",
    "# same for test\n",
    "df_test['r_'] = df_test.groupby('labels').cumcount()\n",
    "df_test = df_test.sort_values(['r_']).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>r_</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>labels</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>(economic: occupation/profession,)</th>\n",
       "      <td>120156</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>(universal,)</th>\n",
       "      <td>103101</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>(non-economic: shared values/mentalities,)</th>\n",
       "      <td>52799</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>(non-economic: nationality,)</th>\n",
       "      <td>31973</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>(non-economic: age,)</th>\n",
       "      <td>19140</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>(economic: income/wealth/economic status,)</th>\n",
       "      <td>16766</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>(economic: employment status,)</th>\n",
       "      <td>3498</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>(non-economic: family,)</th>\n",
       "      <td>1004</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>(non-economic: age, non-economic: family)</th>\n",
       "      <td>817</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>(non-economic: health,)</th>\n",
       "      <td>545</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>(economic: class membership,)</th>\n",
       "      <td>259</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>(economic: ecology of group,)</th>\n",
       "      <td>229</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>(non-economic: crime,)</th>\n",
       "      <td>195</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>(economic: education level,)</th>\n",
       "      <td>179</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>(non-economic: place/location,)</th>\n",
       "      <td>124</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>(non-economic: gender/sexuality,)</th>\n",
       "      <td>99</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>(economic: ecology of group, non-economic: shared values/mentalities)</th>\n",
       "      <td>65</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>(non-economic: nationality, non-economic: shared values/mentalities)</th>\n",
       "      <td>35</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>(economic: occupation/profession, non-economic: nationality)</th>\n",
       "      <td>35</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>(economic: class membership, economic: employment status)</th>\n",
       "      <td>29</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>(economic: occupation/profession, non-economic: health)</th>\n",
       "      <td>26</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>(economic: employment status, non-economic: nationality)</th>\n",
       "      <td>26</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>(economic: class membership, economic: employment status, economic: occupation/profession)</th>\n",
       "      <td>17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>(non-economic: other,)</th>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>(economic: class membership, economic: income/wealth/economic status)</th>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>(economic: ecology of group, economic: occupation/profession)</th>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>(economic: education level, non-economic: age, non-economic: family)</th>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>()</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>(non-economic: nationality, non-economic: place/location)</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>(economic: income/wealth/economic status, non-economic: age, non-economic: family)</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>(non-economic: age, non-economic: crime)</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>(economic: class membership, economic: employment status, non-economic: nationality)</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>(non-economic: age, non-economic: family, non-economic: shared values/mentalities)</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>(non-economic: age, non-economic: nationality)</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>(non-economic: ethnicity,)</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>(economic: education level, non-economic: age, non-economic: shared values/mentalities)</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>(economic: occupation/profession, non-economic: gender/sexuality)</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>(economic: employment status, non-economic: age, non-economic: family, non-economic: shared values/mentalities)</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>(economic: income/wealth/economic status, non-economic: family)</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>(economic: income/wealth/economic status, non-economic: age)</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>(economic: occupation/profession, non-economic: shared values/mentalities)</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>(non-economic: ethnicity, non-economic: nationality, non-economic: religion, non-economic: shared values/mentalities)</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                        r_\n",
       "labels                                                    \n",
       "(economic: occupation/profession,)                  120156\n",
       "(universal,)                                        103101\n",
       "(non-economic: shared values/mentalities,)           52799\n",
       "(non-economic: nationality,)                         31973\n",
       "(non-economic: age,)                                 19140\n",
       "(economic: income/wealth/economic status,)           16766\n",
       "(economic: employment status,)                        3498\n",
       "(non-economic: family,)                               1004\n",
       "(non-economic: age, non-economic: family)              817\n",
       "(non-economic: health,)                                545\n",
       "(economic: class membership,)                          259\n",
       "(economic: ecology of group,)                          229\n",
       "(non-economic: crime,)                                 195\n",
       "(economic: education level,)                           179\n",
       "(non-economic: place/location,)                        124\n",
       "(non-economic: gender/sexuality,)                       99\n",
       "(economic: ecology of group, non-economic: shar...      65\n",
       "(non-economic: nationality, non-economic: share...      35\n",
       "(economic: occupation/profession, non-economic:...      35\n",
       "(economic: class membership, economic: employme...      29\n",
       "(economic: occupation/profession, non-economic:...      26\n",
       "(economic: employment status, non-economic: nat...      26\n",
       "(economic: class membership, economic: employme...      17\n",
       "(non-economic: other,)                                  11\n",
       "(economic: class membership, economic: income/w...      11\n",
       "(economic: ecology of group, economic: occupati...      11\n",
       "(economic: education level, non-economic: age, ...       3\n",
       "()                                                       1\n",
       "(non-economic: nationality, non-economic: place...       1\n",
       "(economic: income/wealth/economic status, non-e...       1\n",
       "(non-economic: age, non-economic: crime)                 1\n",
       "(economic: class membership, economic: employme...       1\n",
       "(non-economic: age, non-economic: family, non-e...       1\n",
       "(non-economic: age, non-economic: nationality)           1\n",
       "(non-economic: ethnicity,)                               1\n",
       "(economic: education level, non-economic: age, ...       1\n",
       "(economic: occupation/profession, non-economic:...       0\n",
       "(economic: employment status, non-economic: age...       0\n",
       "(economic: income/wealth/economic status, non-e...       0\n",
       "(economic: income/wealth/economic status, non-e...       0\n",
       "(economic: occupation/profession, non-economic:...       0\n",
       "(non-economic: ethnicity, non-economic: nationa...       0"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train.groupby('labels').agg({'r_': 'max'}).sort_values('r_', ascending=False)\n",
    "# NOTE: we could consider balancing here, but due to the sorting of data and efficiency of contrastive learning, early stopping will avoid overfitting to overrepresented label combinations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## prepare training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = DatasetDict({\n",
    "    'train': Dataset.from_pandas(df_train),\n",
    "    'dev': Dataset.from_pandas(df_dev),\n",
    "    'test': Dataset.from_pandas(df_test),\n",
    "})\n",
    "dataset = dataset.remove_columns(['labels', 'r_'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # DEPRECATED (yields not efficiency gain)\n",
    "# from sentence_transformers.similarity_functions import SimilarityFunction\n",
    "# from contextlib import nullcontext\n",
    "# from sklearn.metrics.pairwise import paired_cosine_distances\n",
    "# import csv\n",
    "\n",
    "# import logging\n",
    "# logger = logging.getLogger(__name__)\n",
    "\n",
    "# class CustomTripletEvaluator(TripletEvaluator):\n",
    "#     \"\"\"\n",
    "#     Evaluate a model based on a triplet: (sentence, positive_example, negative_example).\n",
    "#     Checks if distance(sentence, positive_example) < distance(sentence, negative_example).\n",
    "\n",
    "#     Example:\n",
    "#         ::\n",
    "\n",
    "#             from sentence_transformers import SentenceTransformer\n",
    "#             from sentence_transformers.evaluation import TripletEvaluator\n",
    "#             from datasets import load_dataset\n",
    "\n",
    "#             # Load a model\n",
    "#             model = SentenceTransformer('all-mpnet-base-v2')\n",
    "\n",
    "#             # Load a dataset with (anchor, positive, negative) triplets\n",
    "#             dataset = load_dataset(\"sentence-transformers/all-nli\", \"triplet\", split=\"dev\")\n",
    "\n",
    "#             # Initialize the TripletEvaluator using anchors, positives, and negatives\n",
    "#             triplet_evaluator = TripletEvaluator(\n",
    "#                 anchors=dataset[:1000][\"anchor\"],\n",
    "#                 positives=dataset[:1000][\"positive\"],\n",
    "#                 negatives=dataset[:1000][\"negative\"],\n",
    "#                 name=\"all-nli-dev\",\n",
    "#             )\n",
    "#             results = triplet_evaluator(model)\n",
    "#             '''\n",
    "#             TripletEvaluator: Evaluating the model on the all-nli-dev dataset:\n",
    "#             Accuracy Cosine Distance:        95.60\n",
    "#             '''\n",
    "#             print(triplet_evaluator.primary_metric)\n",
    "#             # => \"all-nli-dev_max_accuracy\"\n",
    "#             print(results[triplet_evaluator.primary_metric])\n",
    "#             # => 0.956\n",
    "#     \"\"\"\n",
    "\n",
    "#     def __init__(\n",
    "#         self,\n",
    "#         **kwargs,\n",
    "#     ):\n",
    "#         \"\"\"\n",
    "#         Initializes a TripletEvaluator object.\n",
    "\n",
    "#         Args:\n",
    "#             anchors (List[str]): Sentences to check similarity to. (e.g. a query)\n",
    "#             positives (List[str]): List of positive sentences\n",
    "#             negatives (List[str]): List of negative sentences\n",
    "#             main_distance_function (Union[str, SimilarityFunction], optional):\n",
    "#                 The distance function to use. If not specified, use cosine similarity,\n",
    "#                 dot product, Euclidean, and Manhattan. Defaults to None.\n",
    "#             name (str): Name for the output. Defaults to \"\".\n",
    "#             batch_size (int): Batch size used to compute embeddings. Defaults to 16.\n",
    "#             show_progress_bar (bool): If true, prints a progress bar. Defaults to False.\n",
    "#             write_csv (bool): Write results to a CSV file. Defaults to True.\n",
    "#             truncate_dim (int, optional): The dimension to truncate sentence embeddings to.\n",
    "#                 `None` uses the model's current truncation dimension. Defaults to None.\n",
    "#         \"\"\"\n",
    "#         if kwargs['main_distance_function'] is None:\n",
    "#             kwargs['main_distance_function'] = 'cosine'\n",
    "#         elif kwargs['main_distance_function'] != 'cosine':\n",
    "#             raise NotImplementedError(\"Only cosine similarity is supported at the moment.\")\n",
    "#         super().__init__(**kwargs)\n",
    "#         self.csv_headers = [\"epoch\", \"steps\", \"accuracy_cosinus\"]\n",
    "        \n",
    "#     def __call__(\n",
    "#         self, model: SentenceTransformer, output_path: str = None, epoch: int = -1, steps: int = -1\n",
    "#     ) -> dict[str, float]:\n",
    "#         if epoch != -1:\n",
    "#             if steps == -1:\n",
    "#                 out_txt = f\" after epoch {epoch}\"\n",
    "#             else:\n",
    "#                 out_txt = f\" in epoch {epoch} after {steps} steps\"\n",
    "#         else:\n",
    "#             out_txt = \"\"\n",
    "#         if self.truncate_dim is not None:\n",
    "#             out_txt += f\" (truncated to {self.truncate_dim})\"\n",
    "\n",
    "#         logger.info(f\"TripletEvaluator: Evaluating the model on the {self.name} dataset{out_txt}:\")\n",
    "\n",
    "#         num_triplets, num_correct_cos_triplets = 0, 0 \n",
    "\n",
    "#         with nullcontext() if self.truncate_dim is None else model.truncate_sentence_embeddings(self.truncate_dim):\n",
    "#             embeddings_anchors = model.encode(\n",
    "#                 self.anchors,\n",
    "#                 batch_size=self.batch_size,\n",
    "#                 show_progress_bar=self.show_progress_bar,\n",
    "#                 convert_to_numpy=True,\n",
    "#             )\n",
    "#             embeddings_positives = model.encode(\n",
    "#                 self.positives,\n",
    "#                 batch_size=self.batch_size,\n",
    "#                 show_progress_bar=self.show_progress_bar,\n",
    "#                 convert_to_numpy=True,\n",
    "#             )\n",
    "#             embeddings_negatives = model.encode(\n",
    "#                 self.negatives,\n",
    "#                 batch_size=self.batch_size,\n",
    "#                 show_progress_bar=self.show_progress_bar,\n",
    "#                 convert_to_numpy=True,\n",
    "#             )\n",
    "\n",
    "#         # Cosine distance\n",
    "#         pos_cos_distance = paired_cosine_distances(embeddings_anchors, embeddings_positives)\n",
    "#         neg_cos_distances = paired_cosine_distances(embeddings_anchors, embeddings_negatives)\n",
    "\n",
    "#         for idx in range(len(pos_cos_distance)):\n",
    "#             num_triplets += 1\n",
    "\n",
    "#             if pos_cos_distance[idx] < neg_cos_distances[idx]:\n",
    "#                 num_correct_cos_triplets += 1\n",
    "\n",
    "#         accuracy_cos = num_correct_cos_triplets / num_triplets\n",
    "\n",
    "#         logger.info(f\"Accuracy Cosine Distance: \\t{accuracy_cos * 100:.2f}\")\n",
    "\n",
    "#         if output_path is not None and self.write_csv:\n",
    "#             csv_path = os.path.join(output_path, self.csv_file)\n",
    "#             if not os.path.isfile(csv_path):\n",
    "#                 with open(csv_path, newline=\"\", mode=\"w\", encoding=\"utf-8\") as f:\n",
    "#                     writer = csv.writer(f)\n",
    "#                     writer.writerow(self.csv_headers)\n",
    "#                     writer.writerow([epoch, steps, accuracy_cos])\n",
    "\n",
    "#             else:\n",
    "#                 with open(csv_path, newline=\"\", mode=\"a\", encoding=\"utf-8\") as f:\n",
    "#                     writer = csv.writer(f)\n",
    "#                     writer.writerow([epoch, steps, accuracy_cos])\n",
    "\n",
    "#         self.primary_metric = \"cosine_accuracy\"\n",
    "#         metrics = {\"cosine_accuracy\": accuracy_cos}\n",
    "#         metrics = self.prefix_name_to_metrics(metrics, self.name)\n",
    "#         self.store_metrics_in_model_card_data(model, metrics)\n",
    "#         return metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# source checkpoint\n",
    "model_id = \"sentence-transformers/paraphrase-mpnet-base-v2\"\n",
    "model = SentenceTransformer(model_id, device='mps')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "# trained model \n",
    "model_path = '../../models'\n",
    "run_id = 'paraphrase-mpnet-base-v2-social-group-mention-attributes-embedding'\n",
    "model_dir = os.path.join(model_path, run_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/hlicht/miniforge3/envs/galtan_group_appeals/lib/python3.11/site-packages/transformers/training_args.py:2199: UserWarning: `use_mps_device` is deprecated and will be removed in version 5.0 of 🤗 Transformers. `mps` device will be used by default if available similar to the way `cuda` device is used.Therefore, no action from user is required. \n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "steps_ = 100\n",
    "training_args = SentenceTransformerTrainingArguments(\n",
    "    # required\n",
    "    output_dir=model_dir,\n",
    "    # hyper parameters:\n",
    "    num_train_epochs=1,\n",
    "    per_device_train_batch_size=64,\n",
    "    per_device_eval_batch_size=64,\n",
    "    learning_rate=2e-5,\n",
    "    warmup_ratio=0.1,\n",
    "    use_mps_device=True,\n",
    "    # evaluation logging\n",
    "    logging_steps=steps_,\n",
    "    eval_strategy=\"steps\",\n",
    "    eval_steps=steps_,\n",
    "    eval_on_start=True,\n",
    "    # for early stopping\n",
    "    load_best_model_at_end=True,\n",
    "    metric_for_best_model=\"cosine_accuracy\",\n",
    "    greater_is_better=True,\n",
    "    save_strategy=\"steps\",\n",
    "    save_steps=steps_,\n",
    "    save_total_limit=2,\n",
    "    report_to=\"none\",\n",
    "    # reproducibility\n",
    "    seed=42,\n",
    "    data_seed=42,\n",
    "    full_determinism=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# NOTE: evaluation is time consuming so we only take first 10K examples\n",
    "dev_evaluator = TripletEvaluator(\n",
    "    **dataset['dev'].select(range(10_000)).to_dict(),\n",
    "    main_distance_function='cosine',\n",
    "    batch_size=64,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## fine-tune"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sentence_transformers.sampler import BatchSampler, DefaultBatchSampler\n",
    "from torch.utils.data import SequentialSampler\n",
    "\n",
    "# NOTE: we need to subclass the trainer to avoid shuffling of the training data before each epoch\n",
    "#       (we already randomly ordered with a priority for diversity above)\n",
    "class NoShufflingTrainer(SentenceTransformerTrainer):\n",
    "    def get_batch_sampler(\n",
    "            self,\n",
    "            dataset: Dataset,\n",
    "            batch_size: int,\n",
    "            drop_last: bool,\n",
    "            **kwargs,\n",
    "        ) -> BatchSampler | None:\n",
    "            return DefaultBatchSampler(\n",
    "                SequentialSampler(range(len(dataset))), # overwrite `SubsetRandomSampler(range(len(dataset)), generator=generator)`\n",
    "                batch_size=batch_size,\n",
    "                drop_last=drop_last,\n",
    "            )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer = NoShufflingTrainer(\n",
    "    model=model,\n",
    "    loss=losses.TripletLoss,\n",
    "    args=training_args,\n",
    "    train_dataset=dataset['train'],\n",
    "    evaluator=dev_evaluator,\n",
    "    callbacks=[\n",
    "        EarlyStoppingCallback(early_stopping_patience=3, early_stopping_threshold=0.01),\n",
    "    ],\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/5488 [00:23<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_cosine_accuracy': 0.7036, 'eval_dot_accuracy': 0.3047, 'eval_manhattan_accuracy': 0.711, 'eval_euclidean_accuracy': 0.7073, 'eval_max_accuracy': 0.711, 'eval_runtime': 23.6101, 'eval_samples_per_second': 0.0, 'eval_steps_per_second': 0.0, 'epoch': 0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  2%|▏         | 100/5488 [02:06<1:23:09,  1.08it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 4.3505, 'grad_norm': 5.524215221405029, 'learning_rate': 3.642987249544627e-06, 'epoch': 0.02}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  2%|▏         | 100/5488 [02:27<1:23:09,  1.08it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_cosine_accuracy': 0.8194, 'eval_dot_accuracy': 0.1877, 'eval_manhattan_accuracy': 0.8224, 'eval_euclidean_accuracy': 0.8234, 'eval_max_accuracy': 0.8234, 'eval_runtime': 21.2983, 'eval_samples_per_second': 0.0, 'eval_steps_per_second': 0.0, 'epoch': 0.02}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  4%|▎         | 200/5488 [04:07<1:23:10,  1.06it/s] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 3.1213, 'grad_norm': 10.639139175415039, 'learning_rate': 7.285974499089254e-06, 'epoch': 0.04}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  4%|▎         | 200/5488 [04:29<1:23:10,  1.06it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_cosine_accuracy': 0.9528, 'eval_dot_accuracy': 0.0499, 'eval_manhattan_accuracy': 0.9529, 'eval_euclidean_accuracy': 0.9523, 'eval_max_accuracy': 0.9529, 'eval_runtime': 22.0717, 'eval_samples_per_second': 0.0, 'eval_steps_per_second': 0.0, 'epoch': 0.04}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  5%|▌         | 300/5488 [05:54<1:11:35,  1.21it/s] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 1.3908, 'grad_norm': 20.23415756225586, 'learning_rate': 1.0928961748633882e-05, 'epoch': 0.05}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  5%|▌         | 300/5488 [06:16<1:11:35,  1.21it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_cosine_accuracy': 0.9581, 'eval_dot_accuracy': 0.0462, 'eval_manhattan_accuracy': 0.9592, 'eval_euclidean_accuracy': 0.9582, 'eval_max_accuracy': 0.9592, 'eval_runtime': 22.2712, 'eval_samples_per_second': 0.0, 'eval_steps_per_second': 0.0, 'epoch': 0.05}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  7%|▋         | 400/5488 [07:41<1:10:24,  1.20it/s] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.8727, 'grad_norm': 13.966049194335938, 'learning_rate': 1.4571948998178507e-05, 'epoch': 0.07}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  7%|▋         | 400/5488 [08:03<1:10:24,  1.20it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_cosine_accuracy': 0.9749, 'eval_dot_accuracy': 0.0314, 'eval_manhattan_accuracy': 0.9789, 'eval_euclidean_accuracy': 0.9749, 'eval_max_accuracy': 0.9789, 'eval_runtime': 21.9051, 'eval_samples_per_second': 0.0, 'eval_steps_per_second': 0.0, 'epoch': 0.07}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  9%|▉         | 500/5488 [09:49<1:27:44,  1.06s/it] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.3826, 'grad_norm': 4.889810562133789, 'learning_rate': 1.8214936247723133e-05, 'epoch': 0.09}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  9%|▉         | 500/5488 [10:11<1:27:44,  1.06s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_cosine_accuracy': 0.9889, 'eval_dot_accuracy': 0.0116, 'eval_manhattan_accuracy': 0.989, 'eval_euclidean_accuracy': 0.988, 'eval_max_accuracy': 0.989, 'eval_runtime': 21.6023, 'eval_samples_per_second': 0.0, 'eval_steps_per_second': 0.0, 'epoch': 0.09}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 11%|█         | 600/5488 [11:53<1:06:43,  1.22it/s] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.0989, 'grad_norm': 0.4789236783981323, 'learning_rate': 1.979348046163191e-05, 'epoch': 0.11}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 11%|█         | 600/5488 [12:15<1:06:43,  1.22it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_cosine_accuracy': 0.992, 'eval_dot_accuracy': 0.0092, 'eval_manhattan_accuracy': 0.9746, 'eval_euclidean_accuracy': 0.9907, 'eval_max_accuracy': 0.992, 'eval_runtime': 22.2271, 'eval_samples_per_second': 0.0, 'eval_steps_per_second': 0.0, 'epoch': 0.11}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 13%|█▎        | 700/5488 [13:51<1:13:16,  1.09it/s] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.0747, 'grad_norm': 2.7142200469970703, 'learning_rate': 1.938854019032193e-05, 'epoch': 0.13}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 13%|█▎        | 700/5488 [14:12<1:13:16,  1.09it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_cosine_accuracy': 0.9903, 'eval_dot_accuracy': 0.0105, 'eval_manhattan_accuracy': 0.9831, 'eval_euclidean_accuracy': 0.9904, 'eval_max_accuracy': 0.9904, 'eval_runtime': 21.796, 'eval_samples_per_second': 0.0, 'eval_steps_per_second': 0.0, 'epoch': 0.13}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 15%|█▍        | 800/5488 [15:43<1:07:34,  1.16it/s] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.0594, 'grad_norm': 2.8423514366149902, 'learning_rate': 1.8983599919011947e-05, 'epoch': 0.15}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 15%|█▍        | 800/5488 [16:05<1:07:34,  1.16it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_cosine_accuracy': 0.9914, 'eval_dot_accuracy': 0.0089, 'eval_manhattan_accuracy': 0.9868, 'eval_euclidean_accuracy': 0.9923, 'eval_max_accuracy': 0.9923, 'eval_runtime': 21.8326, 'eval_samples_per_second': 0.0, 'eval_steps_per_second': 0.0, 'epoch': 0.15}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 15%|█▍        | 800/5488 [16:08<1:34:34,  1.21s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'train_runtime': 968.3625, 'train_samples_per_second': 362.678, 'train_steps_per_second': 5.667, 'train_loss': 1.2938791829347611, 'epoch': 0.15}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "TrainOutput(global_step=800, training_loss=1.2938791829347611, metrics={'train_runtime': 968.3625, 'train_samples_per_second': 362.678, 'train_steps_per_second': 5.667, 'total_flos': 0.0, 'train_loss': 1.2938791829347611, 'epoch': 0.1457725947521866})"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer.train()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'cosine_accuracy': 0.9854797000258598,\n",
       " 'dot_accuracy': 0.014455650374967675,\n",
       " 'manhattan_accuracy': 0.9164339281096457,\n",
       " 'euclidean_accuracy': 0.9642487716576157,\n",
       " 'max_accuracy': 0.9854797000258598}"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# note: let's evaluate on all test examples (although time consuming)\n",
    "test_evaluator = TripletEvaluator(\n",
    "    **dataset['test'].to_dict(),\n",
    "    main_distance_function='cosine',\n",
    "    batch_size=64,\n",
    ")\n",
    "test_evaluator(trainer.model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Save model to disk and clean up"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "import shutil\n",
    "shutil.rmtree(model_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The provided 'paraphrase-mpnet-base-v2-social-group-mention-embedding' model ID should include the organization or user, such as \"tomaarsen/mpnet-base-nli-matryoshka\". Setting `model_id` to None.\n"
     ]
    }
   ],
   "source": [
    "trainer.model.model_card_data = SentenceTransformerModelCardData(\n",
    "    language='en',\n",
    "    model_id=os.path.basename(model_dir),\n",
    "    model_name=model_id+' finetuned for social group mention attribute classification',\n",
    "    train_datasets='Social group mention attributes multilabel classifications (Licht & Röth, 2025)',\n",
    "    task_name='text embedding'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save_pretrained(model_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['economic: class membership', 'economic: ecology of group',\n",
       "       'economic: education level', 'economic: employment status',\n",
       "       'economic: income/wealth/economic status',\n",
       "       'economic: occupation/profession', 'economic: other',\n",
       "       'non-economic: age', 'non-economic: crime',\n",
       "       'non-economic: ethnicity', 'non-economic: family',\n",
       "       'non-economic: gender/sexuality', 'non-economic: health',\n",
       "       'non-economic: nationality', 'non-economic: other',\n",
       "       'non-economic: place/location', 'non-economic: religion',\n",
       "       'non-economic: shared values/mentalities', 'universal: '],\n",
       "      dtype=object)"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['attribute_combination'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer.model.to('cpu');\n",
    "model.to('cpu');\n",
    "del trainer, model"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "galtan_group_appeals",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
