{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c5604f73-f395-42cb-8082-9974a87ef9e9",
   "metadata": {},
   "source": [
    "## Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "70a859ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from pathlib import Path\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import regex\n",
    "from nltk import download as nltk_download\n",
    "\n",
    "nltk_download('punkt', quiet=True)\n",
    "nltk_download('stopwords', quiet=True)\n",
    "nltk_download('wordnet', quiet=True)\n",
    "\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize\n",
    "import string\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "efc54acc",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_path = Path('../../../data/annotations/group_mention_categorization')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e756be8-3b60-4c86-aa1b-7ef78289b8e2",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Preparing the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8c55d2d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "fp = data_path / 'final_annotations.tsv'\n",
    "annotations = pd.read_csv(fp, sep='\\t')\n",
    "# ignore = ['stance: ', 'universal: ']\n",
    "# annotations.query(\"attribute_combination not in @ignore\", inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2cd9da92",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# verify\n",
    "annotations.q_id.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "3b90c5dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "annotations['sentence_id'] = annotations['mention_id'].str.split('-', expand=True).iloc[:, :-1].apply(lambda x: '-'.join(x), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "cbb59179",
   "metadata": {},
   "outputs": [],
   "source": [
    "# gather attribute combinations with label=='Yes' at the mention level\n",
    "mentions_df = annotations.groupby(['sentence_id', 'mention_id', 'text', 'mention'])[['attribute_combination', 'label']].apply(lambda x: sorted(set(x.attribute_combination[x.label=='Yes']))).reset_index()\n",
    "mentions_df.rename(columns={0: 'attributes'}, inplace=True)\n",
    "mentions_df['span'] = mentions_df.apply(lambda x: regex.search(regex.escape(x['mention']), x['text']).span(), axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6bd64c97",
   "metadata": {},
   "source": [
    "## Get multi-label indicators"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50c29f18",
   "metadata": {},
   "source": [
    "### Attribute level"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e664c485",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = annotations.query(\"category!='other'\")\n",
    "\n",
    "# normalize attribute combinations names\n",
    "df.loc[:, 'attribute_combination'] = df['attribute_combination'].str.replace(': ', '__').str.replace('non-', 'non').str.replace(r'[^a-z_]+', '_', regex=True)\n",
    "\n",
    "features = sorted(set(df['attribute_combination']))\n",
    "df.loc[:, 'label'] = df['label'].map({'Yes': 1, 'No': 0})\n",
    "\n",
    "# pivot labels for attribute_combination to columns using mention_id as id vars\n",
    "df = df.pivot(index=['sentence_id', 'mention_id'], columns='attribute_combination', values='label').reset_index()\n",
    "df.columns.name = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ea264bf1",
   "metadata": {},
   "outputs": [],
   "source": [
    "cnts = df[features].sum(axis=0)\n",
    "MIN_COUNT = 10\n",
    "drop_these = cnts[cnts < MIN_COUNT].index.tolist()\n",
    "if drop_these:\n",
    "    print(f\"Dropping features with less than {MIN_COUNT} positive examples: {drop_these}\")\n",
    "    for f in drop_these:\n",
    "        features.remove(f)\n",
    "    df.drop(columns=drop_these, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb8c9f13",
   "metadata": {},
   "source": [
    "### dimension level"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "cd3f80ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "for dim in ['economic', 'noneconomic']:\n",
    "    dim_features = [f for f in features if f.startswith(dim)]\n",
    "    df[dim] = df[dim_features].astype(bool).any(axis=1).astype(int)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18e38a58",
   "metadata": {},
   "source": [
    "## Data splitting"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da0d3079",
   "metadata": {},
   "source": [
    "### Prevent data leakage\n",
    "\n",
    "Note that some mentions are (near) duplicates.\n",
    "Random sampling into train/dev/test would cause data leakage.\n",
    "Hence, I\n",
    "\n",
    "1. identify near duplicate mentions using the token-level Jaccard similarity,\n",
    "2. group these into components using a similarity threshold of > 0.5\n",
    "3. block by component membership during data splitting\n",
    "\n",
    "Additionally, I connect mentions in the same sentence to further limit leakage (i.e., make the task harder)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "46c9d0ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "# tokenize mentions (applying lowercasing, punct. removal, stopword removal, and lemmatization)\n",
    "stop_words = set(stopwords.words('english'))\n",
    "lemmatizer = WordNetLemmatizer()\n",
    "def preprocess_mention(mention):\n",
    "    # lowercase\n",
    "    mention = mention.lower()\n",
    "    # tokenize\n",
    "    tokens = word_tokenize(mention)\n",
    "    # remove punctuation and stopwords, and lemmatize\n",
    "    tokens = [\n",
    "        lemmatizer.lemmatize(token)\n",
    "        for token in tokens\n",
    "        if token not in string.punctuation and token not in stop_words\n",
    "    ]\n",
    "    return tokens\n",
    "\n",
    "mentions_df['mention_tokens'] = mentions_df['mention'].apply(preprocess_mention)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "d07d26d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# detect near duplicates using jaccard similarity\n",
    "def jaccard_sim(list1, list2):\n",
    "    set1 = set(list1)\n",
    "    set2 = set(list2)\n",
    "    intersection = len(set1.intersection(set2))\n",
    "    union = len(set1.union(set2))\n",
    "    if union == 0:\n",
    "        return 0.0\n",
    "    return intersection / union\n",
    "\n",
    "def find_near_duplicates(df, threshold=0.8):\n",
    "    near_duplicates = set()\n",
    "    n = len(df)\n",
    "    for i in range(n):\n",
    "        for j in range(i + 1, n):\n",
    "            sim = jaccard_sim(df.iloc[i]['mention_tokens'], df.iloc[j]['mention_tokens'])\n",
    "            if sim > threshold:\n",
    "                near_duplicates.add((i, j, sim)) \n",
    "    return near_duplicates\n",
    "\n",
    "near_duplicates = find_near_duplicates(mentions_df, threshold=0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "4df1632d",
   "metadata": {},
   "outputs": [],
   "source": [
    "near_duplicates_df = pd.DataFrame(list(near_duplicates), columns=['idx1', 'idx2', 'similarity'])\n",
    "near_duplicates_df['mention_a'] = near_duplicates_df['idx1'].apply(lambda x: mentions_df.iloc[x]['mention'])\n",
    "near_duplicates_df['mention_b'] = near_duplicates_df['idx2'].apply(lambda x: mentions_df.iloc[x]['mention'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "126a0379",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "393"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# number of near-duplicate pairs (≠ near duplicates components!)\n",
    "len(near_duplicates_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "2093e78b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "similarity\n",
       "1.000000    283\n",
       "0.888889      1\n",
       "0.875000      2\n",
       "0.857143      3\n",
       "0.833333      5\n",
       "0.800000      4\n",
       "0.750000     14\n",
       "0.714286      8\n",
       "0.666667     43\n",
       "0.625000      9\n",
       "0.600000      3\n",
       "0.571429     10\n",
       "0.555556      6\n",
       "0.545455      2\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# get distribution of similarity scores\n",
    "near_duplicates_df.similarity.value_counts().sort_index(ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "f9f487fa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>idx1</th>\n",
       "      <th>idx2</th>\n",
       "      <th>similarity</th>\n",
       "      <th>mention_a</th>\n",
       "      <th>mention_b</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>154</th>\n",
       "      <td>274</td>\n",
       "      <td>381</td>\n",
       "      <td>0.545455</td>\n",
       "      <td>lesbian, gay, bisexual, trans*, inter* and que...</td>\n",
       "      <td>Lesbian, Gay, Bisexual, Trans, Intersex, Queer...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>120</th>\n",
       "      <td>376</td>\n",
       "      <td>381</td>\n",
       "      <td>0.545455</td>\n",
       "      <td>Lesbian, gay, bisexual, transgender, intersex ...</td>\n",
       "      <td>Lesbian, Gay, Bisexual, Trans, Intersex, Queer...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>91</th>\n",
       "      <td>274</td>\n",
       "      <td>289</td>\n",
       "      <td>0.555556</td>\n",
       "      <td>lesbian, gay, bisexual, trans*, inter* and que...</td>\n",
       "      <td>lesbian, gay, bisexual, trans and intersex people</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>155</th>\n",
       "      <td>289</td>\n",
       "      <td>376</td>\n",
       "      <td>0.555556</td>\n",
       "      <td>lesbian, gay, bisexual, trans and intersex people</td>\n",
       "      <td>Lesbian, gay, bisexual, transgender, intersex ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>359</th>\n",
       "      <td>289</td>\n",
       "      <td>380</td>\n",
       "      <td>0.555556</td>\n",
       "      <td>lesbian, gay, bisexual, trans and intersex people</td>\n",
       "      <td>Lesbian, Gay Bisexual, Trans, Intersex, Queer ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>281</th>\n",
       "      <td>57</td>\n",
       "      <td>59</td>\n",
       "      <td>0.857143</td>\n",
       "      <td>people based on race, religion and ethnic origin</td>\n",
       "      <td>people based on race, gender religion and ethn...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>170</th>\n",
       "      <td>57</td>\n",
       "      <td>61</td>\n",
       "      <td>0.857143</td>\n",
       "      <td>people based on race, religion and ethnic origin</td>\n",
       "      <td>people based on race, gender, religion or ethn...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>163</th>\n",
       "      <td>274</td>\n",
       "      <td>275</td>\n",
       "      <td>0.875000</td>\n",
       "      <td>lesbian, gay, bisexual, trans*, inter* and que...</td>\n",
       "      <td>lesbian, gay, bisexual, trans*, inter* and que...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>175</th>\n",
       "      <td>274</td>\n",
       "      <td>294</td>\n",
       "      <td>0.875000</td>\n",
       "      <td>lesbian, gay, bisexual, trans*, inter* and que...</td>\n",
       "      <td>lesbian, gay, bisexual, trans, inter and queer...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>291</th>\n",
       "      <td>380</td>\n",
       "      <td>381</td>\n",
       "      <td>0.888889</td>\n",
       "      <td>Lesbian, Gay Bisexual, Trans, Intersex, Queer ...</td>\n",
       "      <td>Lesbian, Gay, Bisexual, Trans, Intersex, Queer...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>110 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     idx1  idx2  similarity  \\\n",
       "154   274   381    0.545455   \n",
       "120   376   381    0.545455   \n",
       "91    274   289    0.555556   \n",
       "155   289   376    0.555556   \n",
       "359   289   380    0.555556   \n",
       "..    ...   ...         ...   \n",
       "281    57    59    0.857143   \n",
       "170    57    61    0.857143   \n",
       "163   274   275    0.875000   \n",
       "175   274   294    0.875000   \n",
       "291   380   381    0.888889   \n",
       "\n",
       "                                             mention_a  \\\n",
       "154  lesbian, gay, bisexual, trans*, inter* and que...   \n",
       "120  Lesbian, gay, bisexual, transgender, intersex ...   \n",
       "91   lesbian, gay, bisexual, trans*, inter* and que...   \n",
       "155  lesbian, gay, bisexual, trans and intersex people   \n",
       "359  lesbian, gay, bisexual, trans and intersex people   \n",
       "..                                                 ...   \n",
       "281   people based on race, religion and ethnic origin   \n",
       "170   people based on race, religion and ethnic origin   \n",
       "163  lesbian, gay, bisexual, trans*, inter* and que...   \n",
       "175  lesbian, gay, bisexual, trans*, inter* and que...   \n",
       "291  Lesbian, Gay Bisexual, Trans, Intersex, Queer ...   \n",
       "\n",
       "                                             mention_b  \n",
       "154  Lesbian, Gay, Bisexual, Trans, Intersex, Queer...  \n",
       "120  Lesbian, Gay, Bisexual, Trans, Intersex, Queer...  \n",
       "91   lesbian, gay, bisexual, trans and intersex people  \n",
       "155  Lesbian, gay, bisexual, transgender, intersex ...  \n",
       "359  Lesbian, Gay Bisexual, Trans, Intersex, Queer ...  \n",
       "..                                                 ...  \n",
       "281  people based on race, gender religion and ethn...  \n",
       "170  people based on race, gender, religion or ethn...  \n",
       "163  lesbian, gay, bisexual, trans*, inter* and que...  \n",
       "175  lesbian, gay, bisexual, trans, inter and queer...  \n",
       "291  Lesbian, Gay, Bisexual, Trans, Intersex, Queer...  \n",
       "\n",
       "[110 rows x 5 columns]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# look at near duplicates below (token-level) identity\n",
    "near_duplicates_df.query(\"similarity < 1.0\").sort_values(by='similarity', ascending=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "f6b3396d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a graph of near-duplicate mentions\n",
    "import networkx as nx\n",
    "G = nx.Graph()\n",
    "\n",
    "# add edges for near-duplicate mentions\n",
    "for _, row in near_duplicates_df.iterrows():\n",
    "    G.add_edge(row['idx1'], row['idx2'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "61c7f792",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "58"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# get connected components of near-duplicate mentions\n",
    "connected_components = list(nx.connected_components(G))\n",
    "len(connected_components)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "1bb47559",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "16     1\n",
       "10     1\n",
       "9      2\n",
       "8      2\n",
       "7      2\n",
       "6      2\n",
       "5      4\n",
       "4      3\n",
       "3     13\n",
       "2     28\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# distribution of sizes of near duplicate components\n",
    "pd.Series(map(len, connected_components)).value_counts().sort_index(ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "330140bf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Component 0 (N=8):\n",
      "----------\n",
      "our society\n",
      "The society\n",
      "society\n",
      "\n",
      "Component 1 (N=16):\n",
      "----------\n",
      "lesbian, gay, bisexual, transgender and intersex people\n",
      "lesbian, gay, bisexual, trans and intersex people\n",
      "lesbian, gay, bisexual, trans and intersex persons\n",
      "Lesbian, Gay, Bisexual, and Transgender Persons\n",
      "lesbian, gay, bisexual, transgender people\n",
      "Lesbian, Gay Bisexual, Trans, Intersex, Queer and Asexual (LGBTIQA+) and\n",
      "lesbian, gay, bisexual, trans, inter and queer people\n",
      "gay, lesbian, bisexual, transgender and intersex persons\n",
      "Lesbian, Gay, Bisexual and Transgender people\n",
      "gay, lesbian, bisexual and transgender people\n",
      "Lesbian, Gay, Bisexual, Transgender or Intersex (LGBTI) people\n",
      "lesbian, gay, bisexual, trans*, inter* and queer (LSBTIQ*) people\n",
      "Lesbian, gay, bisexual, transgender, intersex and queer (LGBTIQ) people\n",
      "Lesbian, Gay, Bisexual, Trans, Intersex, Queer and Asexual (LGBTIQA+) people\n",
      "gay, lesbian, bisexual and transgender\n",
      "lesbian, gay, bisexual, trans*, inter* and queer people\n",
      "\n",
      "Component 2 (N=9):\n",
      "----------\n",
      "our people\n",
      "People\n",
      "people\n",
      "the people\n",
      "\n",
      "Component 3 (N=9):\n",
      "----------\n",
      "young people\n",
      "young people in Slovakia\n",
      "the families of these young people\n",
      "Young people\n",
      "\n",
      "Component 4 (N=6):\n",
      "----------\n",
      "the elderly\n",
      "The elderly\n",
      "\n",
      "Component 5 (N=7):\n",
      "----------\n",
      "our citizens\n",
      "citizens\n",
      "its citizens\n",
      "Our citizens\n",
      "\n",
      "Component 6 (N=5):\n",
      "----------\n",
      "individuals\n",
      "each individual\n",
      "the individual\n",
      "\n",
      "Component 7 (N=6):\n",
      "----------\n",
      "the victims of crime\n",
      "the Victims of Crime\n",
      "those who are victims of crime\n",
      "The victims of crime\n",
      "people who were victims of some crime\n",
      "people who become victims of a crime\n",
      "\n",
      "Component 8 (N=7):\n",
      "----------\n",
      "The family\n",
      "the family\n",
      "families such as\n",
      "family\n",
      "families\n",
      "\n",
      "Component 9 (N=10):\n",
      "----------\n",
      "children\n",
      "all children\n",
      "the children\n",
      "Children\n",
      "\n",
      "Component 11 (N=5):\n",
      "----------\n",
      "workers\n",
      "\n",
      "Component 12 (N=8):\n",
      "----------\n",
      "ethnic and religious groups\n",
      "ethnic or religious groups\n",
      "other ethnic and religious groups\n",
      "different ethnic and religious groups\n",
      "members of ethnic groups\n",
      "ethnic or linguistic group\n",
      "an ethnic group\n",
      "certain ethnic groups\n",
      "\n",
      "Component 13 (N=5):\n",
      "----------\n",
      "people on the basis of sexual orientation or gender identity\n",
      "people on the basis of ethnicity, religion, sexual orientation or gender identity\n",
      "People of differing sexual orientations or gender identity\n",
      "people on the basis of disability, sexual orientation or transgender identity\n",
      "people on the basis of their sexual and gender identity\n",
      "\n",
      "Component 16 (N=4):\n",
      "----------\n",
      "those from minority ethnic backgrounds\n",
      "with ethnic minority backgrounds\n",
      "people from ethnic minority backgrounds\n",
      "people from ethnic minorities\n",
      "\n",
      "Component 20 (N=5):\n",
      "----------\n",
      "members of their own family\n",
      "the individual family members\n",
      "members of human families\n",
      "individual, family,\n",
      "Members of their own family\n",
      "\n",
      "Component 23 (N=4):\n",
      "----------\n",
      "ordinary people\n",
      "\n",
      "Component 27 (N=4):\n",
      "----------\n",
      "the family of father, mother and children\n",
      "the mothers and fathers of family\n",
      "their fathers and mothers\n",
      "The father or mother of the family\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# show mentions in connected components larger than 3\n",
    "for i, comp in enumerate(connected_components):\n",
    "    if len(comp) > 3:\n",
    "        mentions = mentions_df.loc[list(comp)].mention.tolist()\n",
    "        print(f\"Component {i} (N={len(comp)}):\")\n",
    "        print(\"-\"*10)\n",
    "        print(*list(set(mentions)), sep='\\n')\n",
    "        print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "1cca6006",
   "metadata": {},
   "outputs": [],
   "source": [
    "# add edges for mentions in the same sentence\n",
    "for sentence_id, group in mentions_df.groupby('sentence_id'):\n",
    "    indices = group.index.tolist()\n",
    "    n = len(indices)\n",
    "    for i in range(n):\n",
    "        for j in range(i + 1, n):\n",
    "            G.add_edge(indices[i], indices[j])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "626f7827",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "63"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# get connected components of near-duplicate and same-sentence mentions\n",
    "connected_components = list(nx.connected_components(G))\n",
    "n_comps = len(connected_components)\n",
    "n_comps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "7369c19e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# add nodes for all mentions not already in the graph\n",
    "# NOTE: this is necessary to ensure mentions that have no near-duplicates and do not share a sentence with any other mention have their own component IDs\n",
    "for idx in mentions_df.index:\n",
    "    if idx not in G:\n",
    "        G.add_node(idx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "49d3758e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "430"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# get connected components of near-duplicate and same-sentence mentions\n",
    "connected_components = list(nx.connected_components(G))\n",
    "n_comps = len(connected_components)\n",
    "n_comps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "eb5b2c8e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>component_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>63</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>64</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>65</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>66</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   component_id\n",
       "0            19\n",
       "1            63\n",
       "2            64\n",
       "3            65\n",
       "4            66"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mention_components_df = pd.DataFrame([(c, i) for c, comp in enumerate(connected_components) for i in comp], columns=['component_id', 'mention_idx'])\n",
    "mention_components_df.set_index('mention_idx', inplace=True)\n",
    "mention_components_df.index.name = None\n",
    "mention_components_df.sort_index(inplace=True)\n",
    "mention_components_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "009183b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "mentions_df = mentions_df.join(mention_components_df, how='left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "52b94716",
   "metadata": {},
   "outputs": [],
   "source": [
    "assert mentions_df.component_id.isnull().sum()==0"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac65e140",
   "metadata": {},
   "source": [
    "### add metadata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "75497022",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "_merge\n",
       "both          600\n",
       "left_only       0\n",
       "right_only      0\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "metacols = [\"sentence_id\", \"mention_id\", \"text\", \"mention\", \"span\", \"component_id\"]\n",
    "df = mentions_df[metacols].merge(df, on=[\"sentence_id\", \"mention_id\"], how=\"outer\", indicator=True)\n",
    "df._merge.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "3de62ea7",
   "metadata": {},
   "outputs": [],
   "source": [
    "del df['_merge']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8ce328c",
   "metadata": {},
   "source": [
    "### create folds\n",
    "\n",
    "We want to block by component membership (using grouping) but keep the label distribution as similar across splits as possible.\n",
    "So first, I create a \"signature\" of attribute-level labels that can be used for stratification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "e49825d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.loc[:, 'signature'] = df.loc[:,features].apply(lambda x: ''.join(map(str, x.tolist())), axis=1)\n",
    "df['signature'] = df['signature'].where(df['signature'].isin(df['signature'].value_counts()[df['signature'].value_counts() >= 10].index), '_')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "6cdc32a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.reset_index(drop=True, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "8db19764",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "388 81 131\n",
      "391 88 121\n",
      "371 97 132\n",
      "394 98 108\n",
      "412 80 108\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import StratifiedGroupKFold\n",
    "n_splits = 5 # <=> test_size = 0.20\n",
    "dev_size = 0.15\n",
    "\n",
    "n_ = len(df)\n",
    "n_dev = int(n_ * dev_size)\n",
    "\n",
    "import warnings\n",
    "\n",
    "with warnings.catch_warnings():\n",
    "    warnings.filterwarnings(\"ignore\", category=UserWarning)\n",
    "    splitter = StratifiedGroupKFold(n_splits=n_splits, shuffle=True, random_state=42)\n",
    "    idxs = {}\n",
    "    for fold, (tmp, tst) in enumerate(splitter.split(df.index, y=df['signature'], groups=df['component_id'])):\n",
    "        sub_splitter = StratifiedGroupKFold(n_splits=int(len(tmp)/n_dev), shuffle=True, random_state=42)\n",
    "        trn, val = next(sub_splitter.split(tmp, y=df.iloc[tmp]['signature'], groups=df.iloc[tmp]['component_id']))\n",
    "        print(len(trn), len(val), len(tst))\n",
    "        idxs[fold] = (tmp[trn], tmp[val], tst)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "7860343d",
   "metadata": {},
   "outputs": [],
   "source": [
    "del df['component_id']\n",
    "del df['signature']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a5287600",
   "metadata": {},
   "source": [
    "### write folds to disk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c801b336",
   "metadata": {},
   "outputs": [],
   "source": [
    "splits_path = data_path / \"splits\" / \"error_detection\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "870519b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "for fold, (trn, val, tst) in idxs.items():\n",
    "    dest = splits_path / f\"fold{fold+1:02d}\"\n",
    "    os.makedirs(dest, exist_ok=True)\n",
    "    df.iloc[trn].to_pickle(dest / \"train.pkl\")\n",
    "    df.iloc[val].to_pickle(dest / \"val.pkl\")\n",
    "    df.iloc[tst].to_pickle(dest / \"test.pkl\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "galtan_group_appeals",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
