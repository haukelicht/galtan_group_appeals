{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab7ecb32",
   "metadata": {},
   "outputs": [],
   "source": [
    "# determine if current environment is a python script\n",
    "is_python_script = '__file__' in globals()\n",
    "\n",
    "# evaluate below if run as a python script\n",
    "if not is_python_script:\n",
    "    from types import SimpleNamespace\n",
    "    args = SimpleNamespace()\n",
    "\n",
    "    args.data_splits_path =  '../../data/annotations/group_mention_categorization/splits/fold01/'\n",
    "    # args.label_cols = 'economic,noneconomic'\n",
    "    args.label_cols = 'noneconomic__*'\n",
    "    \n",
    "    args.id_col = 'mention_id'\n",
    "    args.text_col = 'text'\n",
    "    args.mention_col = 'mention'\n",
    "    args.span_col = 'span'\n",
    "\n",
    "    # args.model_name = 'sentence-transformers/all-mpnet-base-v2'\n",
    "    # args.model_name = \"sentence-transformers/all-MiniLM-L6-v2\"\n",
    "    args.model_name = \"ibm-granite/granite-embedding-english-r2\" # can't use because it uses `pooling_mode_cls_token`\n",
    "    # args.model_name = \"nomic-ai/modernbert-embed-base\"\n",
    "    # # args.model_name = \"Alibaba-NLP/gte-modernbert-base\" # can't use because it uses `pooling_mode_cls_token`\n",
    "    # args.model_name = \"google/embeddinggemma-300m\"\n",
    "    # args.model_name = \"Qwen/Qwen3-Embedding-0.6B\"\n",
    "\n",
    "\n",
    "    args.use_span_embeddings = False # or True\n",
    "    args.concat_strategy = None # 'prefix', 'suffix' or None\n",
    "    args.concat_sep_token = ': '  # separator token for prefix/suffix concatenation\n",
    "    \n",
    "    args.class_weighting_strategy = 'inverse_proportional'  # or 'balanced' or None\n",
    "    args.class_weighting_smooth_exponent = 0.5  # default: 0.5\n",
    "\n",
    "    args.head_learning_rate = 0.001 # default: 0.01\n",
    "    args.train_batch_sizes = [32, 16] # default\n",
    "    # args.train_batch_sizes = [32, 8] # for gemma\n",
    "    # args.train_batch_sizes = [16, 4] # for Qwen3 embedding\n",
    "\n",
    "    args.body_early_stopping_patience = 2\n",
    "    args.body_early_stopping_threshold = 0.01\n",
    "    args.head_early_stopping_patience = 5\n",
    "    args.head_early_stopping_threshold = 0.015\n",
    "\n",
    "    strategy = 'span_embedding' if args.use_span_embeddings else 'mention_text' if args.concat_strategy is None else f'concat_{args.concat_strategy}'\n",
    "    args.save_eval_results_to = f'../../results/classifiers/noneconomic_attributes_classification/model_selection/setfit/{args.model_name.replace(\"/\", \"--\")}/fold01/{strategy}'\n",
    "    args.overwrite_results = True\n",
    "    args.do_eval = True\n",
    "    args.save_eval_results = True\n",
    "    args.save_eval_predictions = True\n",
    "    args.do_test = False\n",
    "    args.save_test_results = False\n",
    "    args.save_test_predictions = False\n",
    "\n",
    "    args.save_model = False\n",
    "    # args.save_model_to = '../../models/'\n",
    "    # args.save_model_as = 'social-group-mention-attribute-dimension-classifier-v3'\n",
    "\n",
    "else: # like __name__ == '__main__'\n",
    "    \n",
    "    import argparse\n",
    "    parser = argparse.ArgumentParser()\n",
    "\n",
    "    parser.add_argument('--data_splits_path', type=str, required=True, help='Path to data splits directory. Should contain files \"train.pkl\", \"val.pkl\", and \"test.pkl\"')\n",
    "    parser.add_argument('--label_cols', type=str, required=True, help='Comma-separated list of label column names') # TODO: allow glob patterns\n",
    "    parser.add_argument('--id_col', type=str, default='mention_id', help='Column name for unique mention IDs')\n",
    "    parser.add_argument('--text_col', type=str , default='text', help='Column name for mention context text')\n",
    "    parser.add_argument('--mention_col', type=str , default='mention', help='Column name for mention text')\n",
    "    parser.add_argument('--span_col', type=str , default='span', help='Column name for mention span (start, end)')\n",
    "    \n",
    "    parser.add_argument('--model_name', type=str, required=True, help='Name of the model to use. Must be a sentence-transformers compatible model.')\n",
    "    parser.add_argument('--use_span_embeddings', action='store_true', help='Whether to use custom SeFitForSpanClassification Trainer instead of mention and text concatenation or mention-only strategies')\n",
    "    parser.add_argument('--concat_strategy', type=str, choices=[None, 'prefix', 'suffix'], default=None, help='If not None, concatenate the mention text as prefix or suffix to the context text using --concat_sep_token')\n",
    "    parser.add_argument('--concat_sep_token', type=str, default=': ', help='Separator token to use when concatenating mention text to context text')\n",
    "    \n",
    "    parser.add_argument('--class_weighting_strategy', type=str, choices=[None, 'balanced', 'inverse_proportional'], default=None, help='Class weighting strategy to use during training')\n",
    "    parser.add_argument('--class_weighting_smooth_exponent', type=float, default=None, help='Smoothing exponent to use when computing class weights (only relevant if --class_weighting_strategy is set to \"inverse_proportional\")')\n",
    "\n",
    "    parser.add_argument('--head_learning_rate', type=float, default=0.01, help='Learning rate to use for classifier head training')\n",
    "    parser.add_argument('--train_batch_sizes', type=int, nargs='+', default=[32, 8], help='Tuple of batch sizes to use for embedding model and classifier training, respectively')\n",
    "\n",
    "    parser.add_argument('--body_early_stopping_patience', type=int, default=2, help='Early stopping patience for sentence transformer finetuning')\n",
    "    parser.add_argument('--body_early_stopping_threshold', type=float, default=0.01, help='Early stopping threshold for sentence transformer finetuning')\n",
    "    parser.add_argument('--head_early_stopping_patience', type=int, default=5, help='Early stopping patience for classifier head finetuning')\n",
    "    parser.add_argument('--head_early_stopping_threshold', type=float, default=0.015, help='Early stopping threshold for classifier head finetuning')\n",
    "\n",
    "    parser.add_argument('--save_eval_results_to', type=str, required=True, help='Directory to save evaluation results to')\n",
    "    parser.add_argument('--overwrite_results', action='store_true', help='Whether to overwrite existing evaluation results')\n",
    "    parser.add_argument('--do_eval', action='store_true', help='Whether to perform evaluation on the validation set')\n",
    "    parser.add_argument('--save_eval_results', action='store_true', help='Whether to save evaluation results to disk')\n",
    "    parser.add_argument('--save_eval_predictions', action='store_true', help='Whether to save evaluation predictions to disk')\n",
    "    parser.add_argument('--do_test', action='store_true', help='Whether to perform testing on the test set')\n",
    "    parser.add_argument('--save_test_results', action='store_true', help='Whether to save test results to disk')\n",
    "    parser.add_argument('--save_test_predictions', action='store_true', help='Whether to save test predictions to disk')\n",
    "    \n",
    "    parser.add_argument('--save_model', action='store_true', help='Whether to save the trained model to disk')\n",
    "    parser.add_argument('--save_model_to', type=str, help='Directory to save the trained model to')\n",
    "    parser.add_argument('--save_model_as', type=str, help='Name to save the trained model as')\n",
    "    \n",
    "    args = parser.parse_args()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c5604f73-f395-42cb-8082-9974a87ef9e9",
   "metadata": {},
   "source": [
    "## Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "70a859ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from pathlib import Path\n",
    "import shutil\n",
    "import warnings\n",
    "import json\n",
    "\n",
    "import numpy as np\n",
    "np.set_printoptions(precision=4, suppress=True)\n",
    "import pandas as pd\n",
    "import regex\n",
    "\n",
    "import torch\n",
    "torch.set_float32_matmul_precision('high')\n",
    "from datasets import Dataset, DatasetDict\n",
    "from transformers import AutoTokenizer, set_seed\n",
    "os.environ[\"CUBLAS_WORKSPACE_CONFIG\"] = \":4096:8\"  # to enable deterministic behavior with CuBLAS\n",
    "SEED = 42\n",
    "set_seed(SEED, deterministic=True) # for reproducibility\n",
    "\n",
    "# default setfit body and head\n",
    "from sentence_transformers import SentenceTransformer\n",
    "from setfit.modeling import SetFitHead\n",
    "\n",
    "# class weight head\n",
    "from src.finetuning.setfit_extensions.class_weights_head import (\n",
    "    compute_class_weights,\n",
    "    SetFitHeadWithClassWeights\n",
    ")\n",
    "# early stopping model, training args, and trainer\n",
    "from src.finetuning.setfit_extensions.early_stopping import (\n",
    "    SetFitModelWithEarlyStopping, \n",
    "    EarlyStoppingTrainingArguments,\n",
    "    EarlyStoppingCallback,\n",
    "    SetFitEarlyStoppingTrainer\n",
    ")\n",
    "# span embedding model, head, and trainer\n",
    "from src.finetuning.setfit_extensions.span_embedding import (\n",
    "    SentenceTransformerForSpanEmbedding,\n",
    "    SetFitModelForSpanClassification,\n",
    "    SetFitTrainerForSpanClassification,\n",
    ")\n",
    "\n",
    "from sklearn.metrics import classification_report\n",
    "# from utils.metrics import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "830ea215",
   "metadata": {},
   "outputs": [],
   "source": [
    "def model_init(\n",
    "        model_name: str = \"sentence-transformers/all-MiniLM-L6-v2\",\n",
    "        num_classes: int = 2,\n",
    "        class_weights: np._typing.NDArray = None,\n",
    "        multilabel: bool = False,\n",
    "        use_span_embedding: bool = False,\n",
    "        body_kwargs: dict = {},\n",
    "        head_kwargs: dict = {},\n",
    "        model_kwargs: dict = {},\n",
    "    ) -> SetFitModelWithEarlyStopping | SetFitModelForSpanClassification:\n",
    "    \"\"\"\n",
    "    Initialize a SetFit model with optional span embeddings and class weights.\n",
    "    \"\"\"\n",
    "    \n",
    "    body_class = SentenceTransformerForSpanEmbedding if use_span_embedding else SentenceTransformer\n",
    "    body_kwargs={\"device_map\": \"auto\", **body_kwargs}\n",
    "    body = body_class(model_name, model_kwargs=body_kwargs, trust_remote_code=True)\n",
    "    \n",
    "    \n",
    "    head_class = SetFitHead\n",
    "    head_kwargs = {\n",
    "        \"in_features\": body.get_sentence_embedding_dimension(),\n",
    "        \"out_features\": num_classes,\n",
    "        \"device\": body.device,\n",
    "        \"multitarget\": multilabel,\n",
    "        **head_kwargs\n",
    "    }\n",
    "    if class_weights is not None:\n",
    "        head_class = SetFitHeadWithClassWeights\n",
    "        head_kwargs[\"class_weights\"] = class_weights\n",
    "    head = head_class(**head_kwargs)\n",
    "    \n",
    "\n",
    "    model_class = SetFitModelForSpanClassification if use_span_embedding else SetFitModelWithEarlyStopping\n",
    "    if multilabel and \"multi_target_strategy\" not in model_kwargs:\n",
    "        model_kwargs[\"multi_target_strategy\"] = \"one-vs-rest\"\n",
    "    return model_class(\n",
    "        model_body=body,\n",
    "        model_head=head.to(body.device),\n",
    "        normalize_embeddings=True,\n",
    "        **model_kwargs\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0339ad2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "args.data_splits_path = Path(args.data_splits_path)\n",
    "\n",
    "if isinstance(args.label_cols, str):\n",
    "    args.label_cols = [col.strip() for col in args.label_cols.split(',')]\n",
    "\n",
    "if args.save_eval_results_to is not None:\n",
    "    args.save_eval_results_to = Path(args.save_eval_results_to)\n",
    "    if not (args.do_eval or args.do_test):\n",
    "        raise ValueError(\"'save_eval_results_to' is specified but neither 'do_eval' nor 'do_test' is set.\")\n",
    "    elif not any([args.save_eval_results, args.save_eval_predictions, args.save_test_results, args.save_test_predictions]):\n",
    "        warnings.warn(\"'save_eval_results_to' is specified but none of 'save_eval_results', 'save_eval_predictions', 'save_test_results', or 'save_test_predictions' is set.\")\n",
    "    elif args.save_eval_results_to.exists() and not args.overwrite_results:\n",
    "        raise ValueError(f\"The directory '{args.save_eval_results_to}' already exists. To avoid overwriting, please specify a different path or set 'overwrite_results'\")\n",
    "    else:\n",
    "        args.save_eval_results_to.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "if args.save_model:\n",
    "    if args.save_model_to is None or args.save_model_as is None:\n",
    "        raise ValueError(\"Both 'save_model_to' and 'save_model_as' must be specified if 'save_model' is True.\")\n",
    "    args.save_model_to = Path(args.save_model_to)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e756be8-3b60-4c86-aa1b-7ef78289b8e2",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Prepare the datasets"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d41b09b4",
   "metadata": {},
   "source": [
    "### Load the splits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c59a72c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.concat({split: pd.read_pickle(args.data_splits_path / f\"{split}.pkl\") for split in ['train', 'val', 'test']})\n",
    "df.reset_index(level=0, names='split', inplace=True)\n",
    "df['split'] = pd.Categorical(df['split'], categories=['train', 'val', 'test'], ordered=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3793063a",
   "metadata": {},
   "source": [
    "### prepare the label column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "7a748e8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# consider that entries in args.label_cols may be glob patterns\n",
    "import fnmatch\n",
    "expanded_label_cols = []\n",
    "for lab in args.label_cols:\n",
    "    matched = fnmatch.filter(df.columns, lab)\n",
    "    if matched:\n",
    "        expanded_label_cols.extend(matched)\n",
    "    else:\n",
    "        expanded_label_cols.append(lab)\n",
    "args.label_cols = expanded_label_cols"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "af82ba25",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['labels'] = df[args.label_cols].apply(list, axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cdcf5092",
   "metadata": {},
   "source": [
    "### format inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "7faca004",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained(args.model_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "69912139",
   "metadata": {},
   "outputs": [],
   "source": [
    "if args.use_span_embeddings:\n",
    "    if \"span\" not in df.columns:\n",
    "    # using span embedding strategy\n",
    "        df['span'] = df.apply(lambda x: regex.search(regex.escape(x[args.mention_col]), x[args.text_col]).span(), axis=1)\n",
    "    max_length_ = max(tokenizer(df[args.text_col].to_list(), truncation=False, padding=False, return_length=True).length)\n",
    "    cols = [args.text_col, 'span', 'labels']\n",
    "    cols_mapping = {args.text_col: 'text', 'span': 'span', 'labels': 'label'}\n",
    "elif args.concat_strategy is None:\n",
    "    # default: just the mention text\n",
    "    max_length_ = max(tokenizer(df[args.mention_col].to_list(), truncation=False, padding=False, return_length=True).length)\n",
    "    cols = [args.mention_col, 'labels']\n",
    "    cols_mapping = {args.mention_col: 'text', 'labels': 'label'}\n",
    "else:\n",
    "    # using concat strategy\n",
    "    sep_tok = tokenizer.sep_token if args.concat_sep_token is None else args.concat_sep_token\n",
    "    if args.concat_strategy == 'prefix':\n",
    "        df['input'] = df[args.mention_col] + sep_tok + df[args.text_col]\n",
    "    elif args.concat_strategy == 'suffix':\n",
    "        df['input'] = df[args.text_col] + sep_tok + df[args.mention_col]\n",
    "    else:\n",
    "        raise ValueError(f\"Unknown concat strategy: {args.concat_strategy}\")\n",
    "    max_length_ = max(tokenizer(df['input'].to_list(), truncation=False, padding=False, return_length=True).length)\n",
    "    cols = ['input', 'labels']\n",
    "    cols_mapping = {\"input\": \"text\", \"labels\": \"label\"}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4936057f",
   "metadata": {},
   "source": [
    "### split the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "c3227e78",
   "metadata": {},
   "outputs": [],
   "source": [
    "datasets = DatasetDict({\n",
    "    s: Dataset.from_pandas(d, preserve_index=False)\n",
    "    for s, d in df.groupby('split', observed=True)\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "1a53e931",
   "metadata": {},
   "outputs": [],
   "source": [
    "datasets = datasets.remove_columns(set(df.columns)-set(cols))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "af47318c",
   "metadata": {},
   "outputs": [],
   "source": [
    "datasets = datasets.rename_columns(column_mapping=cols_mapping)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "dbf20eca",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'train': 388, 'val': 81, 'test': 131}"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "datasets.num_rows"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e1702b55",
   "metadata": {},
   "source": [
    "### Prepare fine-tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "c2242313",
   "metadata": {},
   "outputs": [],
   "source": [
    "id2label = {i: l for i, l in enumerate(args.label_cols)}\n",
    "label2id = {l: i for i, l in id2label.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "130f6664",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Class weights: {'noneconomic__age': 2.9495762407505253, 'noneconomic__crime': 4.533823502911814, 'noneconomic__ethnicity': 3.65655170486763, 'noneconomic__family': 3.4544657088084305, 'noneconomic__gender_sexuality': 4.671566055592568, 'noneconomic__health': 4.2895221179054435, 'noneconomic__nationality': 2.3614129639774317, 'noneconomic__place_location': 6.489307444643928, 'noneconomic__religion': 4.671566055592568, 'noneconomic__shared_values_mentalities': 2.385299807658105}\n"
     ]
    }
   ],
   "source": [
    "if args.class_weighting_strategy in ['inverse_proportional']:\n",
    "    class_weighting_args = {\n",
    "        \"multitarget\": len(args.label_cols) > 1,\n",
    "        \"smooth_weights\": args.class_weighting_strategy is not None and args.class_weighting_strategy != 'balanced',\n",
    "        \"smooth_exponent\": args.class_weighting_smooth_exponent if args.class_weighting_smooth_exponent is not None else 0.5\n",
    "    }\n",
    "    class_weights = compute_class_weights(datasets['train']['label'], **class_weighting_args)\n",
    "    print(f\"Class weights: {dict(zip(label2id.keys(), class_weights))}\")\n",
    "else:\n",
    "    class_weights = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f60340a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sentence_transformers.losses import ContrastiveLoss\n",
    "\n",
    "if args.save_model:\n",
    "    if args.save_model_to is None or args.save_model_as is None:\n",
    "        raise ValueError(\"Both 'save_model_to' and 'save_model_as' must be specified if 'save_model' is True.\")\n",
    "    model_dir = args.save_model_to / args.save_model_as \n",
    "else:\n",
    "    from tempfile import TemporaryDirectory\n",
    "    with TemporaryDirectory() as tmpdirname:\n",
    "        model_dir = tmpdirname\n",
    "\n",
    "training_args = EarlyStoppingTrainingArguments(\n",
    "    output_dir=model_dir,\n",
    "    loss=ContrastiveLoss,\n",
    "    \n",
    "    num_epochs=(1, 25),\n",
    "    batch_size=tuple(args.train_batch_sizes),\n",
    "\n",
    "    head_learning_rate = args.head_learning_rate,\n",
    "    # l2_weight=0.03,# TODO !!! /default 0.01\n",
    "    # warmup_proportion=0.15, # TODO !!! /default 0.1\n",
    "    \n",
    "    # sentence transformer (embedding) finetuning args\n",
    "    logging_first_step=False,\n",
    "    eval_strategy=\"steps\",\n",
    "    eval_steps=50,\n",
    "    max_steps=750,\n",
    "    eval_max_steps=250,\n",
    "    \n",
    "    # early stopping config\n",
    "    metric_for_best_model=(\"embedding_loss\", \"f1\"),\n",
    "    greater_is_better=(False, True),\n",
    "    load_best_model_at_end=True,\n",
    "    save_total_limit=2, # NOTE: currently no effect on (early stopping in) classification head training\n",
    "    \n",
    "    # misc\n",
    "    end_to_end=True,\n",
    ")\n",
    "\n",
    "training_callbacks = [\n",
    "    # for sentence transformer finetuning\n",
    "    EarlyStoppingCallback(\n",
    "        early_stopping_patience=args.body_early_stopping_patience,\n",
    "        early_stopping_threshold=args.body_early_stopping_threshold,\n",
    "    ), \n",
    "    # for classifier finetuning\n",
    "    EarlyStoppingCallback(\n",
    "        early_stopping_patience=args.head_early_stopping_patience,\n",
    "        early_stopping_threshold=args.head_early_stopping_threshold,\n",
    "    ), \n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "9f800dc2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ea3b35961ebf4da2a416079f047a1b73",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/388 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "trainer_class = SetFitTrainerForSpanClassification if args.use_span_embeddings else SetFitEarlyStoppingTrainer\n",
    "\n",
    "trainer = trainer_class(\n",
    "    model_init=lambda: model_init(\n",
    "        model_name=args.model_name,\n",
    "        num_classes=len(id2label),\n",
    "        multilabel=True,\n",
    "        class_weights=class_weights,\n",
    "        use_span_embedding=args.use_span_embeddings,\n",
    "    ),\n",
    "    metric=\"f1\",\n",
    "    metric_kwargs={\n",
    "        \"average\": \"macro\" if args.label_cols and len(args.label_cols) > 1 else \"binary\",\n",
    "        # \"zero_division\": 0.0\n",
    "    },\n",
    "    args=training_args,\n",
    "    train_dataset=datasets['train'],\n",
    "    eval_dataset=datasets['val'],\n",
    "    callbacks=training_callbacks,\n",
    "    # column_mapping=cols_mapping,\n",
    ")\n",
    "# fix max_length issue\n",
    "trainer._args.max_length = min(trainer.st_trainer.model.tokenizer.model_max_length, int(max_length_*1.1))\n",
    "\n",
    "# set seeds for reproducibility\n",
    "trainer._args.seed = SEED\n",
    "trainer.st_trainer.args.seed = SEED\n",
    "trainer.st_trainer.args.data_seed = SEED\n",
    "trainer.st_trainer.args.full_determinism = True\n",
    "\n",
    "# don't report to wandb or other experiment trackers\n",
    "trainer._args.report_to = 'none'\n",
    "trainer.st_trainer.args.report_to = 'none'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "72e49ed2",
   "metadata": {},
   "source": [
    "### Fine-tune"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "3a169b14",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "***** Running training *****\n",
      "  Num unique pairs = 24000\n",
      "  Batch size = 32\n",
      "  Num epochs = 1\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='150' max='750' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [150/750 00:29 < 02:00, 4.97 it/s, Epoch 0/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>50</td>\n",
       "      <td>0.025600</td>\n",
       "      <td>0.022608</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>100</td>\n",
       "      <td>0.013700</td>\n",
       "      <td>0.017154</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>150</td>\n",
       "      <td>0.006200</td>\n",
       "      <td>0.015488</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch:   0%|          | 0/25 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1: calculating validation f1 for early stopping\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch:   4%|▍         | 1/25 [00:01<00:45,  1.89s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'training loss': 0.7563324356079102, 'validation loss': 0.6972164809703827, 'f1': 0.0838095238095238}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2: calculating validation f1 for early stopping\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch:   8%|▊         | 2/25 [00:03<00:42,  1.84s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'training loss': 0.6237829291820526, 'validation loss': 0.5429519265890121, 'f1': 0.05}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3: calculating validation f1 for early stopping\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch:  12%|█▏        | 3/25 [00:05<00:35,  1.63s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'training loss': 0.5250413858890534, 'validation loss': 0.5189195772012075, 'f1': 0.34894605394605394}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4: calculating validation f1 for early stopping\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch:  16%|█▌        | 4/25 [00:06<00:31,  1.49s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'training loss': 0.4396515822410583, 'validation loss': 0.40876491367816925, 'f1': 0.34325396825396826}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5: calculating validation f1 for early stopping\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch:  20%|██        | 5/25 [00:07<00:29,  1.45s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'training loss': 0.37032562017440795, 'validation loss': 0.3612157727281253, 'f1': 0.5383155080213904}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 6: calculating validation f1 for early stopping\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch:  24%|██▍       | 6/25 [00:09<00:26,  1.40s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'training loss': 0.33077362179756165, 'validation loss': 0.3514048134287198, 'f1': 0.5108080808080808}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 7: calculating validation f1 for early stopping\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch:  28%|██▊       | 7/25 [00:10<00:25,  1.39s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'training loss': 0.3076485604047775, 'validation loss': 0.5460466047128042, 'f1': 0.5566666666666666}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 8: calculating validation f1 for early stopping\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch:  32%|███▏      | 8/25 [00:11<00:23,  1.39s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'training loss': 0.28406064689159394, 'validation loss': 0.550013134876887, 'f1': 0.5746256684491978}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9: calculating validation f1 for early stopping\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch:  36%|███▌      | 9/25 [00:13<00:21,  1.36s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'training loss': 0.2653011679649353, 'validation loss': 0.3497401873270671, 'f1': 0.5753612854891627}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 10: calculating validation f1 for early stopping\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch:  40%|████      | 10/25 [00:14<00:20,  1.34s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'training loss': 0.2524099487066269, 'validation loss': 0.36011242618163425, 'f1': 0.5859673460952233}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 11: calculating validation f1 for early stopping\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch:  44%|████▍     | 11/25 [00:15<00:18,  1.32s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'training loss': 0.2414713567495346, 'validation loss': 0.5789640173316002, 'f1': 0.5844521945800717}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 12: calculating validation f1 for early stopping\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch:  48%|████▊     | 12/25 [00:17<00:17,  1.34s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'training loss': 0.23357467532157897, 'validation loss': 0.3124457647403081, 'f1': 0.5950582551861323}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 13: calculating validation f1 for early stopping\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch:  52%|█████▏    | 13/25 [00:18<00:15,  1.32s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'training loss': 0.22657135963439942, 'validation loss': 0.36317818860212964, 'f1': 0.5927855279134051}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 14: calculating validation f1 for early stopping\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch:  56%|█████▌    | 14/25 [00:19<00:14,  1.31s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'training loss': 0.21680176317691802, 'validation loss': 0.3572480579217275, 'f1': 0.6033915885194657}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 15: calculating validation f1 for early stopping\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch:  60%|██████    | 15/25 [00:20<00:13,  1.31s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'training loss': 0.2121681135892868, 'validation loss': 0.28647921855250996, 'f1': 0.6033915885194657}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 16: calculating validation f1 for early stopping\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch:  64%|██████▍   | 16/25 [00:22<00:11,  1.30s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'training loss': 0.20419933915138244, 'validation loss': 0.391651709874471, 'f1': 0.6033915885194657}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 17: calculating validation f1 for early stopping\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch:  64%|██████▍   | 16/25 [00:23<00:13,  1.47s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'training loss': 0.20189030587673187, 'validation loss': 0.2833680734038353, 'f1': 0.6033915885194657}\n",
      "Early stopping triggered after 17 epochs\n",
      "Loading best model from epoch 12\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "trainer.train()\n",
    "\n",
    "# clean up\n",
    "if os.path.exists(model_dir):\n",
    "    shutil.rmtree(model_dir)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f903ff2e",
   "metadata": {},
   "source": [
    "## Evaluate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "db5cca91",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_predictions_df(split: str = 'val') -> pd.DataFrame:\n",
    "    preds_df = df.loc[df['split'] == split, [args.id_col, args.text_col, args.mention_col, args.span_col, *args.label_cols]].copy()\n",
    "    \n",
    "    inputs = trainer.model._normalize_inputs(texts=datasets[split]['text'], spans=datasets[split]['span']) if args.use_span_embeddings else datasets[split]['text']\n",
    "    \n",
    "    probs = trainer.model.predict_proba(inputs, as_numpy=True)\n",
    "    prob_cols = [f\"prob_{col}\" for col in args.label_cols]\n",
    "    preds_df[prob_cols] = probs\n",
    "    \n",
    "    preds = np.where(probs > 0.5, 1, 0)\n",
    "    pred_cols = [f\"pred_{col}\" for col in args.label_cols]\n",
    "    preds_df[pred_cols] = preds\n",
    "    \n",
    "    for lab in args.label_cols:\n",
    "        preds_df[f\"error_{lab}\"] = preds_df[f\"pred_{lab}\"] != preds_df[lab]\n",
    "    \n",
    "    return preds_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca40b170",
   "metadata": {},
   "source": [
    "### Validation set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "93e0aa63",
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs = trainer.model._normalize_inputs(texts=datasets['val']['text'], spans=datasets['val']['span']) if args.use_span_embeddings else datasets['val']['text']\n",
    "preds = trainer.model.predict(inputs, as_numpy=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "2ffb25a0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                        precision    recall  f1-score   support\n",
      "\n",
      "                      noneconomic__age       1.00      0.71      0.83         7\n",
      "                    noneconomic__crime       0.00      0.00      0.00         3\n",
      "                noneconomic__ethnicity       0.50      1.00      0.67         3\n",
      "                   noneconomic__family       1.00      1.00      1.00         5\n",
      "         noneconomic__gender_sexuality       1.00      0.70      0.82        10\n",
      "                   noneconomic__health       1.00      0.67      0.80         3\n",
      "              noneconomic__nationality       0.40      0.50      0.44         4\n",
      "           noneconomic__place_location       0.00      0.00      0.00         1\n",
      "                 noneconomic__religion       0.50      0.75      0.60         4\n",
      "noneconomic__shared_values_mentalities       0.90      0.69      0.78        13\n",
      "\n",
      "                             micro avg       0.78      0.68      0.73        53\n",
      "                             macro avg       0.63      0.60      0.60        53\n",
      "                          weighted avg       0.79      0.68      0.71        53\n",
      "                           samples avg       0.36      0.37      0.35        53\n",
      "\n"
     ]
    }
   ],
   "source": [
    "if args.do_eval:\n",
    "    print(classification_report(y_pred=preds, y_true=datasets['val']['label'], target_names=args.label_cols, zero_division=0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "b6300121",
   "metadata": {},
   "outputs": [],
   "source": [
    "if args.save_eval_results:\n",
    "    res = classification_report(y_pred=preds, y_true=datasets['val']['label'], target_names=args.label_cols, zero_division=0, output_dict=True)\n",
    "    fp = args.save_eval_results_to / 'eval_results.json'\n",
    "    with open(fp, 'w') as f:\n",
    "        json.dump(res, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "f0f29d19",
   "metadata": {},
   "outputs": [],
   "source": [
    "if args.save_eval_predictions:\n",
    "    preds_df = get_predictions_df(split='val')\n",
    "    fp = args.save_eval_results_to / 'eval_predictions.pkl'\n",
    "    preds_df.to_pickle(fp)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c03c12f4",
   "metadata": {},
   "source": [
    "### Test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "d7e69db8",
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs = trainer.model._normalize_inputs(texts=datasets['test']['text'], spans=datasets['test']['span']) if args.use_span_embeddings else datasets['test']['text']\n",
    "preds = trainer.model.predict(inputs, as_numpy=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "e80c47af",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                        precision    recall  f1-score   support\n",
      "\n",
      "                      noneconomic__age       0.92      0.61      0.73        18\n",
      "                    noneconomic__crime       1.00      0.33      0.50         9\n",
      "                noneconomic__ethnicity       1.00      0.75      0.86         4\n",
      "                   noneconomic__family       1.00      0.27      0.42        15\n",
      "         noneconomic__gender_sexuality       1.00      0.95      0.98        21\n",
      "                   noneconomic__health       1.00      0.38      0.55         8\n",
      "              noneconomic__nationality       0.80      0.73      0.76        11\n",
      "           noneconomic__place_location       0.00      0.00      0.00         7\n",
      "                 noneconomic__religion       0.67      0.50      0.57         4\n",
      "noneconomic__shared_values_mentalities       0.89      0.50      0.64        16\n",
      "\n",
      "                             micro avg       0.93      0.55      0.69       113\n",
      "                             macro avg       0.83      0.50      0.60       113\n",
      "                          weighted avg       0.88      0.55      0.65       113\n",
      "                           samples avg       0.45      0.41      0.42       113\n",
      "\n"
     ]
    }
   ],
   "source": [
    "if args.do_test:\n",
    "    print(classification_report(y_pred=preds, y_true=datasets['test']['label'], target_names=args.label_cols, zero_division=0))\n",
    "print(classification_report(y_pred=preds, y_true=datasets['test']['label'], target_names=args.label_cols, zero_division=0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "2a4e9f28",
   "metadata": {},
   "outputs": [],
   "source": [
    "if args.save_test_results:\n",
    "    res = classification_report(y_pred=preds, y_true=datasets['test']['label'], target_names=args.label_cols, zero_division=0, output_dict=True)\n",
    "    fp = args.save_eval_results_to / 'test_results.json'\n",
    "    with open(fp, 'w') as f:\n",
    "        json.dump(res, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "ef880b7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "if args.save_test_predictions:\n",
    "    preds_df = get_predictions_df(split='test')\n",
    "    fp = args.save_eval_results_to / 'test_predictions.pkl'\n",
    "    preds_df.to_pickle(fp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "63e9996c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# highlight = lambda text, mention: text.replace(mention, '\\u001B[30m\\u001B[43m'+mention+'\\033[0m')\n",
    "\n",
    "# for labs, subdf in df_test.groupby(args.label_cols):\n",
    "#     print(\"\\033[1mtrue\\033[0m:\", [id2label[i] for i, l in enumerate(labs) if l==1])\n",
    "#     subdf = subdf[subdf[error_cols].any(axis=1)]\n",
    "#     for preds, subsubdf in subdf.groupby(pred_cols):\n",
    "#         print(\" ↳ \\033[1m\\033[3mpred\\033[0m:\", [id2label[i] for i, l in enumerate(preds) if l==1])\n",
    "#         for i, row in subsubdf.sample(n=min(4, len(subsubdf)), random_state=42).iterrows():\n",
    "#             print(f\"    - {str(i).rjust(3)}: {highlight(row['text'], row['mention'])}\")\n",
    "#     print()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bfb8e4b8",
   "metadata": {},
   "source": [
    "## Save the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c40a8fa3",
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the current cell or a previous cell. \n",
      "\u001b[1;31mPlease review the code in the cell(s) to identify a possible cause of the failure. \n",
      "\u001b[1;31mClick <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "if args.save_model:\n",
    "    trainer.model.save_pretrained(model_dir)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "galtan_group_appeals",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
