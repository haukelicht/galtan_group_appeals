{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 125,
   "id": "3c1898ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from pathlib import Path\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from matplotlib import pyplot as plt\n",
    "import seaborn as sns\n",
    "from matplotlib.lines import Line2D"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "id": "1aafa26f",
   "metadata": {},
   "outputs": [],
   "source": [
    "results_path = Path(\"../../../results/classifiers\")\n",
    "STEP = \"hp_search\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "id": "553d7484",
   "metadata": {},
   "outputs": [],
   "source": [
    "varying_hyperparameter_names = [\"batch_size\", \"head_learning_rate\", \"l2_weight\", \"warmup_proportion\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0e42a9e",
   "metadata": {},
   "source": [
    "## Granular attributes classification"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b2f838c",
   "metadata": {},
   "source": [
    "### Economic attributes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "id": "b7c52a59",
   "metadata": {},
   "outputs": [],
   "source": [
    "task = \"economic_attributes_classification\"\n",
    "label_classes = [\n",
    "    # 'economic__class_membership',\n",
    "    'economic__education_level',\n",
    "    'economic__occupation_profession',\n",
    "    'economic__employment_status',\n",
    "    'economic__income_wealth_economic_status',\n",
    "    # 'economic__ecology_of_group',\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab58881f",
   "metadata": {},
   "source": [
    "#### Best hyperparameters?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "id": "b5755107",
   "metadata": {},
   "outputs": [],
   "source": [
    "trial_results_files = list(results_path.glob(f\"{task}/**/{STEP}/**/trial_results.csv\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "id": "ce3e6fbf",
   "metadata": {},
   "outputs": [],
   "source": [
    "trial_results = pd.concat(\n",
    "    {f.parts[-4:-1]: pd.read_csv(f) for f in trial_results_files},\n",
    ")\n",
    "trial_results.reset_index(level=[0, 1, 2], names=[\"model\", \"strategy\", \"fold\"], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "id": "8d71bc96",
   "metadata": {},
   "outputs": [],
   "source": [
    "trial_results_sum = trial_results.groupby([\"model\", \"strategy\", *varying_hyperparameter_names])[\"f1\"].mean().reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "id": "2d1fbc15",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>model</th>\n",
       "      <th>strategy</th>\n",
       "      <th>f1</th>\n",
       "      <th>batch_size</th>\n",
       "      <th>head_learning_rate</th>\n",
       "      <th>l2_weight</th>\n",
       "      <th>warmup_proportion</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>google--embeddinggemma-300m</td>\n",
       "      <td>mention_text</td>\n",
       "      <td>0.605311</td>\n",
       "      <td>(16, 4)</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>0.015</td>\n",
       "      <td>0.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>nomic-ai--modernbert-embed-base</td>\n",
       "      <td>mention_text</td>\n",
       "      <td>0.871875</td>\n",
       "      <td>(8, 16)</td>\n",
       "      <td>0.0030</td>\n",
       "      <td>0.200</td>\n",
       "      <td>0.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>sentence-transformers--all-mpnet-base-v2</td>\n",
       "      <td>mention_text</td>\n",
       "      <td>0.790788</td>\n",
       "      <td>(8, 8)</td>\n",
       "      <td>0.0030</td>\n",
       "      <td>0.200</td>\n",
       "      <td>0.1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                      model      strategy        f1  \\\n",
       "0               google--embeddinggemma-300m  mention_text  0.605311   \n",
       "1           nomic-ai--modernbert-embed-base  mention_text  0.871875   \n",
       "2  sentence-transformers--all-mpnet-base-v2  mention_text  0.790788   \n",
       "\n",
       "  batch_size  head_learning_rate  l2_weight  warmup_proportion  \n",
       "0    (16, 4)              0.0001      0.015                0.1  \n",
       "1    (8, 16)              0.0030      0.200                0.1  \n",
       "2     (8, 8)              0.0030      0.200                0.1  "
      ]
     },
     "execution_count": 132,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# get row with max F1 for each model and strategy\n",
    "trial_results_sum.groupby([\"model\", \"strategy\"])[[\"f1\", *varying_hyperparameter_names]].apply(lambda x: x.loc[x[\"f1\"].idxmax()]).reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "id": "85a4908a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>model</th>\n",
       "      <th>strategy</th>\n",
       "      <th>fold</th>\n",
       "      <th>trial_id</th>\n",
       "      <th>started_at</th>\n",
       "      <th>finished_at</th>\n",
       "      <th>duration</th>\n",
       "      <th>batch_size</th>\n",
       "      <th>head_learning_rate</th>\n",
       "      <th>l2_weight</th>\n",
       "      <th>warmup_proportion</th>\n",
       "      <th>f1</th>\n",
       "      <th>batch_size_body</th>\n",
       "      <th>batch_size_head</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>sentence-transformers--all-mpnet-base-v2</td>\n",
       "      <td>mention_text</td>\n",
       "      <td>fold02</td>\n",
       "      <td>3</td>\n",
       "      <td>2026-02-05T10:59:16</td>\n",
       "      <td>2026-02-05T11:00:20</td>\n",
       "      <td>64</td>\n",
       "      <td>(8, 8)</td>\n",
       "      <td>0.003</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.711994</td>\n",
       "      <td>8</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>sentence-transformers--all-mpnet-base-v2</td>\n",
       "      <td>mention_text</td>\n",
       "      <td>fold02</td>\n",
       "      <td>10</td>\n",
       "      <td>2026-02-05T11:07:54</td>\n",
       "      <td>2026-02-05T11:08:58</td>\n",
       "      <td>63</td>\n",
       "      <td>(8, 8)</td>\n",
       "      <td>0.003</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.711994</td>\n",
       "      <td>8</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>sentence-transformers--all-mpnet-base-v2</td>\n",
       "      <td>mention_text</td>\n",
       "      <td>fold02</td>\n",
       "      <td>11</td>\n",
       "      <td>2026-02-05T11:08:58</td>\n",
       "      <td>2026-02-05T11:10:03</td>\n",
       "      <td>65</td>\n",
       "      <td>(8, 8)</td>\n",
       "      <td>0.003</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.711994</td>\n",
       "      <td>8</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>sentence-transformers--all-mpnet-base-v2</td>\n",
       "      <td>mention_text</td>\n",
       "      <td>fold02</td>\n",
       "      <td>12</td>\n",
       "      <td>2026-02-05T11:10:03</td>\n",
       "      <td>2026-02-05T11:11:06</td>\n",
       "      <td>62</td>\n",
       "      <td>(8, 8)</td>\n",
       "      <td>0.003</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.711994</td>\n",
       "      <td>8</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>sentence-transformers--all-mpnet-base-v2</td>\n",
       "      <td>mention_text</td>\n",
       "      <td>fold03</td>\n",
       "      <td>3</td>\n",
       "      <td>2026-02-05T12:40:34</td>\n",
       "      <td>2026-02-05T12:41:39</td>\n",
       "      <td>65</td>\n",
       "      <td>(8, 8)</td>\n",
       "      <td>0.003</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.720238</td>\n",
       "      <td>8</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>sentence-transformers--all-mpnet-base-v2</td>\n",
       "      <td>mention_text</td>\n",
       "      <td>fold05</td>\n",
       "      <td>3</td>\n",
       "      <td>2026-02-05T16:22:05</td>\n",
       "      <td>2026-02-05T16:23:11</td>\n",
       "      <td>66</td>\n",
       "      <td>(8, 8)</td>\n",
       "      <td>0.003</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.702354</td>\n",
       "      <td>8</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>sentence-transformers--all-mpnet-base-v2</td>\n",
       "      <td>mention_text</td>\n",
       "      <td>fold01</td>\n",
       "      <td>3</td>\n",
       "      <td>2026-02-05T08:56:33</td>\n",
       "      <td>2026-02-05T08:57:41</td>\n",
       "      <td>68</td>\n",
       "      <td>(8, 8)</td>\n",
       "      <td>0.003</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.758507</td>\n",
       "      <td>8</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>sentence-transformers--all-mpnet-base-v2</td>\n",
       "      <td>mention_text</td>\n",
       "      <td>fold04</td>\n",
       "      <td>3</td>\n",
       "      <td>2026-02-05T14:28:22</td>\n",
       "      <td>2026-02-05T14:29:45</td>\n",
       "      <td>82</td>\n",
       "      <td>(8, 8)</td>\n",
       "      <td>0.003</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.917398</td>\n",
       "      <td>8</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>sentence-transformers--all-mpnet-base-v2</td>\n",
       "      <td>mention_text</td>\n",
       "      <td>fold04</td>\n",
       "      <td>10</td>\n",
       "      <td>2026-02-05T14:40:08</td>\n",
       "      <td>2026-02-05T14:41:16</td>\n",
       "      <td>68</td>\n",
       "      <td>(8, 8)</td>\n",
       "      <td>0.003</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.917398</td>\n",
       "      <td>8</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>sentence-transformers--all-mpnet-base-v2</td>\n",
       "      <td>mention_text</td>\n",
       "      <td>fold04</td>\n",
       "      <td>11</td>\n",
       "      <td>2026-02-05T14:41:16</td>\n",
       "      <td>2026-02-05T14:42:32</td>\n",
       "      <td>75</td>\n",
       "      <td>(8, 8)</td>\n",
       "      <td>0.003</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.917398</td>\n",
       "      <td>8</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>sentence-transformers--all-mpnet-base-v2</td>\n",
       "      <td>mention_text</td>\n",
       "      <td>fold04</td>\n",
       "      <td>12</td>\n",
       "      <td>2026-02-05T14:42:32</td>\n",
       "      <td>2026-02-05T14:43:45</td>\n",
       "      <td>73</td>\n",
       "      <td>(8, 8)</td>\n",
       "      <td>0.003</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.917398</td>\n",
       "      <td>8</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                       model      strategy    fold  trial_id  \\\n",
       "3   sentence-transformers--all-mpnet-base-v2  mention_text  fold02         3   \n",
       "10  sentence-transformers--all-mpnet-base-v2  mention_text  fold02        10   \n",
       "11  sentence-transformers--all-mpnet-base-v2  mention_text  fold02        11   \n",
       "12  sentence-transformers--all-mpnet-base-v2  mention_text  fold02        12   \n",
       "3   sentence-transformers--all-mpnet-base-v2  mention_text  fold03         3   \n",
       "3   sentence-transformers--all-mpnet-base-v2  mention_text  fold05         3   \n",
       "3   sentence-transformers--all-mpnet-base-v2  mention_text  fold01         3   \n",
       "3   sentence-transformers--all-mpnet-base-v2  mention_text  fold04         3   \n",
       "10  sentence-transformers--all-mpnet-base-v2  mention_text  fold04        10   \n",
       "11  sentence-transformers--all-mpnet-base-v2  mention_text  fold04        11   \n",
       "12  sentence-transformers--all-mpnet-base-v2  mention_text  fold04        12   \n",
       "\n",
       "             started_at          finished_at  duration batch_size  \\\n",
       "3   2026-02-05T10:59:16  2026-02-05T11:00:20        64     (8, 8)   \n",
       "10  2026-02-05T11:07:54  2026-02-05T11:08:58        63     (8, 8)   \n",
       "11  2026-02-05T11:08:58  2026-02-05T11:10:03        65     (8, 8)   \n",
       "12  2026-02-05T11:10:03  2026-02-05T11:11:06        62     (8, 8)   \n",
       "3   2026-02-05T12:40:34  2026-02-05T12:41:39        65     (8, 8)   \n",
       "3   2026-02-05T16:22:05  2026-02-05T16:23:11        66     (8, 8)   \n",
       "3   2026-02-05T08:56:33  2026-02-05T08:57:41        68     (8, 8)   \n",
       "3   2026-02-05T14:28:22  2026-02-05T14:29:45        82     (8, 8)   \n",
       "10  2026-02-05T14:40:08  2026-02-05T14:41:16        68     (8, 8)   \n",
       "11  2026-02-05T14:41:16  2026-02-05T14:42:32        75     (8, 8)   \n",
       "12  2026-02-05T14:42:32  2026-02-05T14:43:45        73     (8, 8)   \n",
       "\n",
       "    head_learning_rate  l2_weight  warmup_proportion        f1  \\\n",
       "3                0.003        0.2                0.1  0.711994   \n",
       "10               0.003        0.2                0.1  0.711994   \n",
       "11               0.003        0.2                0.1  0.711994   \n",
       "12               0.003        0.2                0.1  0.711994   \n",
       "3                0.003        0.2                0.1  0.720238   \n",
       "3                0.003        0.2                0.1  0.702354   \n",
       "3                0.003        0.2                0.1  0.758507   \n",
       "3                0.003        0.2                0.1  0.917398   \n",
       "10               0.003        0.2                0.1  0.917398   \n",
       "11               0.003        0.2                0.1  0.917398   \n",
       "12               0.003        0.2                0.1  0.917398   \n",
       "\n",
       "    batch_size_body  batch_size_head  \n",
       "3                 8                8  \n",
       "10                8                8  \n",
       "11                8                8  \n",
       "12                8                8  \n",
       "3                 8                8  \n",
       "3                 8                8  \n",
       "3                 8                8  \n",
       "3                 8                8  \n",
       "10                8                8  \n",
       "11                8                8  \n",
       "12                8                8  "
      ]
     },
     "execution_count": 133,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trial_results[['batch_size_body', 'batch_size_head']] = trial_results.batch_size.apply(lambda x: eval(x) if isinstance(x, str) else x).apply(pd.Series)\n",
    "trial_results.query(\"\"\"\\\n",
    "    model == \"sentence-transformers--all-mpnet-base-v2\" and \\\n",
    "    batch_size_body == 8 and batch_size_head == 8 and \\\n",
    "    head_learning_rate == 0.003 and \\\n",
    "    l2_weight == 0.200 and \\\n",
    "    warmup_proportion == 0.10 \\\n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "660b1cfd",
   "metadata": {},
   "source": [
    "#### Model evaluation\n",
    "\n",
    "::: {.callout-tip title=\"model selection\"}\n",
    "\n",
    "I also checked aveage results for `nomic-ai--modernbert-embed-base` but the score rpeorted above is a n outlier -- `sentence-transformers--all-mpnet-base-v2` performs more consistently across categories and folds.\n",
    "\n",
    "::: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "id": "ba580369",
   "metadata": {},
   "outputs": [],
   "source": [
    "# model = \"nomic-ai--modernbert-embed-base\"\n",
    "model = \"sentence-transformers--all-mpnet-base-v2\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50593eab",
   "metadata": {},
   "outputs": [],
   "source": [
    "results_dir = results_path / task / STEP / \"setfit\" / model\n",
    "\n",
    "df = pd.concat({\n",
    "    fp.parts[-5:-1]: pd.read_json(fp).T.reset_index(level=0, names=\"what\") \n",
    "    for fp in results_dir.glob(\"**/eval_results.json\")\n",
    "})\n",
    "df.reset_index(level=[0,1,2,3], names=[\"method\", \"model_name\", \"strategy\", \"fold\"], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "id": "90ec42aa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "what\n",
       "education                        0.942±0.089\n",
       "occupation/profession            0.787±0.107\n",
       "income/wealth/economic status    0.751±0.093\n",
       "employment status                0.721±0.151\n",
       "dtype: object"
      ]
     },
     "execution_count": 141,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "metrics = [\"weighted avg\", \"macro avg\", \"micro avg\", \"samples avg\"]\n",
    "pdat = df.query(\"what not in @metrics\").copy()\n",
    "pdat[\"what\"] = pdat[\"what\"]\\\n",
    "    .str.replace(\"economic__\", \"\")\\\n",
    "    .str.replace(\"_status\", \" status\")\\\n",
    "    .str.replace(\"_level\", \"\")\\\n",
    "    .str.replace(\"_\", \"/\")\n",
    "\n",
    "pdat.groupby(\"what\")[\"f1-score\"].agg(['mean', 'std']).sort_values('mean', ascending=False).apply(lambda x: f\"{x['mean']:.3f}±{x['std']:.3f}\", axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "3bb544aa",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_2500622/1071733072.py:13: UserWarning: \n",
      "\n",
      "The `scale` parameter is deprecated and will be removed in v0.15.0. You can now control the size of each plot element using matplotlib `Line2D` parameters (e.g., `linewidth`, `markersize`, etc.).\n",
      "\n",
      "  sns.pointplot(\n",
      "/tmp/ipykernel_2500622/1071733072.py:13: FutureWarning: \n",
      "\n",
      "The `errwidth` parameter is deprecated. And will be removed in v0.15.0. Pass `err_kws={'linewidth': 1}` instead.\n",
      "\n",
      "  sns.pointplot(\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 400x300 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "pdat = pdat.melt(id_vars=[\"what\", \"fold\"], value_vars=[\"precision\", \"recall\", \"f1-score\"], var_name=\"metric\", value_name=\"value\")\n",
    "\n",
    "plt.figure(figsize=(4, 3))\n",
    "\n",
    "# add grey horizontal stripes at alternating y positions\n",
    "for i in range(pdat.what.nunique()):\n",
    "    if i % 2 == 0:\n",
    "        plt.gca().axhspan(i - 0.5, i + 0.5, color='gray', alpha=0.1, zorder=0, linewidth=0)\n",
    "\n",
    "ls = '-' # (0, (5, 10))\n",
    "plt.grid(axis=\"x\", which='major', linestyle=ls,  linewidth=0.25, color='gray', alpha=0.5)\n",
    "\n",
    "sns.pointplot(\n",
    "    data=pdat,\n",
    "    y=\"what\",\n",
    "    x=\"value\",\n",
    "\n",
    "    hue=\"metric\",\n",
    "    dodge=1/3,\n",
    "    #color='black',\n",
    "    \n",
    "    linestyles='none',\n",
    "    scale=2/3,\n",
    "    errwidth=1,\n",
    "    # markersize=3,\n",
    "\n",
    "    errorbar='ci',\n",
    "    # capsize=.05,\n",
    "    # err_kws={'linewidth': .75},\n",
    "\n",
    "    # legend=False,\n",
    "    seed=42\n",
    ")\n",
    "# add bold title and labels\n",
    "# plt.title(metric, fontweight='bold')\n",
    "plt.xlabel(\"score\")\n",
    "plt.ylabel(\"\")\n",
    "plt.xlim(-0.01, 1.01)\n",
    "plt.xticks(np.arange(0, 1.1, 0.1))\n",
    "\n",
    "# place legend below plot\n",
    "plt.legend(title=None, bbox_to_anchor=(0.5, +1.2), loc='upper center', ncol=3, frameon=False)\n",
    "# plt.tight_layout()\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c97b7c59",
   "metadata": {},
   "source": [
    "#### Error analysis\n",
    "\n",
    "- get predicted labels for val sets of different folds\n",
    "- compute misclassification rates across models and strategies\n",
    "- review mis-classified instances"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "1df184aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "key_cols = ['fold', 'mention_id', 'text', 'mention', 'span']\n",
    "\n",
    "preds_df = pd.concat({\n",
    "    fp.parts[-4:-1]: pd.read_pickle(fp)\n",
    "    for fp in results_dir.glob(\"**/eval_predictions.pkl\")\n",
    "})\n",
    "preds_df.reset_index(level=[0,1,2], names=[\"model_name\", \"strategy\", \"fold\"], inplace=True)\n",
    "# get index of column \"span\"\n",
    "i = preds_df.columns.get_loc(\"span\")\n",
    "key_cols = preds_df.columns[:i+1]\n",
    "preds_df_long = preds_df.melt(id_vars=key_cols, var_name=\"attribute\", value_name=\"value\")\n",
    "\n",
    "preds_df_long['what'] = preds_df_long['attribute'].str.extract('^(prob|pred|error)_.+$')\n",
    "preds_df_long.loc[preds_df_long['what'].isnull(), 'what'] = 'label'\n",
    "preds_df_long['attribute'] = preds_df_long['attribute'].str.replace('^(prob|pred|error)_', '', regex=True)\n",
    "\n",
    "preds_df = preds_df_long.pivot(index=[*key_cols, 'attribute'], columns='what', values='value').reset_index()\n",
    "preds_df.columns.name = None\n",
    "\n",
    "preds_df['label'] = preds_df['label'].astype(int)\n",
    "preds_df['pred'] = preds_df['pred'].astype(int)\n",
    "preds_df['prob'] = preds_df['prob'].astype(float)\n",
    "preds_df['error'] = preds_df['error'].astype(bool)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "095cd09c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# compute error rate\n",
    "id_cols = ['mention_id', 'text', 'mention', 'span', 'attribute', 'label']\n",
    "error_rates_df = preds_df.groupby(id_cols, observed=False).agg({'error': 'mean'}).reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "3fbef4ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "error_rates_df.sort_values('error', ascending=False, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "4e1121fd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1meconomic__education_level\u001b[0m\n",
      "  ~> \u001b[1m\u001b[3mfalse positives\u001b[0m\n",
      "\n",
      "  ~> \u001b[1m\u001b[3mfalse negatives\u001b[0m\n",
      "  -  14110_201904-203887-1 (1.00):  \u001b[30m\u001b[43mPeople who are not well\u001b[0m, especially boys, are getting worse.\n",
      "  -  11110_200209-393006-1 (1.00):  \u001b[30m\u001b[43mStudents with children\u001b[0m have great difficulties bringing the economy together.\n",
      "  -  53110_199706-276868-1 (1.00):  6. A reduction of the maximum size of the larger second-level schools to between 350 and 500 \u001b[30m\u001b[43mpupils\u001b[0m.\n",
      "\n",
      "\u001b[1meconomic__employment_status\u001b[0m\n",
      "  ~> \u001b[1m\u001b[3mfalse positives\u001b[0m\n",
      "  -  92436_200509-360693-2 (1.00):  It is necessary to expand the lustration, to disclose all peer-related special services officers and \u001b[30m\u001b[43msecret collaborators\u001b[0m.\n",
      "  -   62110_201510-97858-2 (1.00):  Canadians are a \u001b[30m\u001b[43mpeople united by cooperation, hard work, and mutual respect\u001b[0m.\n",
      "  -   43110_198710-98339-1 (1.00):  In the face of any ideological differences, promoting the cooperation of \u001b[30m\u001b[43mall the green forces\u001b[0m is our primary concern.\n",
      "  -  31110_201206-217612-1 (1.00):  Careers of \u001b[30m\u001b[43mcultural workers\u001b[0m and French foreign language teachers.\n",
      "  -  51320_200106-231303-1 (1.00):  \u001b[30m\u001b[43mFrontline staff\u001b[0m are advocates for citizens, and ambassadors for their services.\n",
      "  -  41521_198010-121766-1 (1.00):  In \u001b[30m\u001b[43man anonymous, work-sharing society\u001b[0m, the family is the place where trust, tolerance and fulfillment of duties can be learned and lived.\n",
      "  -  41953_201709-171044-2 (1.00):  Today’s children are \u001b[30m\u001b[43mthe potential contributors of tomorrow\u001b[0m.\n",
      "  -  53110_199706-276868-1 (1.00):  6. A reduction of the maximum size of the larger second-level schools to between 350 and 500 \u001b[30m\u001b[43mpupils\u001b[0m.\n",
      "  -  11110_199109-390936-1 (1.00):  \u001b[30m\u001b[43mThose that deal with life and our right to love, feel and have time left for anything other than paid work\u001b[0m.\n",
      "\n",
      "  ~> \u001b[1m\u001b[3mfalse negatives\u001b[0m\n",
      "  -  53110_198906-276143-2 (1.00):  Any negative effects deriving from people leaving the labour force would be balanced by \u001b[30m\u001b[43mthose joining it\u001b[0m.\n",
      "  -  13229_200109-191846-1 (1.00):  In this way, \u001b[30m\u001b[43meach pensioner\u001b[0m will be paid exactly the same pension he would otherwise have received.\n",
      "  -  92436_200109-360301-1 (1.00):  \u001b[30m\u001b[43mPeople who started with goods carried across the border in suitcases and from field beds on the streets, from small consulting firms and service workshops, gradually built shops, wholesalers, factories, corporations and today give jobs to dozens of people: workers\u001b[0m.\n",
      "  -  92436_200509-360923-2 (1.00):  improvement of the quality of life of Poles, especially of \u001b[30m\u001b[43mpensioners\u001b[0m and other vulnerable social groups.\n",
      "  -  22110_200301-320182-1 (1.00):  Not just from anonymous cameras, but from \u001b[30m\u001b[43mthe people who live and work there\u001b[0m.\n",
      "  -  41953_201709-171077-1 (1.00):  This is a depreciation of \u001b[30m\u001b[43mthe long-term contributors\u001b[0m.\n",
      "  -  13230_201109-192881-2 (1.00):  And will it be fair if the wealthiest contribute a little more so \u001b[30m\u001b[43mpensioners\u001b[0m can get a little more money each month?\n",
      "  -  13230_198112-182709-1 (1.00):  \u001b[30m\u001b[43mThose who are now referred to living from public income transfers\u001b[0m must have improved their income.\n",
      "  -  41953_202109-180606-1 (1.00):  This is a depreciation of \u001b[30m\u001b[43mthe long-term contributors\u001b[0m.\n",
      "\n",
      "\u001b[1meconomic__income_wealth_economic_status\u001b[0m\n",
      "  ~> \u001b[1m\u001b[3mfalse positives\u001b[0m\n",
      "  -   42420_198611-04499-2 (1.00):  The main objective of freedom policy for persons with disabilities is the integration of \u001b[30m\u001b[43mthose concerned\u001b[0m into the community through active participation in social life.\n",
      "  -  51320_201912-249581-1 (1.00):  Labour will end the scandal of leasehold for \u001b[30m\u001b[43mthe millions who have bought their home but don't feel like they own it\u001b[0m.\n",
      "  -   21112_198712-29548-2 (1.00):  Seniors are \u001b[30m\u001b[43mpeople who are rich in experience precisely because of their advanced age\u001b[0m.\n",
      "  -  14110_201904-203800-1 (1.00):  Involve all \u001b[30m\u001b[43mstakeholders in society\u001b[0m: workers, industry, civil society.\n",
      "  -  11110_201809-399481-1 (1.00):  \u001b[30m\u001b[43mA society where wealth is not measured in consumption but in having time for yourself and each other\u001b[0m.\n",
      "\n",
      "  ~> \u001b[1m\u001b[3mfalse negatives\u001b[0m\n",
      "  -  93711_199611-377332-2 (1.00):  Emergency granting of land ownership titles to all entitled persons, including \u001b[30m\u001b[43mshareholders in state-owned commercial companies\u001b[0m, by the end of 1997.\n",
      "  -  51320_201706-244572-1 (1.00):  Too many \u001b[30m\u001b[43mordinary people\u001b[0m know this.\n",
      "  -  86110_201004-262708-1 (1.00):  \u001b[30m\u001b[43mThose who are able to live independently\u001b[0m should be helped by the community.\n",
      "  -  41320_197211-118594-1 (1.00):  \u001b[30m\u001b[43mChildren in homeless settlements\u001b[0m and children from other marginalized groups.\n",
      "  -  13951_197702-181934-1 (1.00):  The tax system has ended up in an unparalleled bureaucracy, where it is not uncommon for \u001b[30m\u001b[43mordinary people\u001b[0m to seek accountant assistance to fill out their self-statement.\n",
      "  -  13229_199803-187861-3 (1.00):  Far from the public light, few people in the business world and in the political systems of both Denmark and the EU make decisions that have far-reaching implications for society and the everyday lives of \u001b[30m\u001b[43mordinary people\u001b[0m.\n",
      "  -  64110_201409-352805-4 (1.00):  By putting children first, and choosing to ensure every child has enough to thrive, New Zealand can design its economy to work for everyone, not just \u001b[30m\u001b[43ma few\u001b[0m.\n",
      "  -  51620_199204-227297-3 (1.00):  Companies which looked inwards to Whitehall are now listening to their customers and \u001b[30m\u001b[43mshareholders\u001b[0m.\n",
      "  -  86710_201804-275232-1 (1.00):  The tax would also cover \u001b[30m\u001b[43mthe individual concerned\u001b[0m and the assets of its business entities.\n",
      "  -  14820_197509-197462-1 (1.00):  A real support for \u001b[30m\u001b[43mordinary people\u001b[0m.\n",
      "  -  86710_201404-270610-2 (1.00):  Together, these companies have deceived the majority of \u001b[30m\u001b[43mthose involved in the currency lending trap\u001b[0m.\n",
      "  -  22110_200611-321808-1 (1.00):  \u001b[30m\u001b[43mPeople who are looking for their own home for the first time\u001b[0m.\n",
      "  -  53110_199211-276467-1 (1.00):  The State should provide credit and training to \u001b[30m\u001b[43mlandless people who wish to enter agriculture\u001b[0m.\n",
      "  -  51320_197006-219018-1 (1.00):  Until Labour came to power, \u001b[30m\u001b[43mthose living off capital gains or land profits\u001b[0m were allowed to substantially escape the net of taxation.\n",
      "  -  64110_201709-358728-2 (1.00):  Students are \u001b[30m\u001b[43mthe only group in society expected to borrow just to get by\u001b[0m.\n",
      "  - 171101_201207-307846-2 (1.00):  Everything seems to indicate that the benefits of globalization and trade opening are distributed very unequally among individuals, \u001b[30m\u001b[43msocial classes\u001b[0m and geographical regions.\n",
      "  -  53110_200705-277992-1 (1.00):  Increasing prices are a major problem for \u001b[30m\u001b[43myoung homebuyers\u001b[0m and those who need to move to larger homes.\n",
      "  -   43951_199110-99020-1 (1.00):  Improvements in the AHV must benefit especially \u001b[30m\u001b[43mthose groups of people who do not yet have a pension fund\u001b[0m.\n",
      "  -  51320_199204-226480-1 (1.00):  We will set new targets to cut the inequalities in health between \u001b[30m\u001b[43msocial classes\u001b[0m and ethnic groups.\n",
      "\n",
      "\u001b[1meconomic__occupation_profession\u001b[0m\n",
      "  ~> \u001b[1m\u001b[3mfalse positives\u001b[0m\n",
      "  -  41320_197610-119535-2 (1.00):  This is what today’s pensioners and \u001b[30m\u001b[43mthe working generation\u001b[0m can expect in the future.\n",
      "  -  93711_199611-377332-2 (1.00):  Emergency granting of land ownership titles to all entitled persons, including \u001b[30m\u001b[43mshareholders in state-owned commercial companies\u001b[0m, by the end of 1997.\n",
      "  -  61620_198411-412422-1 (1.00):  Republicans put the needs of \u001b[30m\u001b[43mpeople at the center of environmental concerns\u001b[0m.\n",
      "  -   21914_198510-27676-1 (1.00):  \u001b[30m\u001b[43mGenerations of Flemish fighters\u001b[0m have not given the best of themselves so that Flanders would soon become another American protectorate, or be condemned to another island in the Goel archipelago.\n",
      "  -  31720_200206-209343-1 (1.00):  \u001b[30m\u001b[43mForeign political agitators acting under the cover of Islam\u001b[0m will be expelled without weakness.\n",
      "  -  15111_199905-280303-1 (1.00):  The leftist movement - green supply wants to apply for the development of \u001b[30m\u001b[43mthe 4 / 1 workforce\u001b[0m towards increased diversity and benefit from environmentally-friendly technologies.\n",
      "  -  43810_201910-108133-1 (1.00):  Two-thirds of \u001b[30m\u001b[43mSwiss employees\u001b[0m are employed in SMEs.\n",
      "  -  41320_199012-128021-1 (1.00):  \u001b[30m\u001b[43mThose who want to solve the major transnational challenges\u001b[0m, such as environmental protection, need a strong Europe.\n",
      "  -  43110_201510-105403-1 (1.00):  The Greens demand that \u001b[30m\u001b[43mthe multinationals based in Switzerland\u001b[0m assume their responsibility for sustainable global development according to their size and do not go into their own pockets.\n",
      "  -  92436_200509-360693-2 (1.00):  It is necessary to expand the lustration, to disclose all peer-related special services officers and \u001b[30m\u001b[43msecret collaborators\u001b[0m.\n",
      "  -  92436_200509-360923-2 (1.00):  improvement of the quality of life of Poles, especially of \u001b[30m\u001b[43mpensioners\u001b[0m and other vulnerable social groups.\n",
      "  -  11710_201809-401265-1 (1.00):  \u001b[30m\u001b[43mThose who live and operate in our suburbs\u001b[0m get their shops robbed, destroyed or taken over by criminals.\n",
      "  -  22110_199805-315887-1 (1.00):  \u001b[30m\u001b[43mHigher vocational education students\u001b[0m are entitled to the OV student card.\n",
      "  -   42420_200211-11355-2 (1.00):  Without such a restriction on the free movement of workers, Austria would have been affected by a massive immigration and professional donation migration due to the strong wage differences and, consequently, by a significant increase in the shortage of Pushcher, which would have led to a competition for displacement, i.e. a massive increase in the unemployment of \u001b[30m\u001b[43mdomestic workers\u001b[0m.\n",
      "  -  86710_201404-270610-2 (1.00):  Together, these companies have deceived the majority of \u001b[30m\u001b[43mthose involved in the currency lending trap\u001b[0m.\n",
      "  -  41112_199012-127111-2 (1.00):  Their clients are \u001b[30m\u001b[43mmen from all walks of life and professions\u001b[0m.\n",
      "  -  13230_201109-192881-2 (1.00):  And will it be fair if the wealthiest contribute a little more so \u001b[30m\u001b[43mpensioners\u001b[0m can get a little more money each month?\n",
      "  -   21111_200706-60109-2 (1.00):  Failure first affects students from disadvantaged socioeconomic backgrounds, as well as \u001b[30m\u001b[43mthose attending technical and professional education\u001b[0m.\n",
      "\n",
      "  ~> \u001b[1m\u001b[3mfalse negatives\u001b[0m\n",
      "  -  12951_200909-340654-5 (1.00):  ensure that cases with known perpetrators are not laid down, if necessary by using private services that police and \u001b[30m\u001b[43mprosecutors\u001b[0m in individual cases shall exercise their duties independently of the government and that police and \u001b[30m\u001b[43mprosecutors\u001b[0m shall be clearly separated from each other in order to independence and the best possible legal security\n",
      "  -  14110_200303-198344-1 (1.00):  The new jobs in the industry that appear in the statistics are not \u001b[30m\u001b[43mfactory dounars\u001b[0m, but designers, marketers and other well-trained white-collar people working at the office desk.\n",
      "  -  41113_200909-147282-2 (1.00):  Be it developers of computer games, \u001b[30m\u001b[43moperators of internet portals\u001b[0m or bloggers who want to make their vocation a profession.\n",
      "  -  22110_201006-322802-1 (1.00):  From \u001b[30m\u001b[43mshareholders and managers who merely measure the performance of companies to the short-term profit\u001b[0m.\n",
      "  -  13951_198709-183660-1 (1.00):  When \u001b[30m\u001b[43mpeople from the useful professions\u001b[0m act like this, it goes beyond themselves.\n",
      "  -  93712_199209-377150-1 (1.00):  Between different \u001b[30m\u001b[43msocial and professional categories\u001b[0m, between generations, hostile theses with territorial claims are being brought to the surface, and step by step, through a whole arsenal of means, the dismemberment of Romania is sought.\n",
      "  -  43810_200310-100870-2 (1.00):  As developments in other countries show, it makes no sense to unilaterally promote a particular \u001b[30m\u001b[43meducation or vocational group\u001b[0m or to play out vocational training against university education.\n",
      "  -  13229_200111-188337-2 (1.00):  Everyday racism must be combated at workplaces, in residential neighborhoods, in trade unions and also in the Parliament, where \u001b[30m\u001b[43mbourgeois and social democratic politicians\u001b[0m daily feed the inner pig dog.\n",
      "  -  93712_199611-377435-1 (1.00):  Within these forms of agricultural exploitation (practiced also in Western Countries), \u001b[30m\u001b[43mthe peasants\u001b[0m remain owners of the land with which they have entered into association.\n",
      "  -  13951_197501-181621-1 (1.00):  This is in the interests of both \u001b[30m\u001b[43mworkers\u001b[0m and employers.\n",
      "  -  31110_201206-217726-1 (1.00):  The President of the Sixth Republic will not participate directly in government tasks, he will not submit any text to a referendum, he will not appoint any \u001b[30m\u001b[43mcivil and military officials\u001b[0m, he will not ensure any budgetary arbitration, he will not participate in the negotiation of international treaties.\n",
      "  -  31110_201206-217612-1 (1.00):  Careers of \u001b[30m\u001b[43mcultural workers\u001b[0m and French foreign language teachers.\n",
      "  -  51320_201912-249608-1 (1.00):  The Labour Party was founded to give \u001b[30m\u001b[43mworking-class people\u001b[0m a voice in politics.\n",
      "  -  51620_200505-235254-2 (1.00):  Small community hospitals which have the support of local patients and \u001b[30m\u001b[43mGPs\u001b[0m will not be closed by bureaucrats.\n",
      "  -  14110_200303-198345-2 (1.00):  The service industries can better employ \u001b[30m\u001b[43mpeople who are not specialized in industry-leading professions\u001b[0m.\n",
      "  -  14110_201904-203808-1 (1.00):  Make a plan to support different sectors and \u001b[30m\u001b[43mgroups of people in their transition from the fossil economy\u001b[0m.\n",
      "  -   42420_201710-19463-1 (1.00):  Improve the compatibility of work and family through the expansion of childcare places and a professional image for \u001b[30m\u001b[43mdaymothers\u001b[0m\n",
      "  -  35110_198707-372282-2 (1.00):  We do not even exist to repeat in green the old vices of parties that have been spent on the distance between those who support them and\u001b[30m\u001b[43m those who lead them\u001b[0m, specialized in promising now and denying later, in seducing and disappointing, in making power at the expense of intrigue and money (preferably the State).\n",
      "  -   21914_199906-50888-1 (1.00):  Many of \u001b[30m\u001b[43mthe exotic self-employed\u001b[0m are also a market disturbing element.\n",
      "  -  51620_197410-221827-1 (1.00):  The new Conservative government will strengthen the police force, \u001b[30m\u001b[43mour principal defenders against internal attack\u001b[0m.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "highlight = lambda text, mention: text.replace(mention, '\\u001B[30m\\u001B[43m'+mention+'\\033[0m')\n",
    "\n",
    "threshold = 1/3\n",
    "label_id_2_error_type = {0: 'false positives', 1: 'false negatives'}\n",
    "for a, tmp in error_rates_df.groupby('attribute'):\n",
    "    print(f\"\\033[1m{a}\\033[0m\")\n",
    "    for l, subdf in tmp.groupby('label'):\n",
    "        # print attribute name in bold\n",
    "        print(f\"  ~> \\033[1m\\033[3m{label_id_2_error_type[l]}\\033[0m\")\n",
    "        for i, row in subdf[subdf['error'] > threshold].head(20).iterrows():\n",
    "            highlighted_text = highlight(row['text'], row['mention'])\n",
    "            print(f\"  - {row['mention_id'].rjust(22)} ({row['error']:.2f}):  {highlighted_text}\")\n",
    "        print()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d68e558",
   "metadata": {},
   "source": [
    "### Non-economic attributes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "99b73422",
   "metadata": {},
   "outputs": [],
   "source": [
    "task = \"noneconomic_attributes_classification\"\n",
    "label_classes = [\n",
    "    'noneconomic__age',\n",
    "    'noneconomic__crime',\n",
    "    'noneconomic__ethnicity',\n",
    "    'noneconomic__family',\n",
    "    'noneconomic__gender_sexuality',\n",
    "    'noneconomic__health',\n",
    "    'noneconomic__nationality',\n",
    "    'noneconomic__place_location',\n",
    "    'noneconomic__religion',\n",
    "    'noneconomic__shared_values_mentalities',\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b1eb0508",
   "metadata": {},
   "source": [
    "#### Best hyperparameters?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "55f8a4e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "trial_results_files = list(results_path.glob(f\"{task}/**/{STEP}/**/trial_results.csv\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "48e8c55d",
   "metadata": {},
   "outputs": [],
   "source": [
    "trial_results = pd.concat(\n",
    "    {f.parts[-4:-1]: pd.read_csv(f) for f in trial_results_files},\n",
    ")\n",
    "trial_results.reset_index(level=[0, 1, 2], names=[\"model\", \"strategy\", \"fold\"], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "id": "46e9ee28",
   "metadata": {},
   "outputs": [],
   "source": [
    "trial_results_sum = trial_results.groupby([\"model\", \"strategy\", *varying_hyperparameter_names])[\"f1\"].mean().reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "id": "827b294e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>model</th>\n",
       "      <th>strategy</th>\n",
       "      <th>f1</th>\n",
       "      <th>batch_size</th>\n",
       "      <th>head_learning_rate</th>\n",
       "      <th>l2_weight</th>\n",
       "      <th>warmup_proportion</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>google--embeddinggemma-300m</td>\n",
       "      <td>mention_text</td>\n",
       "      <td>0.607652</td>\n",
       "      <td>(8, 4)</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>0.015</td>\n",
       "      <td>0.10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>nomic-ai--modernbert-embed-base</td>\n",
       "      <td>mention_text</td>\n",
       "      <td>0.858777</td>\n",
       "      <td>(32, 4)</td>\n",
       "      <td>0.0300</td>\n",
       "      <td>0.015</td>\n",
       "      <td>0.15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>sentence-transformers--all-mpnet-base-v2</td>\n",
       "      <td>mention_text</td>\n",
       "      <td>0.797181</td>\n",
       "      <td>(8, 4)</td>\n",
       "      <td>0.0100</td>\n",
       "      <td>0.200</td>\n",
       "      <td>0.10</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                      model      strategy        f1  \\\n",
       "0               google--embeddinggemma-300m  mention_text  0.607652   \n",
       "1           nomic-ai--modernbert-embed-base  mention_text  0.858777   \n",
       "2  sentence-transformers--all-mpnet-base-v2  mention_text  0.797181   \n",
       "\n",
       "  batch_size  head_learning_rate  l2_weight  warmup_proportion  \n",
       "0     (8, 4)              0.0001      0.015               0.10  \n",
       "1    (32, 4)              0.0300      0.015               0.15  \n",
       "2     (8, 4)              0.0100      0.200               0.10  "
      ]
     },
     "execution_count": 107,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# get row with max F1 for each model and strategy\n",
    "trial_results_sum.groupby([\"model\", \"strategy\"])[[\"f1\", *varying_hyperparameter_names]].apply(lambda x: x.loc[x[\"f1\"].idxmax()]).reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "id": "3b410d55",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>model</th>\n",
       "      <th>strategy</th>\n",
       "      <th>batch_size</th>\n",
       "      <th>head_learning_rate</th>\n",
       "      <th>l2_weight</th>\n",
       "      <th>warmup_proportion</th>\n",
       "      <th>f1_mean</th>\n",
       "      <th>f1_std</th>\n",
       "      <th>n</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>nomic-ai--modernbert-embed-base</td>\n",
       "      <td>mention_text</td>\n",
       "      <td>(32, 4)</td>\n",
       "      <td>0.0300</td>\n",
       "      <td>0.015</td>\n",
       "      <td>0.15</td>\n",
       "      <td>0.858777</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>nomic-ai--modernbert-embed-base</td>\n",
       "      <td>mention_text</td>\n",
       "      <td>(32, 8)</td>\n",
       "      <td>0.0300</td>\n",
       "      <td>0.015</td>\n",
       "      <td>0.15</td>\n",
       "      <td>0.816529</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>57</th>\n",
       "      <td>sentence-transformers--all-mpnet-base-v2</td>\n",
       "      <td>mention_text</td>\n",
       "      <td>(8, 4)</td>\n",
       "      <td>0.0100</td>\n",
       "      <td>0.200</td>\n",
       "      <td>0.10</td>\n",
       "      <td>0.797181</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>nomic-ai--modernbert-embed-base</td>\n",
       "      <td>mention_text</td>\n",
       "      <td>(8, 4)</td>\n",
       "      <td>0.0300</td>\n",
       "      <td>0.015</td>\n",
       "      <td>0.10</td>\n",
       "      <td>0.791129</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>52</th>\n",
       "      <td>sentence-transformers--all-mpnet-base-v2</td>\n",
       "      <td>mention_text</td>\n",
       "      <td>(32, 4)</td>\n",
       "      <td>0.0300</td>\n",
       "      <td>0.015</td>\n",
       "      <td>0.15</td>\n",
       "      <td>0.789560</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>51</th>\n",
       "      <td>sentence-transformers--all-mpnet-base-v2</td>\n",
       "      <td>mention_text</td>\n",
       "      <td>(32, 4)</td>\n",
       "      <td>0.0100</td>\n",
       "      <td>0.010</td>\n",
       "      <td>0.15</td>\n",
       "      <td>0.788394</td>\n",
       "      <td>0.035650</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>54</th>\n",
       "      <td>sentence-transformers--all-mpnet-base-v2</td>\n",
       "      <td>mention_text</td>\n",
       "      <td>(32, 8)</td>\n",
       "      <td>0.0100</td>\n",
       "      <td>0.010</td>\n",
       "      <td>0.15</td>\n",
       "      <td>0.781241</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>sentence-transformers--all-mpnet-base-v2</td>\n",
       "      <td>mention_text</td>\n",
       "      <td>(16, 16)</td>\n",
       "      <td>0.0030</td>\n",
       "      <td>0.010</td>\n",
       "      <td>0.10</td>\n",
       "      <td>0.773594</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48</th>\n",
       "      <td>sentence-transformers--all-mpnet-base-v2</td>\n",
       "      <td>mention_text</td>\n",
       "      <td>(16, 8)</td>\n",
       "      <td>0.0100</td>\n",
       "      <td>0.010</td>\n",
       "      <td>0.15</td>\n",
       "      <td>0.768419</td>\n",
       "      <td>0.071974</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>55</th>\n",
       "      <td>sentence-transformers--all-mpnet-base-v2</td>\n",
       "      <td>mention_text</td>\n",
       "      <td>(32, 8)</td>\n",
       "      <td>0.0300</td>\n",
       "      <td>0.015</td>\n",
       "      <td>0.10</td>\n",
       "      <td>0.766632</td>\n",
       "      <td>0.060566</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50</th>\n",
       "      <td>sentence-transformers--all-mpnet-base-v2</td>\n",
       "      <td>mention_text</td>\n",
       "      <td>(32, 16)</td>\n",
       "      <td>0.0300</td>\n",
       "      <td>0.015</td>\n",
       "      <td>0.10</td>\n",
       "      <td>0.766551</td>\n",
       "      <td>0.048787</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>nomic-ai--modernbert-embed-base</td>\n",
       "      <td>mention_text</td>\n",
       "      <td>(16, 16)</td>\n",
       "      <td>0.0300</td>\n",
       "      <td>0.015</td>\n",
       "      <td>0.10</td>\n",
       "      <td>0.763550</td>\n",
       "      <td>0.015880</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>nomic-ai--modernbert-embed-base</td>\n",
       "      <td>mention_text</td>\n",
       "      <td>(16, 8)</td>\n",
       "      <td>0.0100</td>\n",
       "      <td>0.010</td>\n",
       "      <td>0.15</td>\n",
       "      <td>0.762645</td>\n",
       "      <td>0.047355</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>nomic-ai--modernbert-embed-base</td>\n",
       "      <td>mention_text</td>\n",
       "      <td>(32, 4)</td>\n",
       "      <td>0.0100</td>\n",
       "      <td>0.010</td>\n",
       "      <td>0.15</td>\n",
       "      <td>0.753004</td>\n",
       "      <td>0.059950</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>58</th>\n",
       "      <td>sentence-transformers--all-mpnet-base-v2</td>\n",
       "      <td>mention_text</td>\n",
       "      <td>(8, 8)</td>\n",
       "      <td>0.0030</td>\n",
       "      <td>0.010</td>\n",
       "      <td>0.15</td>\n",
       "      <td>0.752386</td>\n",
       "      <td>0.045747</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45</th>\n",
       "      <td>sentence-transformers--all-mpnet-base-v2</td>\n",
       "      <td>mention_text</td>\n",
       "      <td>(16, 16)</td>\n",
       "      <td>0.0300</td>\n",
       "      <td>0.015</td>\n",
       "      <td>0.10</td>\n",
       "      <td>0.751272</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>nomic-ai--modernbert-embed-base</td>\n",
       "      <td>mention_text</td>\n",
       "      <td>(8, 16)</td>\n",
       "      <td>0.0100</td>\n",
       "      <td>0.010</td>\n",
       "      <td>0.15</td>\n",
       "      <td>0.749536</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>nomic-ai--modernbert-embed-base</td>\n",
       "      <td>mention_text</td>\n",
       "      <td>(32, 8)</td>\n",
       "      <td>0.0300</td>\n",
       "      <td>0.015</td>\n",
       "      <td>0.10</td>\n",
       "      <td>0.746934</td>\n",
       "      <td>0.058429</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47</th>\n",
       "      <td>sentence-transformers--all-mpnet-base-v2</td>\n",
       "      <td>mention_text</td>\n",
       "      <td>(16, 8)</td>\n",
       "      <td>0.0030</td>\n",
       "      <td>0.015</td>\n",
       "      <td>0.15</td>\n",
       "      <td>0.746675</td>\n",
       "      <td>0.050254</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>nomic-ai--modernbert-embed-base</td>\n",
       "      <td>mention_text</td>\n",
       "      <td>(16, 16)</td>\n",
       "      <td>0.0100</td>\n",
       "      <td>0.010</td>\n",
       "      <td>0.15</td>\n",
       "      <td>0.737458</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49</th>\n",
       "      <td>sentence-transformers--all-mpnet-base-v2</td>\n",
       "      <td>mention_text</td>\n",
       "      <td>(32, 16)</td>\n",
       "      <td>0.0030</td>\n",
       "      <td>0.010</td>\n",
       "      <td>0.10</td>\n",
       "      <td>0.735710</td>\n",
       "      <td>0.106044</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>56</th>\n",
       "      <td>sentence-transformers--all-mpnet-base-v2</td>\n",
       "      <td>mention_text</td>\n",
       "      <td>(8, 16)</td>\n",
       "      <td>0.0100</td>\n",
       "      <td>0.010</td>\n",
       "      <td>0.15</td>\n",
       "      <td>0.730965</td>\n",
       "      <td>0.060402</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>nomic-ai--modernbert-embed-base</td>\n",
       "      <td>mention_text</td>\n",
       "      <td>(16, 16)</td>\n",
       "      <td>0.0030</td>\n",
       "      <td>0.015</td>\n",
       "      <td>0.15</td>\n",
       "      <td>0.729825</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>nomic-ai--modernbert-embed-base</td>\n",
       "      <td>mention_text</td>\n",
       "      <td>(32, 16)</td>\n",
       "      <td>0.0300</td>\n",
       "      <td>0.015</td>\n",
       "      <td>0.10</td>\n",
       "      <td>0.729383</td>\n",
       "      <td>0.064267</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46</th>\n",
       "      <td>sentence-transformers--all-mpnet-base-v2</td>\n",
       "      <td>mention_text</td>\n",
       "      <td>(16, 4)</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>0.015</td>\n",
       "      <td>0.10</td>\n",
       "      <td>0.725357</td>\n",
       "      <td>0.051200</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44</th>\n",
       "      <td>sentence-transformers--all-mpnet-base-v2</td>\n",
       "      <td>mention_text</td>\n",
       "      <td>(16, 16)</td>\n",
       "      <td>0.0100</td>\n",
       "      <td>0.010</td>\n",
       "      <td>0.15</td>\n",
       "      <td>0.710991</td>\n",
       "      <td>0.092296</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>nomic-ai--modernbert-embed-base</td>\n",
       "      <td>mention_text</td>\n",
       "      <td>(8, 8)</td>\n",
       "      <td>0.0030</td>\n",
       "      <td>0.010</td>\n",
       "      <td>0.15</td>\n",
       "      <td>0.694607</td>\n",
       "      <td>0.061100</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>nomic-ai--modernbert-embed-base</td>\n",
       "      <td>mention_text</td>\n",
       "      <td>(16, 16)</td>\n",
       "      <td>0.0030</td>\n",
       "      <td>0.010</td>\n",
       "      <td>0.15</td>\n",
       "      <td>0.677205</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>nomic-ai--modernbert-embed-base</td>\n",
       "      <td>mention_text</td>\n",
       "      <td>(16, 8)</td>\n",
       "      <td>0.0030</td>\n",
       "      <td>0.015</td>\n",
       "      <td>0.15</td>\n",
       "      <td>0.666012</td>\n",
       "      <td>0.164679</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>nomic-ai--modernbert-embed-base</td>\n",
       "      <td>mention_text</td>\n",
       "      <td>(32, 16)</td>\n",
       "      <td>0.0030</td>\n",
       "      <td>0.010</td>\n",
       "      <td>0.10</td>\n",
       "      <td>0.658000</td>\n",
       "      <td>0.043750</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>nomic-ai--modernbert-embed-base</td>\n",
       "      <td>mention_text</td>\n",
       "      <td>(16, 4)</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>0.015</td>\n",
       "      <td>0.10</td>\n",
       "      <td>0.651555</td>\n",
       "      <td>0.054245</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>nomic-ai--modernbert-embed-base</td>\n",
       "      <td>mention_text</td>\n",
       "      <td>(8, 16)</td>\n",
       "      <td>0.0030</td>\n",
       "      <td>0.010</td>\n",
       "      <td>0.15</td>\n",
       "      <td>0.639356</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>nomic-ai--modernbert-embed-base</td>\n",
       "      <td>mention_text</td>\n",
       "      <td>(8, 16)</td>\n",
       "      <td>0.0030</td>\n",
       "      <td>0.015</td>\n",
       "      <td>0.15</td>\n",
       "      <td>0.637501</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>google--embeddinggemma-300m</td>\n",
       "      <td>mention_text</td>\n",
       "      <td>(8, 4)</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>0.015</td>\n",
       "      <td>0.10</td>\n",
       "      <td>0.607652</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>nomic-ai--modernbert-embed-base</td>\n",
       "      <td>mention_text</td>\n",
       "      <td>(8, 8)</td>\n",
       "      <td>0.0030</td>\n",
       "      <td>0.200</td>\n",
       "      <td>0.10</td>\n",
       "      <td>0.589712</td>\n",
       "      <td>0.217036</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>nomic-ai--modernbert-embed-base</td>\n",
       "      <td>mention_text</td>\n",
       "      <td>(32, 8)</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>0.200</td>\n",
       "      <td>0.10</td>\n",
       "      <td>0.587786</td>\n",
       "      <td>0.056058</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>59</th>\n",
       "      <td>sentence-transformers--all-mpnet-base-v2</td>\n",
       "      <td>mention_text</td>\n",
       "      <td>(8, 8)</td>\n",
       "      <td>0.0030</td>\n",
       "      <td>0.200</td>\n",
       "      <td>0.10</td>\n",
       "      <td>0.570433</td>\n",
       "      <td>0.326868</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>google--embeddinggemma-300m</td>\n",
       "      <td>mention_text</td>\n",
       "      <td>(8, 8)</td>\n",
       "      <td>0.0100</td>\n",
       "      <td>0.015</td>\n",
       "      <td>0.10</td>\n",
       "      <td>0.551843</td>\n",
       "      <td>0.154634</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>google--embeddinggemma-300m</td>\n",
       "      <td>mention_text</td>\n",
       "      <td>(8, 4)</td>\n",
       "      <td>0.0300</td>\n",
       "      <td>0.200</td>\n",
       "      <td>0.10</td>\n",
       "      <td>0.544892</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>google--embeddinggemma-300m</td>\n",
       "      <td>mention_text</td>\n",
       "      <td>(8, 8)</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>0.015</td>\n",
       "      <td>0.10</td>\n",
       "      <td>0.536183</td>\n",
       "      <td>0.219993</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>53</th>\n",
       "      <td>sentence-transformers--all-mpnet-base-v2</td>\n",
       "      <td>mention_text</td>\n",
       "      <td>(32, 8)</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>0.200</td>\n",
       "      <td>0.10</td>\n",
       "      <td>0.531470</td>\n",
       "      <td>0.298393</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>google--embeddinggemma-300m</td>\n",
       "      <td>mention_text</td>\n",
       "      <td>(16, 4)</td>\n",
       "      <td>0.0300</td>\n",
       "      <td>0.010</td>\n",
       "      <td>0.10</td>\n",
       "      <td>0.526955</td>\n",
       "      <td>0.048991</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>google--embeddinggemma-300m</td>\n",
       "      <td>mention_text</td>\n",
       "      <td>(16, 4)</td>\n",
       "      <td>0.0300</td>\n",
       "      <td>0.015</td>\n",
       "      <td>0.10</td>\n",
       "      <td>0.525590</td>\n",
       "      <td>0.071796</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>google--embeddinggemma-300m</td>\n",
       "      <td>mention_text</td>\n",
       "      <td>(16, 4)</td>\n",
       "      <td>0.0030</td>\n",
       "      <td>0.010</td>\n",
       "      <td>0.10</td>\n",
       "      <td>0.520945</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>google--embeddinggemma-300m</td>\n",
       "      <td>mention_text</td>\n",
       "      <td>(8, 8)</td>\n",
       "      <td>0.0300</td>\n",
       "      <td>0.015</td>\n",
       "      <td>0.10</td>\n",
       "      <td>0.478080</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>google--embeddinggemma-300m</td>\n",
       "      <td>mention_text</td>\n",
       "      <td>(16, 4)</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>0.010</td>\n",
       "      <td>0.15</td>\n",
       "      <td>0.456475</td>\n",
       "      <td>0.131701</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>google--embeddinggemma-300m</td>\n",
       "      <td>mention_text</td>\n",
       "      <td>(16, 4)</td>\n",
       "      <td>0.0100</td>\n",
       "      <td>0.010</td>\n",
       "      <td>0.10</td>\n",
       "      <td>0.442974</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>google--embeddinggemma-300m</td>\n",
       "      <td>mention_text</td>\n",
       "      <td>(8, 4)</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>0.200</td>\n",
       "      <td>0.10</td>\n",
       "      <td>0.438464</td>\n",
       "      <td>0.205208</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>google--embeddinggemma-300m</td>\n",
       "      <td>mention_text</td>\n",
       "      <td>(16, 4)</td>\n",
       "      <td>0.0300</td>\n",
       "      <td>0.200</td>\n",
       "      <td>0.10</td>\n",
       "      <td>0.429460</td>\n",
       "      <td>0.171567</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>google--embeddinggemma-300m</td>\n",
       "      <td>mention_text</td>\n",
       "      <td>(16, 4)</td>\n",
       "      <td>0.0030</td>\n",
       "      <td>0.010</td>\n",
       "      <td>0.15</td>\n",
       "      <td>0.425108</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>google--embeddinggemma-300m</td>\n",
       "      <td>mention_text</td>\n",
       "      <td>(8, 8)</td>\n",
       "      <td>0.0030</td>\n",
       "      <td>0.015</td>\n",
       "      <td>0.10</td>\n",
       "      <td>0.416943</td>\n",
       "      <td>0.192687</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>google--embeddinggemma-300m</td>\n",
       "      <td>mention_text</td>\n",
       "      <td>(8, 8)</td>\n",
       "      <td>0.0300</td>\n",
       "      <td>0.200</td>\n",
       "      <td>0.15</td>\n",
       "      <td>0.372333</td>\n",
       "      <td>0.205309</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>google--embeddinggemma-300m</td>\n",
       "      <td>mention_text</td>\n",
       "      <td>(8, 4)</td>\n",
       "      <td>0.0100</td>\n",
       "      <td>0.010</td>\n",
       "      <td>0.10</td>\n",
       "      <td>0.368151</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>google--embeddinggemma-300m</td>\n",
       "      <td>mention_text</td>\n",
       "      <td>(8, 4)</td>\n",
       "      <td>0.0030</td>\n",
       "      <td>0.010</td>\n",
       "      <td>0.10</td>\n",
       "      <td>0.337506</td>\n",
       "      <td>0.178044</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>google--embeddinggemma-300m</td>\n",
       "      <td>mention_text</td>\n",
       "      <td>(8, 4)</td>\n",
       "      <td>0.0030</td>\n",
       "      <td>0.200</td>\n",
       "      <td>0.10</td>\n",
       "      <td>0.288988</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>google--embeddinggemma-300m</td>\n",
       "      <td>mention_text</td>\n",
       "      <td>(16, 8)</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>0.200</td>\n",
       "      <td>0.15</td>\n",
       "      <td>0.256835</td>\n",
       "      <td>0.190418</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>google--embeddinggemma-300m</td>\n",
       "      <td>mention_text</td>\n",
       "      <td>(16, 8)</td>\n",
       "      <td>0.0100</td>\n",
       "      <td>0.200</td>\n",
       "      <td>0.15</td>\n",
       "      <td>0.226664</td>\n",
       "      <td>0.201640</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>google--embeddinggemma-300m</td>\n",
       "      <td>mention_text</td>\n",
       "      <td>(8, 4)</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>0.010</td>\n",
       "      <td>0.10</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>google--embeddinggemma-300m</td>\n",
       "      <td>mention_text</td>\n",
       "      <td>(8, 8)</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>0.015</td>\n",
       "      <td>0.15</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>google--embeddinggemma-300m</td>\n",
       "      <td>mention_text</td>\n",
       "      <td>(16, 4)</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>0.015</td>\n",
       "      <td>0.10</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                       model      strategy batch_size  \\\n",
       "33           nomic-ai--modernbert-embed-base  mention_text    (32, 4)   \n",
       "36           nomic-ai--modernbert-embed-base  mention_text    (32, 8)   \n",
       "57  sentence-transformers--all-mpnet-base-v2  mention_text     (8, 4)   \n",
       "40           nomic-ai--modernbert-embed-base  mention_text     (8, 4)   \n",
       "52  sentence-transformers--all-mpnet-base-v2  mention_text    (32, 4)   \n",
       "51  sentence-transformers--all-mpnet-base-v2  mention_text    (32, 4)   \n",
       "54  sentence-transformers--all-mpnet-base-v2  mention_text    (32, 8)   \n",
       "43  sentence-transformers--all-mpnet-base-v2  mention_text   (16, 16)   \n",
       "48  sentence-transformers--all-mpnet-base-v2  mention_text    (16, 8)   \n",
       "55  sentence-transformers--all-mpnet-base-v2  mention_text    (32, 8)   \n",
       "50  sentence-transformers--all-mpnet-base-v2  mention_text   (32, 16)   \n",
       "26           nomic-ai--modernbert-embed-base  mention_text   (16, 16)   \n",
       "29           nomic-ai--modernbert-embed-base  mention_text    (16, 8)   \n",
       "32           nomic-ai--modernbert-embed-base  mention_text    (32, 4)   \n",
       "58  sentence-transformers--all-mpnet-base-v2  mention_text     (8, 8)   \n",
       "45  sentence-transformers--all-mpnet-base-v2  mention_text   (16, 16)   \n",
       "39           nomic-ai--modernbert-embed-base  mention_text    (8, 16)   \n",
       "35           nomic-ai--modernbert-embed-base  mention_text    (32, 8)   \n",
       "47  sentence-transformers--all-mpnet-base-v2  mention_text    (16, 8)   \n",
       "25           nomic-ai--modernbert-embed-base  mention_text   (16, 16)   \n",
       "49  sentence-transformers--all-mpnet-base-v2  mention_text   (32, 16)   \n",
       "56  sentence-transformers--all-mpnet-base-v2  mention_text    (8, 16)   \n",
       "24           nomic-ai--modernbert-embed-base  mention_text   (16, 16)   \n",
       "31           nomic-ai--modernbert-embed-base  mention_text   (32, 16)   \n",
       "46  sentence-transformers--all-mpnet-base-v2  mention_text    (16, 4)   \n",
       "44  sentence-transformers--all-mpnet-base-v2  mention_text   (16, 16)   \n",
       "41           nomic-ai--modernbert-embed-base  mention_text     (8, 8)   \n",
       "23           nomic-ai--modernbert-embed-base  mention_text   (16, 16)   \n",
       "28           nomic-ai--modernbert-embed-base  mention_text    (16, 8)   \n",
       "30           nomic-ai--modernbert-embed-base  mention_text   (32, 16)   \n",
       "27           nomic-ai--modernbert-embed-base  mention_text    (16, 4)   \n",
       "37           nomic-ai--modernbert-embed-base  mention_text    (8, 16)   \n",
       "38           nomic-ai--modernbert-embed-base  mention_text    (8, 16)   \n",
       "11               google--embeddinggemma-300m  mention_text     (8, 4)   \n",
       "42           nomic-ai--modernbert-embed-base  mention_text     (8, 8)   \n",
       "34           nomic-ai--modernbert-embed-base  mention_text    (32, 8)   \n",
       "59  sentence-transformers--all-mpnet-base-v2  mention_text     (8, 8)   \n",
       "20               google--embeddinggemma-300m  mention_text     (8, 8)   \n",
       "16               google--embeddinggemma-300m  mention_text     (8, 4)   \n",
       "17               google--embeddinggemma-300m  mention_text     (8, 8)   \n",
       "53  sentence-transformers--all-mpnet-base-v2  mention_text    (32, 8)   \n",
       "5                google--embeddinggemma-300m  mention_text    (16, 4)   \n",
       "6                google--embeddinggemma-300m  mention_text    (16, 4)   \n",
       "2                google--embeddinggemma-300m  mention_text    (16, 4)   \n",
       "21               google--embeddinggemma-300m  mention_text     (8, 8)   \n",
       "0                google--embeddinggemma-300m  mention_text    (16, 4)   \n",
       "4                google--embeddinggemma-300m  mention_text    (16, 4)   \n",
       "12               google--embeddinggemma-300m  mention_text     (8, 4)   \n",
       "7                google--embeddinggemma-300m  mention_text    (16, 4)   \n",
       "3                google--embeddinggemma-300m  mention_text    (16, 4)   \n",
       "19               google--embeddinggemma-300m  mention_text     (8, 8)   \n",
       "22               google--embeddinggemma-300m  mention_text     (8, 8)   \n",
       "15               google--embeddinggemma-300m  mention_text     (8, 4)   \n",
       "13               google--embeddinggemma-300m  mention_text     (8, 4)   \n",
       "14               google--embeddinggemma-300m  mention_text     (8, 4)   \n",
       "8                google--embeddinggemma-300m  mention_text    (16, 8)   \n",
       "9                google--embeddinggemma-300m  mention_text    (16, 8)   \n",
       "10               google--embeddinggemma-300m  mention_text     (8, 4)   \n",
       "18               google--embeddinggemma-300m  mention_text     (8, 8)   \n",
       "1                google--embeddinggemma-300m  mention_text    (16, 4)   \n",
       "\n",
       "    head_learning_rate  l2_weight  warmup_proportion   f1_mean    f1_std   n  \n",
       "33              0.0300      0.015               0.15  0.858777       NaN   1  \n",
       "36              0.0300      0.015               0.15  0.816529       NaN   1  \n",
       "57              0.0100      0.200               0.10  0.797181       NaN   1  \n",
       "40              0.0300      0.015               0.10  0.791129       NaN   1  \n",
       "52              0.0300      0.015               0.15  0.789560       NaN   1  \n",
       "51              0.0100      0.010               0.15  0.788394  0.035650  12  \n",
       "54              0.0100      0.010               0.15  0.781241       NaN   1  \n",
       "43              0.0030      0.010               0.10  0.773594       NaN   1  \n",
       "48              0.0100      0.010               0.15  0.768419  0.071974  11  \n",
       "55              0.0300      0.015               0.10  0.766632  0.060566   5  \n",
       "50              0.0300      0.015               0.10  0.766551  0.048787   5  \n",
       "26              0.0300      0.015               0.10  0.763550  0.015880   4  \n",
       "29              0.0100      0.010               0.15  0.762645  0.047355   8  \n",
       "32              0.0100      0.010               0.15  0.753004  0.059950   6  \n",
       "58              0.0030      0.010               0.15  0.752386  0.045747   5  \n",
       "45              0.0300      0.015               0.10  0.751272       NaN   1  \n",
       "39              0.0100      0.010               0.15  0.749536       NaN   1  \n",
       "35              0.0300      0.015               0.10  0.746934  0.058429   7  \n",
       "47              0.0030      0.015               0.15  0.746675  0.050254   5  \n",
       "25              0.0100      0.010               0.15  0.737458       NaN   1  \n",
       "49              0.0030      0.010               0.10  0.735710  0.106044   6  \n",
       "56              0.0100      0.010               0.15  0.730965  0.060402   3  \n",
       "24              0.0030      0.015               0.15  0.729825       NaN   1  \n",
       "31              0.0300      0.015               0.10  0.729383  0.064267   5  \n",
       "46              0.0001      0.015               0.10  0.725357  0.051200   5  \n",
       "44              0.0100      0.010               0.15  0.710991  0.092296   3  \n",
       "41              0.0030      0.010               0.15  0.694607  0.061100   8  \n",
       "23              0.0030      0.010               0.15  0.677205       NaN   1  \n",
       "28              0.0030      0.015               0.15  0.666012  0.164679   8  \n",
       "30              0.0030      0.010               0.10  0.658000  0.043750   5  \n",
       "27              0.0001      0.015               0.10  0.651555  0.054245   5  \n",
       "37              0.0030      0.010               0.15  0.639356       NaN   1  \n",
       "38              0.0030      0.015               0.15  0.637501       NaN   1  \n",
       "11              0.0001      0.015               0.10  0.607652       NaN   1  \n",
       "42              0.0030      0.200               0.10  0.589712  0.217036   5  \n",
       "34              0.0001      0.200               0.10  0.587786  0.056058   5  \n",
       "59              0.0030      0.200               0.10  0.570433  0.326868   5  \n",
       "20              0.0100      0.015               0.10  0.551843  0.154634   6  \n",
       "16              0.0300      0.200               0.10  0.544892       NaN   1  \n",
       "17              0.0001      0.015               0.10  0.536183  0.219993   8  \n",
       "53              0.0001      0.200               0.10  0.531470  0.298393   5  \n",
       "5               0.0300      0.010               0.10  0.526955  0.048991   5  \n",
       "6               0.0300      0.015               0.10  0.525590  0.071796   7  \n",
       "2               0.0030      0.010               0.10  0.520945       NaN   1  \n",
       "21              0.0300      0.015               0.10  0.478080       NaN   1  \n",
       "0               0.0001      0.010               0.15  0.456475  0.131701   5  \n",
       "4               0.0100      0.010               0.10  0.442974       NaN   1  \n",
       "12              0.0001      0.200               0.10  0.438464  0.205208   5  \n",
       "7               0.0300      0.200               0.10  0.429460  0.171567   5  \n",
       "3               0.0030      0.010               0.15  0.425108       NaN   1  \n",
       "19              0.0030      0.015               0.10  0.416943  0.192687   2  \n",
       "22              0.0300      0.200               0.15  0.372333  0.205309   5  \n",
       "15              0.0100      0.010               0.10  0.368151       NaN   1  \n",
       "13              0.0030      0.010               0.10  0.337506  0.178044   5  \n",
       "14              0.0030      0.200               0.10  0.288988       NaN   1  \n",
       "8               0.0001      0.200               0.15  0.256835  0.190418   5  \n",
       "9               0.0100      0.200               0.15  0.226664  0.201640   5  \n",
       "10              0.0001      0.010               0.10  0.000000       NaN   1  \n",
       "18              0.0001      0.015               0.15  0.000000  0.000000   2  \n",
       "1               0.0001      0.015               0.10  0.000000       NaN   1  "
      ]
     },
     "execution_count": 123,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trial_results.groupby([\"model\", \"strategy\", *varying_hyperparameter_names]).agg(f1_mean=('f1', 'mean'), f1_std=('f1', 'std'), n=('f1', 'size')).reset_index().sort_values('f1_mean', ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "id": "aaf4c540",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>model</th>\n",
       "      <th>strategy</th>\n",
       "      <th>fold</th>\n",
       "      <th>trial_id</th>\n",
       "      <th>started_at</th>\n",
       "      <th>finished_at</th>\n",
       "      <th>duration</th>\n",
       "      <th>batch_size</th>\n",
       "      <th>head_learning_rate</th>\n",
       "      <th>l2_weight</th>\n",
       "      <th>warmup_proportion</th>\n",
       "      <th>f1</th>\n",
       "      <th>batch_size_body</th>\n",
       "      <th>batch_size_head</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>sentence-transformers--all-mpnet-base-v2</td>\n",
       "      <td>mention_text</td>\n",
       "      <td>fold02</td>\n",
       "      <td>8</td>\n",
       "      <td>2026-02-05T11:07:10</td>\n",
       "      <td>2026-02-05T11:08:24</td>\n",
       "      <td>74</td>\n",
       "      <td>(32, 4)</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.15</td>\n",
       "      <td>0.690619</td>\n",
       "      <td>32</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>sentence-transformers--all-mpnet-base-v2</td>\n",
       "      <td>mention_text</td>\n",
       "      <td>fold03</td>\n",
       "      <td>8</td>\n",
       "      <td>2026-02-05T13:05:07</td>\n",
       "      <td>2026-02-05T13:06:21</td>\n",
       "      <td>73</td>\n",
       "      <td>(32, 4)</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.15</td>\n",
       "      <td>0.776178</td>\n",
       "      <td>32</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>sentence-transformers--all-mpnet-base-v2</td>\n",
       "      <td>mention_text</td>\n",
       "      <td>fold03</td>\n",
       "      <td>11</td>\n",
       "      <td>2026-02-05T13:08:48</td>\n",
       "      <td>2026-02-05T13:10:05</td>\n",
       "      <td>76</td>\n",
       "      <td>(32, 4)</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.15</td>\n",
       "      <td>0.776178</td>\n",
       "      <td>32</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>sentence-transformers--all-mpnet-base-v2</td>\n",
       "      <td>mention_text</td>\n",
       "      <td>fold03</td>\n",
       "      <td>12</td>\n",
       "      <td>2026-02-05T13:10:05</td>\n",
       "      <td>2026-02-05T13:11:18</td>\n",
       "      <td>73</td>\n",
       "      <td>(32, 4)</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.15</td>\n",
       "      <td>0.776178</td>\n",
       "      <td>32</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>sentence-transformers--all-mpnet-base-v2</td>\n",
       "      <td>mention_text</td>\n",
       "      <td>fold05</td>\n",
       "      <td>8</td>\n",
       "      <td>2026-02-05T17:02:29</td>\n",
       "      <td>2026-02-05T17:04:01</td>\n",
       "      <td>91</td>\n",
       "      <td>(32, 4)</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.15</td>\n",
       "      <td>0.834855</td>\n",
       "      <td>32</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>sentence-transformers--all-mpnet-base-v2</td>\n",
       "      <td>mention_text</td>\n",
       "      <td>fold01</td>\n",
       "      <td>8</td>\n",
       "      <td>2026-02-05T09:02:40</td>\n",
       "      <td>2026-02-05T09:04:30</td>\n",
       "      <td>109</td>\n",
       "      <td>(32, 4)</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.15</td>\n",
       "      <td>0.794595</td>\n",
       "      <td>32</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>sentence-transformers--all-mpnet-base-v2</td>\n",
       "      <td>mention_text</td>\n",
       "      <td>fold01</td>\n",
       "      <td>10</td>\n",
       "      <td>2026-02-05T09:06:07</td>\n",
       "      <td>2026-02-05T09:07:57</td>\n",
       "      <td>109</td>\n",
       "      <td>(32, 4)</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.15</td>\n",
       "      <td>0.794595</td>\n",
       "      <td>32</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>sentence-transformers--all-mpnet-base-v2</td>\n",
       "      <td>mention_text</td>\n",
       "      <td>fold01</td>\n",
       "      <td>11</td>\n",
       "      <td>2026-02-05T09:07:57</td>\n",
       "      <td>2026-02-05T09:09:46</td>\n",
       "      <td>108</td>\n",
       "      <td>(32, 4)</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.15</td>\n",
       "      <td>0.794595</td>\n",
       "      <td>32</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>sentence-transformers--all-mpnet-base-v2</td>\n",
       "      <td>mention_text</td>\n",
       "      <td>fold01</td>\n",
       "      <td>12</td>\n",
       "      <td>2026-02-05T09:09:46</td>\n",
       "      <td>2026-02-05T09:11:32</td>\n",
       "      <td>106</td>\n",
       "      <td>(32, 4)</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.15</td>\n",
       "      <td>0.794595</td>\n",
       "      <td>32</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>sentence-transformers--all-mpnet-base-v2</td>\n",
       "      <td>mention_text</td>\n",
       "      <td>fold01</td>\n",
       "      <td>13</td>\n",
       "      <td>2026-02-05T09:11:32</td>\n",
       "      <td>2026-02-05T09:13:17</td>\n",
       "      <td>104</td>\n",
       "      <td>(32, 4)</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.15</td>\n",
       "      <td>0.794595</td>\n",
       "      <td>32</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>sentence-transformers--all-mpnet-base-v2</td>\n",
       "      <td>mention_text</td>\n",
       "      <td>fold04</td>\n",
       "      <td>8</td>\n",
       "      <td>2026-02-05T15:08:52</td>\n",
       "      <td>2026-02-05T15:10:24</td>\n",
       "      <td>91</td>\n",
       "      <td>(32, 4)</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.15</td>\n",
       "      <td>0.816870</td>\n",
       "      <td>32</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>sentence-transformers--all-mpnet-base-v2</td>\n",
       "      <td>mention_text</td>\n",
       "      <td>fold04</td>\n",
       "      <td>11</td>\n",
       "      <td>2026-02-05T15:12:57</td>\n",
       "      <td>2026-02-05T15:14:30</td>\n",
       "      <td>92</td>\n",
       "      <td>(32, 4)</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.15</td>\n",
       "      <td>0.816870</td>\n",
       "      <td>32</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                       model      strategy    fold  trial_id  \\\n",
       "8   sentence-transformers--all-mpnet-base-v2  mention_text  fold02         8   \n",
       "8   sentence-transformers--all-mpnet-base-v2  mention_text  fold03         8   \n",
       "11  sentence-transformers--all-mpnet-base-v2  mention_text  fold03        11   \n",
       "12  sentence-transformers--all-mpnet-base-v2  mention_text  fold03        12   \n",
       "8   sentence-transformers--all-mpnet-base-v2  mention_text  fold05         8   \n",
       "8   sentence-transformers--all-mpnet-base-v2  mention_text  fold01         8   \n",
       "10  sentence-transformers--all-mpnet-base-v2  mention_text  fold01        10   \n",
       "11  sentence-transformers--all-mpnet-base-v2  mention_text  fold01        11   \n",
       "12  sentence-transformers--all-mpnet-base-v2  mention_text  fold01        12   \n",
       "13  sentence-transformers--all-mpnet-base-v2  mention_text  fold01        13   \n",
       "8   sentence-transformers--all-mpnet-base-v2  mention_text  fold04         8   \n",
       "11  sentence-transformers--all-mpnet-base-v2  mention_text  fold04        11   \n",
       "\n",
       "             started_at          finished_at  duration batch_size  \\\n",
       "8   2026-02-05T11:07:10  2026-02-05T11:08:24        74    (32, 4)   \n",
       "8   2026-02-05T13:05:07  2026-02-05T13:06:21        73    (32, 4)   \n",
       "11  2026-02-05T13:08:48  2026-02-05T13:10:05        76    (32, 4)   \n",
       "12  2026-02-05T13:10:05  2026-02-05T13:11:18        73    (32, 4)   \n",
       "8   2026-02-05T17:02:29  2026-02-05T17:04:01        91    (32, 4)   \n",
       "8   2026-02-05T09:02:40  2026-02-05T09:04:30       109    (32, 4)   \n",
       "10  2026-02-05T09:06:07  2026-02-05T09:07:57       109    (32, 4)   \n",
       "11  2026-02-05T09:07:57  2026-02-05T09:09:46       108    (32, 4)   \n",
       "12  2026-02-05T09:09:46  2026-02-05T09:11:32       106    (32, 4)   \n",
       "13  2026-02-05T09:11:32  2026-02-05T09:13:17       104    (32, 4)   \n",
       "8   2026-02-05T15:08:52  2026-02-05T15:10:24        91    (32, 4)   \n",
       "11  2026-02-05T15:12:57  2026-02-05T15:14:30        92    (32, 4)   \n",
       "\n",
       "    head_learning_rate  l2_weight  warmup_proportion        f1  \\\n",
       "8                 0.01       0.01               0.15  0.690619   \n",
       "8                 0.01       0.01               0.15  0.776178   \n",
       "11                0.01       0.01               0.15  0.776178   \n",
       "12                0.01       0.01               0.15  0.776178   \n",
       "8                 0.01       0.01               0.15  0.834855   \n",
       "8                 0.01       0.01               0.15  0.794595   \n",
       "10                0.01       0.01               0.15  0.794595   \n",
       "11                0.01       0.01               0.15  0.794595   \n",
       "12                0.01       0.01               0.15  0.794595   \n",
       "13                0.01       0.01               0.15  0.794595   \n",
       "8                 0.01       0.01               0.15  0.816870   \n",
       "11                0.01       0.01               0.15  0.816870   \n",
       "\n",
       "    batch_size_body  batch_size_head  \n",
       "8                32                4  \n",
       "8                32                4  \n",
       "11               32                4  \n",
       "12               32                4  \n",
       "8                32                4  \n",
       "8                32                4  \n",
       "10               32                4  \n",
       "11               32                4  \n",
       "12               32                4  \n",
       "13               32                4  \n",
       "8                32                4  \n",
       "11               32                4  "
      ]
     },
     "execution_count": 124,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trial_results[['batch_size_body', 'batch_size_head']] = trial_results.batch_size.apply(lambda x: eval(x) if isinstance(x, str) else x).apply(pd.Series)\n",
    "trial_results.query(\"\"\"\\\n",
    "    model == \"sentence-transformers--all-mpnet-base-v2\" and \\\n",
    "    batch_size_body == 32 and batch_size_head == 4 and \\\n",
    "    head_learning_rate == 0.01 and \\\n",
    "    l2_weight == 0.01 and \\\n",
    "    warmup_proportion == 0.15 \\\n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7a7f5e9",
   "metadata": {},
   "source": [
    "#### Model evaluation\n",
    "\n",
    "::: {.callout-tip title=\"model selection\"}\n",
    "\n",
    "I also checked aveage results for `nomic-ai--modernbert-embed-base` but the score rpeorted above is a n outlier -- `sentence-transformers--all-mpnet-base-v2` performs more consistently across categories and folds.\n",
    "\n",
    "::: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "id": "f22f2c9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# model = \"nomic-ai--modernbert-embed-base\"\n",
    "model = \"sentence-transformers--all-mpnet-base-v2\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "id": "ed880311",
   "metadata": {},
   "outputs": [],
   "source": [
    "results_dir = results_path / task / STEP / \"setfit\" / model\n",
    "\n",
    "df = pd.concat({\n",
    "    fp.parts[-5:-1]: pd.read_json(fp).T.reset_index(level=0, names=\"what\") \n",
    "    for fp in results_dir.glob(\"**/eval_results.json\")\n",
    "})\n",
    "df.reset_index(level=[0,1,2,3], names=[\"method\", \"model_name\", \"strategy\", \"fold\"], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "id": "9674d64e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "what\n",
       "ethnicity                    0.921±0.074\n",
       "family                       0.905±0.136\n",
       "age                          0.872±0.033\n",
       "nationality                  0.819±0.059\n",
       "gender/sexuality             0.765±0.257\n",
       "crime                        0.764±0.209\n",
       "religion                     0.759±0.223\n",
       "shared values/mentalities    0.753±0.062\n",
       "place/location               0.750±0.186\n",
       "health                       0.732±0.154\n",
       "dtype: object"
      ]
     },
     "execution_count": 110,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "metrics = [\"weighted avg\", \"macro avg\", \"micro avg\", \"samples avg\"]\n",
    "pdat = df.query(\"what not in @metrics\").copy()\n",
    "pdat[\"what\"] = pdat[\"what\"]\\\n",
    "    .str.replace(\"noneconomic__\", \"\")\\\n",
    "    .str.replace(\"shared_\", \"shared \")\\\n",
    "    .str.replace(\"_\", \"/\")\n",
    "\n",
    "pdat.groupby(\"what\")[\"f1-score\"].agg(['mean', 'std']).sort_values('mean', ascending=False).apply(lambda x: f\"{x['mean']:.3f}±{x['std']:.3f}\", axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "id": "cd04b19b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_2500622/4284136641.py:14: UserWarning: \n",
      "\n",
      "The `scale` parameter is deprecated and will be removed in v0.15.0. You can now control the size of each plot element using matplotlib `Line2D` parameters (e.g., `linewidth`, `markersize`, etc.).\n",
      "\n",
      "  sns.pointplot(\n",
      "/tmp/ipykernel_2500622/4284136641.py:14: FutureWarning: \n",
      "\n",
      "The `errwidth` parameter is deprecated. And will be removed in v0.15.0. Pass `err_kws={'linewidth': 1}` instead.\n",
      "\n",
      "  sns.pointplot(\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 400x400 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "pdat = pdat.melt(id_vars=[\"what\", \"fold\"], value_vars=[\"precision\", \"recall\", \"f1-score\"], var_name=\"metric\", value_name=\"value\")\n",
    "\n",
    "n_ys = pdat.what.nunique()\n",
    "plt.figure(figsize=(4, n_ys/2.5))\n",
    "\n",
    "# add grey horizontal stripes at alternating y positions\n",
    "for i in range(n_ys):\n",
    "    if i % 2 == 0:\n",
    "        plt.gca().axhspan(i - 0.5, i + 0.5, color='gray', alpha=0.1, zorder=0, linewidth=0)\n",
    "\n",
    "ls = '-' # (0, (5, 10))\n",
    "plt.grid(axis=\"x\", which='major', linestyle=ls,  linewidth=0.25, color='gray', alpha=0.5)\n",
    "\n",
    "sns.pointplot(\n",
    "    data=pdat,\n",
    "    y=\"what\",\n",
    "    x=\"value\",\n",
    "\n",
    "    hue=\"metric\",\n",
    "    dodge=1/3,\n",
    "    #color='black',\n",
    "    \n",
    "    linestyles='none',\n",
    "    scale=2/3,\n",
    "    errwidth=1,\n",
    "    # markersize=3,\n",
    "\n",
    "    errorbar='ci',\n",
    "    # capsize=.05,\n",
    "    # err_kws={'linewidth': .75},\n",
    "\n",
    "    # legend=False,\n",
    "    seed=42\n",
    ")\n",
    "# add bold title and labels\n",
    "# plt.title(metric, fontweight='bold')\n",
    "plt.xlabel(\"score\")\n",
    "plt.ylabel(\"\")\n",
    "plt.xlim(-0.01, 1.01)\n",
    "plt.xticks(np.arange(0, 1.1, 0.1))\n",
    "\n",
    "# place legend below plot\n",
    "plt.legend(title=None, bbox_to_anchor=(0.5, +1.2), loc='upper center', ncol=3, frameon=False)\n",
    "# plt.tight_layout()\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad73936b",
   "metadata": {},
   "source": [
    "#### Error analysis\n",
    "\n",
    "- get predicted labels for val sets of different folds\n",
    "- compute misclassification rates across models and strategies\n",
    "- review mis-classified instances"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "id": "33170695",
   "metadata": {},
   "outputs": [],
   "source": [
    "key_cols = ['fold', 'mention_id', 'text', 'mention', 'span']\n",
    "\n",
    "preds_df = pd.concat({\n",
    "    fp.parts[-4:-1]: pd.read_pickle(fp)\n",
    "    for fp in results_dir.glob(\"**/eval_predictions.pkl\")\n",
    "})\n",
    "preds_df.reset_index(level=[0,1,2], names=[\"model_name\", \"strategy\", \"fold\"], inplace=True)\n",
    "# get index of column \"span\"\n",
    "i = preds_df.columns.get_loc(\"span\")\n",
    "key_cols = preds_df.columns[:i+1]\n",
    "preds_df_long = preds_df.melt(id_vars=key_cols, var_name=\"attribute\", value_name=\"value\")\n",
    "\n",
    "preds_df_long['what'] = preds_df_long['attribute'].str.extract('^(prob|pred|error)_.+$')\n",
    "preds_df_long.loc[preds_df_long['what'].isnull(), 'what'] = 'label'\n",
    "preds_df_long['attribute'] = preds_df_long['attribute'].str.replace('^(prob|pred|error)_', '', regex=True)\n",
    "\n",
    "preds_df = preds_df_long.pivot(index=[*key_cols, 'attribute'], columns='what', values='value').reset_index()\n",
    "preds_df.columns.name = None\n",
    "\n",
    "preds_df['label'] = preds_df['label'].astype(int)\n",
    "preds_df['pred'] = preds_df['pred'].astype(int)\n",
    "preds_df['prob'] = preds_df['prob'].astype(float)\n",
    "preds_df['error'] = preds_df['error'].astype(bool)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "id": "c2240951",
   "metadata": {},
   "outputs": [],
   "source": [
    "# compute error rate\n",
    "id_cols = ['mention_id', 'text', 'mention', 'span', 'attribute', 'label']\n",
    "error_rates_df = preds_df.groupby(id_cols, observed=False).agg({'error': 'mean'}).reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "id": "0ce3d889",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "error\n",
       "0.0    5852\n",
       "1.0     148\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 114,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# TODO: error rates don't make senses with one classifier and distinct eval (test) sets per fold\n",
    "error_rates_df.error.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "id": "71654fdb",
   "metadata": {},
   "outputs": [],
   "source": [
    "error_rates_df.sort_values('error', ascending=False, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "id": "84271cc2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1mnoneconomic__age\u001b[0m\n",
      "  ~> \u001b[1m\u001b[3mfalse positives\u001b[0m\n",
      "  -  11320_201409-397483-1 (1.00):  \u001b[30m\u001b[43mEveryone working in the elderly care sector\u001b[0m should be trained in dementia and multi-disease.\n",
      "  - 171101_200306-303319-1 (1.00):  In 40% of \u001b[30m\u001b[43mthe families of these young people\u001b[0m, the characteristics of the reference group of their children are unknown, as well as the activities they regularly carry out.\n",
      "  -  82720_201310-117539-1 (1.00):  Only \u001b[30m\u001b[43mthose who lead an orderly life and educate children properly\u001b[0m deserve support.\n",
      "  -   42110_198611-03946-1 (1.00):  \u001b[30m\u001b[43mPowerful cliques behind and within the old parties\u001b[0m are heading towards the Great Coalition.\n",
      "  -   21914_198510-27676-1 (1.00):  \u001b[30m\u001b[43mGenerations of Flemish fighters\u001b[0m have not given the best of themselves so that Flanders would soon become another American protectorate, or be condemned to another island in the Goel archipelago.\n",
      "  -  11110_200209-393006-1 (1.00):  \u001b[30m\u001b[43mStudents with children\u001b[0m have great difficulties bringing the economy together.\n",
      "\n",
      "  ~> \u001b[1m\u001b[3mfalse negatives\u001b[0m\n",
      "  -  41320_197610-119535-2 (1.00):  This is what today’s pensioners and \u001b[30m\u001b[43mthe working generation\u001b[0m can expect in the future.\n",
      "  -  51320_198306-223343-2 (1.00):  For those who require long-term care - \u001b[30m\u001b[43melderly, mentally handicapped, mentally ill and disabled people\u001b[0m - develop services within both the health service and the local authority services, based on support for them and their families within the community.\n",
      "  -   21111_200706-59279-1 (1.00):  Building \u001b[30m\u001b[43ma truly intergenerational society\u001b[0m.\n",
      "  -   62110_201510-98019-1 (1.00):  The most extreme challenges of aging are experienced by \u001b[30m\u001b[43mseniors living in poverty\u001b[0m, a disproportionate proportion of whom are women.\n",
      "  -  51620_198706-225844-1 (1.00):  Fourth, \u001b[30m\u001b[43melderly, disabled, mentally ill and mentally handicapped people\u001b[0m, should be cared for within the community whenever this is right for them.\n",
      "  -  22110_200301-320320-2 (1.00):  When white parents pick up \u001b[30m\u001b[43mtheir crust\u001b[0m from a mixed school, it's the world-on-heads when then black students are forced to be scattered.\n",
      "  -  61320_197611-404347-1 (1.00):  The Democratic Party is committed to the right of \u001b[30m\u001b[43mall adult Americans\u001b[0m willing, able and seeking work to have opportunities for useful jobs at living wages.\n",
      "  -  41521_198701-126128-2 (1.00):  The elderly are \u001b[30m\u001b[43mindependent, active and confident citizens who want to actively use, expand and pass on their experiences and knowledge\u001b[0m.\n",
      "  -  11110_201009-394992-1 (1.00):  The investments we make today create \u001b[30m\u001b[43mtomorrow’s society\u001b[0m.\n",
      "  -  13720_200111-190125-2 (1.00):  Street gangs and \u001b[30m\u001b[43mother organized groups of burdened young criminals\u001b[0m characterize the development.\n",
      "\n",
      "\u001b[1mnoneconomic__crime\u001b[0m\n",
      "  ~> \u001b[1m\u001b[3mfalse positives\u001b[0m\n",
      "  -  51620_197410-221827-1 (1.00):  The new Conservative government will strengthen the police force, \u001b[30m\u001b[43mour principal defenders against internal attack\u001b[0m.\n",
      "  -  14820_197903-197512-1 (1.00):  Do not submit to \u001b[30m\u001b[43mthe betrayers of your promises\u001b[0m.\n",
      "  -  11110_200609-393935-1 (1.00):  We want to raise damages to \u001b[30m\u001b[43mindividuals who are discriminated against by companies or government agencies\u001b[0m.\n",
      "\n",
      "  ~> \u001b[1m\u001b[3mfalse negatives\u001b[0m\n",
      "  -  51320_200106-231987-2 (1.00):  In 1997, victims were \u001b[30m\u001b[43mthe forgotten people in legal battles\u001b[0m.\n",
      "  -  53110_199706-276756-1 (1.00):  \u001b[30m\u001b[43mThose who advocate a 'war' on crime, while ignoring underlying causes\u001b[0m only help institutionalise the crime culture.\n",
      "  -  41111_198701-123538-9 (1.00):  The Federal Republic must acknowledge its responsibility to the victims of fascism and recognize the compensation demands of all the victims of the Nazi, especially the Roma and Sinti, the Jewish people, the homosexuals, the forced sterilized, the survivors of the \"ethanasia\" actions, the resistance fighters and \u001b[30m\u001b[43mthe so-called associalists\u001b[0m.\n",
      "  -  92436_200509-360693-2 (1.00):  It is necessary to expand the lustration, to disclose all peer-related special services officers and \u001b[30m\u001b[43msecret collaborators\u001b[0m.\n",
      "  -  14820_197201-197442-1 (1.00):  \u001b[30m\u001b[43mAll the culprits\u001b[0m must be thoroughly investigated and those involved must be held accountable and liable to compensation, including the leading politicians of the old parties.\n",
      "  -  86710_201404-270610-2 (1.00):  Together, these companies have deceived the majority of \u001b[30m\u001b[43mthose involved in the currency lending trap\u001b[0m.\n",
      "  -  12951_198909-330603-1 (1.00):  Especially \u001b[30m\u001b[43myoung offenders\u001b[0m.\n",
      "  -   80620_200907-92823-1 (1.00):  The RPS has shown that it is the only political force that really exposes corruption and ties to \u001b[30m\u001b[43mthe mafia\u001b[0m at the high levels of power.\n",
      "\n",
      "\u001b[1mnoneconomic__ethnicity\u001b[0m\n",
      "  ~> \u001b[1m\u001b[3mfalse positives\u001b[0m\n",
      "\n",
      "  ~> \u001b[1m\u001b[3mfalse negatives\u001b[0m\n",
      "  -  15111_201710-281205-1 (1.00):  Insurance needs access to a diversified culture in \u001b[30m\u001b[43ma multicultural society\u001b[0m.\n",
      "  -  14110_199903-198263-2 (1.00):  Every person belongs to \u001b[30m\u001b[43ma minority\u001b[0m.\n",
      "  -  11110_200609-393935-1 (1.00):  We want to raise damages to \u001b[30m\u001b[43mindividuals who are discriminated against by companies or government agencies\u001b[0m.\n",
      "  -   21111_199111-32560-1 (1.00):  Immigration: \u001b[30m\u001b[43mA multicultural society\u001b[0m.\n",
      "\n",
      "\u001b[1mnoneconomic__family\u001b[0m\n",
      "  ~> \u001b[1m\u001b[3mfalse positives\u001b[0m\n",
      "  -  64110_201111-352757-1 (1.00):  (\u001b[30m\u001b[43mkids\u001b[0m splash) After all, It's every Kiwi kid's birthright.\n",
      "  -  96710_201006-381008-1 (1.00):  The upbringing and education of \u001b[30m\u001b[43mour children and youth\u001b[0m is the most responsible and noble task of society.\n",
      "  -   80640_201703-95265-3 (1.00):  Creation of a specialized team that initiates and implements projects related to the artistic and creative industries, and the artistic and creative skills of young people who want to realize themselves in another sphere, regardless of their choice of profession; Creation of a center for \u001b[30m\u001b[43mtalented children (in particular - with dyslexia)\u001b[0m, and specialized educational and extra-class programs/ parallels for them; Creation of the \"Ministry of Innovations\" which drafts strategy and tactics based on future world trends (10+ years), and which starts from now on the preparation of processes, people, skills, experimental developments, pilot projects through which will ensure the long-term survival of Bulgaria (e.g. are people prepared for the moment when cars will be inexperienced and there will be no need for drivers, or what people will work, whose professions will be and can be\n",
      "  -  23113_200906-299389-1 (1.00):  It is also important that \u001b[30m\u001b[43meach child, as an individual\u001b[0m, can develop their life project according to their capabilities, skills and wishes.\n",
      "\n",
      "  ~> \u001b[1m\u001b[3mfalse negatives\u001b[0m\n",
      "  -  82110_201310-117137-1 (1.00):  We will promote the awareness of the rights of \u001b[30m\u001b[43mchildren growing up in children’s homes and institutional care facilities\u001b[0m.\n",
      "  -   80710_200907-92925-2 (1.00):  Complete revision of the return of land to their true owners or \u001b[30m\u001b[43mtheir heirs\u001b[0m.\n",
      "\n",
      "\u001b[1mnoneconomic__gender_sexuality\u001b[0m\n",
      "  ~> \u001b[1m\u001b[3mfalse positives\u001b[0m\n",
      "  -   21111_198111-22981-1 (1.00):  \u001b[30m\u001b[43mrepresentatives of women’s associations\u001b[0m.\n",
      "  -  31720_200206-209210-2 (1.00):  It is in the supreme interest of the Nation to reaffirm the concern of France towards the French to be born and to surround \u001b[30m\u001b[43mthe mothers and fathers of family\u001b[0m with the vigilance and care of the public authorities.\n",
      "  -   42110_200211-10474-1 (1.00):  However, the present is characterized by other forms of coexistence: in addition to \u001b[30m\u001b[43mfather-mother-child family\u001b[0m, life-stage partnerships and patchwork families, very different life concepts have also created a diverse society.\n",
      "  -   80710_201305-93134-1 (1.00):  And you help \u001b[30m\u001b[43mtheir fathers and mothers\u001b[0m by putting some of your money into their retirement deposits.\n",
      "\n",
      "  ~> \u001b[1m\u001b[3mfalse negatives\u001b[0m\n",
      "  -  11320_201009-395337-2 (1.00):  Men get more than \u001b[30m\u001b[43mwome\u001b[0mn.\n",
      "  -  22110_201703-327702-1 (1.00):  \u001b[30m\u001b[43mFamilies whose composition is different from the traditional mother-father composition\u001b[0m are entitled to equal opportunities for legal parenting.\n",
      "  -  41953_201709-170789-1 (1.00):  The AfD wants the family policy of the Federation and the states to be based on the image of \u001b[30m\u001b[43mthe family of father, mother and children\u001b[0m.\n",
      "  -  31720_198603-207728-1 (1.00):  \u001b[30m\u001b[43mFamilial mothers\u001b[0m should be given priority to vocational training in order to re-integrate into economic life.\n",
      "  -  41112_199012-127111-2 (1.00):  Their clients are \u001b[30m\u001b[43mmen from all walks of life and professions\u001b[0m.\n",
      "  -   42710_200809-14967-1 (1.00):  The BZÖ wants to expand the child allowance introduced by it to a maternity salary of 1,000 euros for all those \u001b[30m\u001b[43mmothers who want to dedicate themselves entirely to the upbringing of their children\u001b[0m.\n",
      "  -  11110_200609-393935-1 (1.00):  We want to raise damages to \u001b[30m\u001b[43mindividuals who are discriminated against by companies or government agencies\u001b[0m.\n",
      "  -  97110_199212-382866-1 (1.00):  We live in \u001b[30m\u001b[43ma society that is ruled by men\u001b[0m.\n",
      "\n",
      "\u001b[1mnoneconomic__health\u001b[0m\n",
      "  ~> \u001b[1m\u001b[3mfalse positives\u001b[0m\n",
      "  -  22110_201006-323838-1 (1.00):  Therefore, it is good to set additional requirements for \u001b[30m\u001b[43mdoctors who are dealing with this\u001b[0m in a separate law.\n",
      "  -  14110_201904-203887-1 (1.00):  \u001b[30m\u001b[43mPeople who are not well\u001b[0m, especially boys, are getting worse.\n",
      "  -  51620_197905-222762-1 (1.00):  The lack of money to improve our social services and assist \u001b[30m\u001b[43mthose in need\u001b[0m can only be overcome by restoring the nation's prosperity.\n",
      "  -  86710_201804-275232-1 (1.00):  The tax would also cover \u001b[30m\u001b[43mthe individual concerned\u001b[0m and the assets of its business entities.\n",
      "  -  51620_201505-241457-4 (1.00):  Patients, doctors and nurses are \u001b[30m\u001b[43mthe experts on how to improve people's health\u001b[0m.\n",
      "\n",
      "  ~> \u001b[1m\u001b[3mfalse negatives\u001b[0m\n",
      "  -  51620_200505-235236-1 (1.00):  It is too impersonal, too inflexible, too centralised and too bureaucratic to respond to the needs of \u001b[30m\u001b[43mpatients\u001b[0m.\n",
      "  -  92436_200509-360961-1 (1.00):  \u001b[30m\u001b[43mOrdinary people who practice sports\u001b[0m have fewer healthcare expenditures, fewer pathologies and better development prospects.\n",
      "  -  41113_201709-165781-2 (1.00):  In addition, caregivers should be allowed to take 10 days a year to take special care of \u001b[30m\u001b[43ma person to be cared for\u001b[0m.\n",
      "  -  43110_201110-104517-3 (1.00):  Children with a migrant background, children from an educational background or \u001b[30m\u001b[43mchildren with a dependent or mentally ill parent\u001b[0m often have poor opportunities when entering school.\n",
      "  -   42420_198611-04499-2 (1.00):  The main objective of freedom policy for persons with disabilities is the integration of \u001b[30m\u001b[43mthose concerned\u001b[0m into the community through active participation in social life.\n",
      "  -  86710_201804-274934-1 (1.00):  The same is needed for \u001b[30m\u001b[43myoung people who are unable or unwilling to integrate into the normal educational system because of their behavioral problems\u001b[0m.\n",
      "  -  92436_200509-360923-3 (1.00):  improvement of the quality of life of Poles, especially of pensioners and \u001b[30m\u001b[43mother vulnerable social groups\u001b[0m.\n",
      "  -  11110_200609-393935-1 (1.00):  We want to raise damages to \u001b[30m\u001b[43mindividuals who are discriminated against by companies or government agencies\u001b[0m.\n",
      "  -  53110_201602-279437-1 (1.00):  We need to reform how we deliver such services to get a better outcome for \u001b[30m\u001b[43mpatients\u001b[0m, students and parents and not just rely on putting ever increasing resources into a system that is in need of reform.\n",
      "\n",
      "\u001b[1mnoneconomic__nationality\u001b[0m\n",
      "  ~> \u001b[1m\u001b[3mfalse positives\u001b[0m\n",
      "  -  61320_202011-434465-3 (1.00):  We condemn the decades-long campaign to demonize and dehumanize the Muslim faith community, which has led to increased rates of violence and discrimination targeting American Muslims or \u001b[30m\u001b[43mthose perceived to be Muslim\u001b[0m.\n",
      "  -  41320_199012-128021-1 (1.00):  \u001b[30m\u001b[43mThose who want to solve the major transnational challenges\u001b[0m, such as environmental protection, need a strong Europe.\n",
      "  -  13720_201506-194129-1 (1.00):  Including \u001b[30m\u001b[43mthe elderly, who have built up the Danish society and have difficulty coping with themselves\u001b[0m.\n",
      "  -  61620_201211-430157-2 (1.00):  It has created a backdoor amnesty program unrecognized in law, granting worker authorization to illegal aliens, and shown little regard for the lifeanddeath situations facing \u001b[30m\u001b[43mthe men and women of the border patrol\u001b[0m.\n",
      "  -   42420_201710-19827-1 (1.00):  The goal of European integration must be the community of those states that geographically, spiritually and culturally make up Europe and have committed themselves to Western values, to the heritage of cultures and traditions of \u001b[30m\u001b[43mthe European peoples\u001b[0m.\n",
      "  -   42420_199910-10164-1 (1.00):  Rather, it is about promoting \u001b[30m\u001b[43mpeople either of origin in a structured education\u001b[0m system according to their talents as best possible.\n",
      "  -  34512_199609-252823-1 (1.00):  \u001b[30m\u001b[43mA farmer in Greece\u001b[0m.\n",
      "  -  51320_197006-218800-3 (1.00):  We insist, too, that society should not discriminate against minorities on grounds \u001b[30m\u001b[43mof religion or race or colour\u001b[0m: that all should have equal protection under the law and equal opportunity for advancement in and service to the community.\n",
      "\n",
      "  ~> \u001b[1m\u001b[3mfalse negatives\u001b[0m\n",
      "  -   42110_199910-09145-1 (1.00):  And: Our safety has to do with the living conditions of \u001b[30m\u001b[43mpeople in other parts of the world\u001b[0m.\n",
      "  -  86110_201804-273634-1 (1.00):  Therefore, a new social contract is needed: between the state and its \u001b[30m\u001b[43mcitizens\u001b[0m, rich and poor, young and old, women and men.\n",
      "  -  11620_198209-390299-1 (1.00):  The main task of the party is to secure a future in freedom for Sweden and \u001b[30m\u001b[43mits citizens\u001b[0m.\n",
      "  -  86421_200604-261378-1 (1.00):  Romanian culture is \u001b[30m\u001b[43ma majority society\u001b[0m.\n",
      "  -  15111_201710-281205-1 (1.00):  Insurance needs access to a diversified culture in \u001b[30m\u001b[43ma multicultural society\u001b[0m.\n",
      "  -  11320_197009-389709-3 (1.00):  We reject the bourgeois attempts to prevent society from creating the instruments necessary to protect the employment of \u001b[30m\u001b[43mcitizens\u001b[0m.\n",
      "  -  96710_199809-378834-1 (1.00):  A nation is \u001b[30m\u001b[43man ethnic community, a homogeneous ethnic space in which one can only be born\u001b[0m.\n",
      "  -  22110_201703-327673-1 (1.00):  Violence against \u001b[30m\u001b[43mpeople because of their origin, religion or sexual preference\u001b[0m is not tolerated.\n",
      "  -   21112_200706-64890-1 (1.00):  There is a strong negative and stigmatizing tendency towards \u001b[30m\u001b[43mpeople of a different skin color or of a different alleged origin\u001b[0m.\n",
      "  -  92436_200109-360301-1 (1.00):  \u001b[30m\u001b[43mPeople who started with goods carried across the border in suitcases and from field beds on the streets, from small consulting firms and service workshops, gradually built shops, wholesalers, factories, corporations and today give jobs to dozens of people: workers\u001b[0m.\n",
      "  -   21914_199111-35555-1 (1.00):  The program of the Flemish Bloc is the program of and for \u001b[30m\u001b[43mour people\u001b[0m.\n",
      "  -  61620_199211-417322-1 (1.00):  We also support establishment of a strong central government in Lebanon, democratically elected and representative of \u001b[30m\u001b[43mits citizens\u001b[0m.\n",
      "  -   21914_199111-35733-2 (1.00):  The problem of foreigners in Flanders is primarily caused by \u001b[30m\u001b[43mthe host workers\u001b[0m.\n",
      "  -  34710_200709-253044-3 (1.00):  The substantial support of motherhood, children and the third age, to protect the institution of the family and to ensure that there will be \u001b[30m\u001b[43mGreeks\u001b[0m in the long run.\n",
      "  -  43901_200710-104046-3 (1.00):  Companies must hire job-seekers and not \u001b[30m\u001b[43minterim or border workers\u001b[0m.\n",
      "  -  41521_198701-126128-2 (1.00):  The elderly are \u001b[30m\u001b[43mindependent, active and confident citizens who want to actively use, expand and pass on their experiences and knowledge\u001b[0m.\n",
      "  -   21111_199111-32560-1 (1.00):  Immigration: \u001b[30m\u001b[43mA multicultural society\u001b[0m.\n",
      "  -  11110_200609-393935-1 (1.00):  We want to raise damages to \u001b[30m\u001b[43mindividuals who are discriminated against by companies or government agencies\u001b[0m.\n",
      "\n",
      "\u001b[1mnoneconomic__place_location\u001b[0m\n",
      "  ~> \u001b[1m\u001b[3mfalse positives\u001b[0m\n",
      "  -  12951_199709-334859-1 (1.00):  The Progress Party wants the rules on immigration cessation to be strictly enforced, so that \u001b[30m\u001b[43mpersons from such countries\u001b[0m should only be granted temporary work permits if they have special qualifications that are lacking in Norway.\n",
      "  -  43810_201910-109323-1 (1.00):  \u001b[30m\u001b[43mWell-trained professionals from Switzerland\u001b[0m.\n",
      "  -  64110_202010-359455-1 (1.00):  This tax would only affect \u001b[30m\u001b[43mthe wealthiest 6 per cent of New Zealanders\u001b[0m.\n",
      "  -  51620_200505-235254-2 (1.00):  Small community hospitals which have the support of local patients and \u001b[30m\u001b[43mGPs\u001b[0m will not be closed by bureaucrats.\n",
      "\n",
      "  ~> \u001b[1m\u001b[3mfalse negatives\u001b[0m\n",
      "  -  83612_200303-196193-1 (1.00):  Most \u001b[30m\u001b[43mmunicipal and urban people\u001b[0m must be convinced of the benefits of joining.\n",
      "  -  51951_200106-233561-1 (1.00):  of \u001b[30m\u001b[43mlocal communities\u001b[0m, businesses and individual citizens.\n",
      "  -   42110_199910-09145-1 (1.00):  And: Our safety has to do with the living conditions of \u001b[30m\u001b[43mpeople in other parts of the world\u001b[0m.\n",
      "  -  43110_201510-105403-1 (1.00):  The Greens demand that \u001b[30m\u001b[43mthe multinationals based in Switzerland\u001b[0m assume their responsibility for sustainable global development according to their size and do not go into their own pockets.\n",
      "  -  51620_200505-235251-2 (1.00):  We will give patients and \u001b[30m\u001b[43mlocal GPs\u001b[0m the right to choose the hospital or care provider that is right for them.\n",
      "  -  51110_201912-248557-3 (1.00):  This will boost the leisure and cultural sectors, helping 125,000 businesses at the heart of \u001b[30m\u001b[43mtheir local communities\u001b[0m.\n",
      "  -  61320_197211-401907-1 (1.00):  So, too, are the backgrounds, traditions and contributions of \u001b[30m\u001b[43mwhite national, ethnic, religious and regional communities\u001b[0m ignored.\n",
      "\n",
      "\u001b[1mnoneconomic__religion\u001b[0m\n",
      "  ~> \u001b[1m\u001b[3mfalse positives\u001b[0m\n",
      "  -  12951_200909-340196-1 (1.00):  The right to vote should be universal and not limited to \u001b[30m\u001b[43mcertain ethnic groups\u001b[0m, therefore we will abolish the coalition.\n",
      "  -   21112_199505-36962-1 (1.00):  It is also a prerequisite for \u001b[30m\u001b[43man ethnic group\u001b[0m to be able to adapt to a new environment.\n",
      "  -   42110_199010-05508-1 (1.00):  No \u001b[30m\u001b[43methnic or linguistic group\u001b[0m, no matter how numerous or powerful they may feel, may claim to have created a culture that is superior to other cultures.\n",
      "  -  61320_201611-431137-4 (1.00):  We will end racial profiling that targets individuals solely on the basis of race, religion\u001b[30m\u001b[43m, ethnicity, or national origin\u001b[0m, which is un-American and counterproductive.\n",
      "  -  22110_199405-314415-1 (1.00):  In addition, the government enables \u001b[30m\u001b[43mmembers of ethnic groups\u001b[0m to maintain a lively connection with their own language and culture.\n",
      "  -  11710_201409-399392-2 (1.00):  A Sweden where all citizens, regardless of \u001b[30m\u001b[43mrace and ethnicity\u001b[0m, have the same basic right to land and water in all parts of Sweden.\n",
      "  -   21914_199906-49863-2 (1.00):  The wave of naturalization of the last few years has obviously caused many organizations called Belgian to actually consist of \u001b[30m\u001b[43mindividuals belonging to one of the aforementioned ethnic groups\u001b[0m.\n",
      "\n",
      "  ~> \u001b[1m\u001b[3mfalse negatives\u001b[0m\n",
      "  -  31720_200206-209343-1 (1.00):  \u001b[30m\u001b[43mForeign political agitators acting under the cover of Islam\u001b[0m will be expelled without weakness.\n",
      "  -  15111_201710-281205-1 (1.00):  Insurance needs access to a diversified culture in \u001b[30m\u001b[43ma multicultural society\u001b[0m.\n",
      "  -  86421_201804-274166-1 (1.00):  Christianity has traditionally been interpreted as a question of faith, and it is for \u001b[30m\u001b[43mmany of us\u001b[0m.\n",
      "  -   21111_199111-32560-1 (1.00):  Immigration: \u001b[30m\u001b[43mA multicultural society\u001b[0m.\n",
      "  -  11110_200609-393935-1 (1.00):  We want to raise damages to \u001b[30m\u001b[43mindividuals who are discriminated against by companies or government agencies\u001b[0m.\n",
      "\n",
      "\u001b[1mnoneconomic__shared_values_mentalities\u001b[0m\n",
      "  ~> \u001b[1m\u001b[3mfalse positives\u001b[0m\n",
      "  -  61320_202011-434242-7 (1.00):  Democrats will support measures to improve training and education for judges, corrections officers, prosecutors, public defenders, and police officers to ensure transgender and \u001b[30m\u001b[43mgender non-conforming people\u001b[0m receive fair and equitable treatment in the criminal justice system.\n",
      "  -  31110_200206-209041-2 (1.00):  The Greens propose to experiment with new ways, to look at the situation across the globe, to improve the quality of life in everyday life to combat social inequalities, to end the gap between those who make decisions and \u001b[30m\u001b[43mthose who are undergoing profound democratic reforms\u001b[0m.\n",
      "  -   42710_200610-13573-1 (1.00):  \u001b[30m\u001b[43mForeigners who do not meet the requirements of the integration agreement\u001b[0m are therefore not willing to integrate.\n",
      "  -  92712_199110-359840-1 (1.00):  \u001b[30m\u001b[43mA professional group that sees the enormous insecurity of the nation\u001b[0m.\n",
      "  -  32630_201302-287800-2 (1.00):  One part comes from the evasion of SMEs and another residual from \u001b[30m\u001b[43mself-employed workers\u001b[0m.\n",
      "  -   80710_201410-95182-1 (1.00):  With the energy of \u001b[30m\u001b[43mthose who have proven to work for the Bulgarian cause\u001b[0m.\n",
      "\n",
      "  ~> \u001b[1m\u001b[3mfalse negatives\u001b[0m\n",
      "  -  13951_197312-181349-1 (1.00):  On all other points, the Progress Party freely sets \u001b[30m\u001b[43mits supporters\u001b[0m, but it is highlighted that the overwhelming majority of the Party agrees with the following views:\n",
      "  -  61320_202011-434466-3 (1.00):  We will hold accountable those who engage in or enable violent or other illegal activity targeting religious minorities, including by directing the federal government to address the growing and violent threat of white supremacist, \u001b[30m\u001b[43mneo-Nazi\u001b[0m and anti-government groups.\n",
      "  -  96710_199006-377854-1 (1.00):  The Slovak National Party (SNS) is an association of \u001b[30m\u001b[43mthose members of the Slovak nation who are concerned with their future destiny at home, in Europe and in the world\u001b[0m.\n",
      "  -  61320_202011-434466-4 (1.00):  We will hold accountable those who engage in or enable violent or other illegal activity targeting religious minorities, including by directing the federal government to address the growing and violent threat of white supremacist, neo-Nazi and \u001b[30m\u001b[43manti-government groups\u001b[0m.\n",
      "  -  12951_200509-337528-2 (1.00):  The policy of the Progress Party is based on the liberal idea that prioritizes the right of all men to live as \u001b[30m\u001b[43mfree and self-sufficient individuals\u001b[0m, as long as they do not unjustifiably interfere with other people's right to free and independent life.\n",
      "  -  43110_201910-107382-1 (1.00):  Only \u001b[30m\u001b[43mthose who are transparently informed\u001b[0m can choose sustainable, fair and healthy products and services.\n",
      "  -  22110_201006-322802-1 (1.00):  From \u001b[30m\u001b[43mshareholders and managers who merely measure the performance of companies to the short-term profit\u001b[0m.\n",
      "  -  31110_201206-217114-2 (1.00):  a taxation supporting SMEs and local and environmentally friendly crafts: creation of a “sustainable development bonus” for \u001b[30m\u001b[43mthose whose field of activity contributes to the environmental transition\u001b[0m;\n",
      "  -  82720_201310-117539-1 (1.00):  Only \u001b[30m\u001b[43mthose who lead an orderly life and educate children properly\u001b[0m deserve support.\n",
      "  -  13720_201506-194129-1 (1.00):  Including \u001b[30m\u001b[43mthe elderly, who have built up the Danish society and have difficulty coping with themselves\u001b[0m.\n",
      "  -  51620_200505-235163-1 (1.00):  \u001b[30m\u001b[43mParents who work hard to give their children the best start in life\u001b[0m need a government that is on their side.\n",
      "  -   42420_201710-19827-1 (1.00):  The goal of European integration must be the community of those states that geographically, spiritually and culturally make up Europe and have committed themselves to Western values, to the heritage of cultures and traditions of \u001b[30m\u001b[43mthe European peoples\u001b[0m.\n",
      "  -  51620_199705-230533-1 (1.00):  \u001b[30m\u001b[43mA civilised society\u001b[0m respects its animals.\n",
      "  -  14110_200703-198908-1 (1.00):  This creates \u001b[30m\u001b[43ma creative society\u001b[0m.\n",
      "  -  41111_198701-123538-9 (1.00):  The Federal Republic must acknowledge its responsibility to the victims of fascism and recognize the compensation demands of all the victims of the Nazi, especially the Roma and Sinti, the Jewish people, the homosexuals, the forced sterilized, the survivors of the \"ethanasia\" actions, the resistance fighters and \u001b[30m\u001b[43mthe so-called associalists\u001b[0m.\n",
      "  -  92436_200509-360961-1 (1.00):  \u001b[30m\u001b[43mOrdinary people who practice sports\u001b[0m have fewer healthcare expenditures, fewer pathologies and better development prospects.\n",
      "  -  11620_199109-391248-1 (1.00):  \u001b[30m\u001b[43mA subsidiary society\u001b[0m becomes a dependent society.\n",
      "  -   43110_198710-98339-1 (1.00):  In the face of any ideological differences, promoting the cooperation of \u001b[30m\u001b[43mall the green forces\u001b[0m is our primary concern.\n",
      "  -  14820_197903-197512-1 (1.00):  Do not submit to \u001b[30m\u001b[43mthe betrayers of your promises\u001b[0m.\n",
      "  -  86710_201804-274934-1 (1.00):  The same is needed for \u001b[30m\u001b[43myoung people who are unable or unwilling to integrate into the normal educational system because of their behavioral problems\u001b[0m.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "highlight = lambda text, mention: text.replace(mention, '\\u001B[30m\\u001B[43m'+mention+'\\033[0m')\n",
    "\n",
    "threshold = 1/3\n",
    "label_id_2_error_type = {0: 'false positives', 1: 'false negatives'}\n",
    "for a, tmp in error_rates_df.groupby('attribute'):\n",
    "    print(f\"\\033[1m{a}\\033[0m\")\n",
    "    for l, subdf in tmp.groupby('label'):\n",
    "        # print attribute name in bold\n",
    "        print(f\"  ~> \\033[1m\\033[3m{label_id_2_error_type[l]}\\033[0m\")\n",
    "        for i, row in subdf[subdf['error'] > threshold].head(20).iterrows():\n",
    "            highlighted_text = highlight(row['text'], row['mention'])\n",
    "            print(f\"  - {row['mention_id'].rjust(22)} ({row['error']:.2f}):  {highlighted_text}\")\n",
    "        print()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "galtan_group_appeals",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
