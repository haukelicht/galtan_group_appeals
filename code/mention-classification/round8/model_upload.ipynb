{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "60200e90",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "base_path = Path('../../../')\n",
    "data_path = base_path / 'data' / 'annotations' / 'group_mention_categorization'\n",
    "models_path = base_path / 'models'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c3c35277",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[PosixPath('../../../models/all-mpnet-base-v2_economic-attributes-classifier'),\n",
       " PosixPath('../../../models/all-mpnet-base-v2_noneconomic-attributes-classifier'),\n",
       " PosixPath('../../../models/economic__occupation_professionmention_clustering_model'),\n",
       " PosixPath('../../../models/modelcard_metadata_template.yml'),\n",
       " PosixPath('../../../models/mention_stance_nli'),\n",
       " PosixPath('../../../models/social-group-mention-econ-attributes-classifier'),\n",
       " PosixPath('../../../models/social-group-mention-nonecon-attributes-classifier'),\n",
       " PosixPath('../../../models/modelcards_data.yml'),\n",
       " PosixPath('../../../models/social-group-mention-attribute-dimension-classifier-v2'),\n",
       " PosixPath('../../../models/temp_upload_all-mpnet-base-v2_noneconomic-attributes-classifier'),\n",
       " PosixPath('../../../models/social-group-mention-stance-classifier'),\n",
       " PosixPath('../../../models/social-group-mention-attribute-dimension-classifier-v3'),\n",
       " PosixPath('../../../models/modelcard_template.md'),\n",
       " PosixPath('../../../models/temp_upload_all-mpnet-base-v2_economic-attributes-classifier'),\n",
       " PosixPath('../../../models/all-mpnet-base-v2_mention-economic-attributes-classifier')]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# list folder ins models_path\n",
    "list(models_path.glob(\"*\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d3f67870",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e5271557",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sentence-transformers==5.1.0\n",
      "transformers==4.57.1\n",
      "setfit==1.1.2\n"
     ]
    }
   ],
   "source": [
    "!pip freeze | grep transformers\n",
    "!pip freeze | grep setfit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "92362a27",
   "metadata": {},
   "outputs": [],
   "source": [
    "usage_template = \"\"\"\\\n",
    "\n",
    "## Usage\n",
    "\n",
    "You can use the model with the [`setfit` python library](https://github.com/huggingface/setfit) (>=1.1.0):\n",
    "\n",
    "*Note:* It is recommended to use transformers version >=4.5.5,<=5.0.0 and sentence-transformers version >=4.0.1,<=5.1.0 for compatibility.\n",
    "\n",
    "### Classification\n",
    "\n",
    "```python\n",
    "import torch\n",
    "from setfit import SetFitModel\n",
    "\n",
    "model_name = \"haukelicht/{model_name}\"\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"mps\" if torch.backends.mps.is_available() else \"cpu\"\n",
    "classifier = SetFitModel.from_pretrained(model_name)\n",
    "classifier.to(device);\n",
    "\n",
    "# Example mentions\n",
    "mentions = [\"working class people\", \"highly-educated professionals\", \"people without a stable job\"]\n",
    "\n",
    "# Get predictions\n",
    "with torch.no_grad():\n",
    "    predictions = classifier.predict(mentions)\n",
    "print(predictions)\n",
    "\n",
    "# Map predictions to labels\n",
    "[\n",
    "    [\n",
    "        classifier.id2label[l]\n",
    "        for l, p in enumerate(pred) if p==1\n",
    "    ]\n",
    "    for pred in predictions\n",
    "]\n",
    "```\n",
    "\n",
    "### Mention embedding\n",
    "\n",
    "```python\n",
    "import torch\n",
    "from sentence_transformers import SentenceTransformer\n",
    "\n",
    "model_name = \"haukelicht/{model_name}\"\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"mps\" if torch.backends.mps.is_available() else \"cpu\"\n",
    "\n",
    "# Load the sentence transformer component of the pre-trained classifier\n",
    "model = SentenceTransformer(model_name, device=device)\n",
    "\n",
    "# Example mentions\n",
    "mentions = [\"working class people\", \"highly-educated professionals\", \"people without a stable job\"]\n",
    "\n",
    "# Compute mention embeddings\n",
    "with torch.no_grad():\n",
    "    embeddings = model.encode(mentions)\n",
    "````\n",
    "\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e5a74836",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "fp = data_path / 'attribute_definitions.json'\n",
    "#data/annotations/group_mention_categorization/attribute_definitions.jsonl\n",
    "with open(fp, 'r') as f:\n",
    "    attributes_definitions = json.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "040252f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "econ_tab = pd.DataFrame([attributes_definitions[\"economic\"]], index=['definition']).T.reset_index(names=['attribute'])\n",
    "nonecon_tab = pd.DataFrame([attributes_definitions[\"non-economic\"]], index=['definition']).T.reset_index(names=['attribute'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ddec4ddf",
   "metadata": {},
   "outputs": [],
   "source": [
    "econ_desc = f\"\"\"\\\n",
    "A multi-label classifier for detecting **economic attribute** categories referred to in a social group mention, trained with `setfit` based on the light-weight [`sentence-transformers/all-mpnet-base-v2`](https://huggingface.co/sentence-transformers/all-mpnet-base-v2) sentence embedding model.\n",
    "\n",
    "The economic attributes classified are:\n",
    "\n",
    "{econ_tab.to_markdown(index=False)}\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "d5535c37",
   "metadata": {},
   "outputs": [],
   "source": [
    "nonecon_desc = f\"\"\"\\\n",
    "A multi-label classifier for detecting **non-economic attribute** categories referred to in a social group mention, trained with `setfit` based on the light-weight [`sentence-transformers/all-mpnet-base-v2`](https://huggingface.co/sentence-transformers/all-mpnet-base-v2) sentence embedding model.\n",
    "\n",
    "The non-economic attributes classified are:\n",
    "\n",
    "{nonecon_tab.to_markdown(index=False)}\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "bf3506b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "default_tags = [\"mention-classification\", \"mpnet-base-v2\", \"setfit\", \"multi-label-classification\"]\n",
    "\n",
    "model_dict = {\n",
    "    \"all-mpnet-base-v2_economic-attributes-classifier\": {\n",
    "        \"title\": \"Group mention economic attributes classifier\",\n",
    "        \"tags\": [\"economic-attributes\", *default_tags],\n",
    "        \"description\": econ_desc,\n",
    "        \"license\": \"apache-2.0\",\n",
    "    },\n",
    "    \"all-mpnet-base-v2_noneconomic-attributes-classifier\":  {\n",
    "        \"title\": \"Group mention non-economic attributes classifier\",\n",
    "        \"tags\": [\"noneconomic-attributes\", *default_tags],\n",
    "        \"description\": nonecon_desc,\n",
    "        \"license\": \"apache-2.0\",\n",
    "    }\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3183a24d",
   "metadata": {},
   "source": [
    "### Save models as seet fit "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "f94a9db2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create temp directories per model\n",
    "temp_model_dirs = {}\n",
    "for model_name, model_info in model_dict.items():\n",
    "    temp_model_dir = models_path / f'temp_upload_{model_name}'\n",
    "    temp_model_dir.mkdir(exist_ok=True)\n",
    "    temp_model_dirs[model_name] = temp_model_dir"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "33060838",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from setfit import SetFitModel, SetFitHead\n",
    "\n",
    "for model_name, model_info in model_dict.items():\n",
    "\n",
    "    # Use the correct model path for each model\n",
    "    model_path = models_path / model_name\n",
    "    model = SetFitModel.from_pretrained(model_path)\n",
    "    model.to(\"cpu\")\n",
    "\n",
    "    # Create a new standard SetFitHead with the same configuration\n",
    "    new_head = SetFitHead(\n",
    "        model.model_head.in_features,\n",
    "        model.model_head.out_features,\n",
    "        device=\"cpu\",\n",
    "        multitarget=model.model_head.multitarget\n",
    "    )\n",
    "    new_head.to(\"cpu\")\n",
    "\n",
    "    # Get the state dict and ensure all tensors are in normal mode\n",
    "    original_state_dict = model.model_head.state_dict()\n",
    "    \n",
    "    # Use torch.no_grad() to ensure we're not in inference mode when creating new tensors\n",
    "    with torch.no_grad():\n",
    "        new_state_dict = {}\n",
    "        for key, tensor in original_state_dict.items():\n",
    "            # Create a new tensor with the same data but ensure it's a normal tensor\n",
    "            new_tensor = torch.tensor(tensor.cpu().numpy(), dtype=tensor.dtype, device=\"cpu\")\n",
    "            new_state_dict[key] = new_tensor\n",
    "    \n",
    "    # Load the cleaned state dict into the new head\n",
    "    new_head.load_state_dict(new_state_dict)\n",
    "\n",
    "    # Replace the model head with the new standard SetFitHead\n",
    "    model.model_head = new_head\n",
    "\n",
    "    # Ensure everything is properly set to training mode and then eval mode\n",
    "    model.model_body.train()  # Set to training mode first to ensure normal tensor behavior\n",
    "    model.model_body.eval()   # Then set to eval mode for inference\n",
    "    model.model_head.train()   # Then set to eval mode for inference\n",
    "    model.model_head.eval()   # Then set to eval mode for inference\n",
    "    model.to(\"cpu\")\n",
    "\n",
    "    model.save_pretrained(temp_model_dirs[model_name])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "39e99523",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<setfit.modeling.SetFitModel at 0x7ede29502410>"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "SetFitModel.from_pretrained(temp_model_dirs[model_name])  # test load"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "57ca1ebb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import pandas as pd\n",
    "\n",
    "# def parse_test_results(fp):\n",
    "#     with open(fp, 'r') as f:\n",
    "#         res = json.load(f)\n",
    "\n",
    "#     res_df = pd.DataFrame.from_dict(res, orient='index', columns=['value']).reset_index(names='tmp')\n",
    "#     res_df[['scheme', 'tmp']] = res_df.tmp.str.replace('test_', '').str.split('-', n=1, expand=True)\n",
    "#     res_df = res_df[res_df.tmp.notnull()]\n",
    "#     res_df[['type', 'metric']] = res_df.tmp.str.split('_', expand=True)\n",
    "\n",
    "#     schemes = ['seqeval', 'softseqeval', 'doclevel']\n",
    "#     res_df = res_df.query(\"scheme in @schemes and metric=='f1' and type in @GROUP_TYPES\")\n",
    "\n",
    "#     res_df = res_df.pivot_table(index='type', columns='scheme', values='value', aggfunc='first').reset_index()\n",
    "#     res_df['type'] = pd.Categorical(res_df.type, categories=GROUP_TYPES, ordered=True)\n",
    "#     res_df.columns.name = None\n",
    "#     res_df = res_df.sort_values('type')\n",
    "\n",
    "\n",
    "#     return res_df[['type']+schemes]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "645c71f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# schemes_dict = {\n",
    "#     'seqeval': 'seq-eval F1',\n",
    "#     'softseqeval': 'soft seq-eval  F1',\n",
    "#     'doclevel': 'sentence level  F1'\n",
    "# }\n",
    "\n",
    "# def results_to_metrics_entries(x, schemes):\n",
    "#     res_df = x.copy()\n",
    "#     res_df.rename(columns={'type': 'name'}, inplace=True)\n",
    "#     res_df = res_df.melt(id_vars='name', var_name='type', value_name='value')\n",
    "#     if isinstance(schemes, dict):\n",
    "#         res_df = res_df[res_df['type'].isin(schemes.keys())]\n",
    "#         res_df['type'] = res_df['type'].map(schemes)\n",
    "#     elif isinstance(schemes, list):\n",
    "#         res_df = res_df[res_df['type'].isin(schemes)]\n",
    "#     elif isinstance(schemes, str):\n",
    "#         res_df = res_df[res_df['type'].isin([schemes])]\n",
    "#     res_df['name'] = res_df.apply(lambda x: f\"{x['name']} ({x['type']})\", axis=1)\n",
    "#     return res_df[['type', 'name', 'value']].to_dict(orient='records')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "1bcfc100",
   "metadata": {},
   "outputs": [],
   "source": [
    "# results_to_markdown_table = lambda res_df, schemes=schemes_dict: res_df.rename(columns=schemes).to_markdown(index=False, tablefmt='github', floatfmt=\".3f\", colalign=(\"right\", \"center\", \"center\", \"center\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f4ae214",
   "metadata": {},
   "source": [
    "### parse and fill"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "f71b6f35",
   "metadata": {},
   "outputs": [],
   "source": [
    "import yaml\n",
    "from jinja2 import Template\n",
    "\n",
    "# Load templates\n",
    "with open(models_path / \"modelcard_metadata_template.yml\") as f:\n",
    "    meta_template = Template(f.read())\n",
    "with open(models_path / \"modelcard_template.md\") as f:\n",
    "    body_template = Template(f.read())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "ce3653b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(models_path / 'modelcards_data.yml', 'r') as f:\n",
    "    modelcard_data = yaml.safe_load(f)\n",
    "\n",
    "models = modelcard_data.pop(\"finetunes\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "a27230c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import regex\n",
    "def create_readme(model_name: str, title: str, description: str, tags: list):\n",
    "    # fp = models_path / model_name\n",
    "    # res_df = parse_test_results(fp)\n",
    "    # test_res = results_to_metrics_entries(res_df, schemes='seqeval')\n",
    "    # results_table = results_to_markdown_table(res_df, schemes=schemes_dict)\n",
    "\n",
    "    model_data = models[model_name]\n",
    "    model_data[\"model_description\"] = title\n",
    "    model_data[\"model_summary\"] = description\n",
    "    model_data[\"get_started_code\"] = usage_template.format(model_name=model_name)\n",
    "    model_data[\"tags\"] = tags\n",
    "    metadata = {\n",
    "        'model_id': model_name,\n",
    "        # **{'test_results': test_res},\n",
    "        **{k: v for k, v in modelcard_data.items() if v is not None},\n",
    "        **model_data\n",
    "    }\n",
    "    metadata = meta_template.render(metadata)\n",
    "    metadata = regex.sub(r'(\\n\\h*){3,}', '\\n', metadata)\n",
    "    body_data = {\n",
    "        'model_id': title,\n",
    "        **modelcard_data,\n",
    "        **model_data,\n",
    "        # **{'results': results_table}\n",
    "    }\n",
    "    body = body_template.render(body_data)\n",
    "    # remove comment lines in body\n",
    "    body = regex.sub(r'^\\s*<!--.*?-->\\s*$', '', body, flags=regex.MULTILINE)\n",
    "    body = regex.sub(r'\\n{3,}', '\\n\\n', body)\n",
    "    body = regex.sub(r'(\\n\\h*){3,}', '\\n\\n', body)\n",
    "    # remove (sub)sections where there is no content or only \"[More Information Needed]\"\n",
    "    body = regex.sub(r'##+\\s+.*?\\n+(?:\\s*\\[More Information Needed\\]\\s*\\n*)+', '', body)\n",
    "\n",
    "    return metadata+'\\n\\n'+body+'\\n'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "32120bd2",
   "metadata": {},
   "outputs": [],
   "source": [
    "readmes = {}\n",
    "for model_name, model_info in model_dict.items():\n",
    "    readme = create_readme(\n",
    "        model_name=model_name,\n",
    "        title=model_info['title'],\n",
    "        description=model_info['description'],\n",
    "        tags=model_info['tags']\n",
    "    )\n",
    "    with open(temp_model_dirs[model_name] / 'README.md', 'w') as f:\n",
    "        f.write(readme)\n",
    "    readmes[model_name] = readme"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "700a6073",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['all-mpnet-base-v2_economic-attributes-classifier',\n",
       " 'all-mpnet-base-v2_noneconomic-attributes-classifier']"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "models_names = list(model_dict.keys())\n",
    "models_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "3fd100fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "from huggingface_hub import login, create_repo, upload_folder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "72d3b584",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7cfc92c8f4dc444e81cb3bbf49d60d88",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Processing Files (0 / 0): |          |  0.00B /  0.00B            "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "06f967a6e945451e91d0bbe54442d55d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "New Data Upload: |          |  0.00B /  0.00B            "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "CommitInfo(commit_url='https://huggingface.co/haukelicht/all-mpnet-base-v2_economic-attributes-classifier/commit/99bd01e05034ff85fcd5c7f875ca39b93a1e40f5', commit_message='used native setfit head', commit_description='', oid='99bd01e05034ff85fcd5c7f875ca39b93a1e40f5', pr_url=None, repo_url=RepoUrl('https://huggingface.co/haukelicht/all-mpnet-base-v2_economic-attributes-classifier', endpoint='https://huggingface.co', repo_type='model', repo_id='haukelicht/all-mpnet-base-v2_economic-attributes-classifier'), pr_revision=None, pr_num=None)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_name = models_names[0]\n",
    "model_id = f\"haukelicht/{model_name}\"\n",
    "model_path = temp_model_dirs[model_name]\n",
    "\n",
    "create_repo(\n",
    "    repo_id=model_id,  # Just the model name if you want it at root\n",
    "    repo_type=\"model\",\n",
    "    private=False,  # or True if you want it private\n",
    "    exist_ok=True   # avoids error if it already exists\n",
    ")\n",
    "\n",
    "upload_folder(\n",
    "    repo_type=\"model\",\n",
    "    repo_id=model_id,\n",
    "    folder_path=model_path,\n",
    "    commit_message=\"used native setfit head\",\n",
    "    create_pr=False,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "ae664cfa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7fe088e12637457d8149ae8ac351fad0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Processing Files (0 / 0): |          |  0.00B /  0.00B            "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2adaeb930f194f318af984d82015b934",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "New Data Upload: |          |  0.00B /  0.00B            "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "CommitInfo(commit_url='https://huggingface.co/haukelicht/all-mpnet-base-v2_noneconomic-attributes-classifier/commit/5955e841ee249909e1609bbf8465bd0cce33afff', commit_message='used native setfit head', commit_description='', oid='5955e841ee249909e1609bbf8465bd0cce33afff', pr_url=None, repo_url=RepoUrl('https://huggingface.co/haukelicht/all-mpnet-base-v2_noneconomic-attributes-classifier', endpoint='https://huggingface.co', repo_type='model', repo_id='haukelicht/all-mpnet-base-v2_noneconomic-attributes-classifier'), pr_revision=None, pr_num=None)"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_name = models_names[1]\n",
    "model_id = f\"haukelicht/{model_name}\"\n",
    "model_path = temp_model_dirs[model_name]\n",
    "\n",
    "create_repo(\n",
    "    repo_id=model_id,  # Just the model name if you want it at root\n",
    "    repo_type=\"model\",\n",
    "    private=False,  # or True if you want it private\n",
    "    exist_ok=True   # avoids error if it already exists\n",
    ")\n",
    "\n",
    "upload_folder(\n",
    "    repo_type=\"model\",\n",
    "    repo_id=model_id,\n",
    "    folder_path=model_path,\n",
    "    commit_message=\"used native setfit head\",\n",
    "    create_pr=False,\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "galtan_group_appeals",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
