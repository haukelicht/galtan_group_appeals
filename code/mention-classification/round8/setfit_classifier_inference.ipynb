{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# determine if current environment is a python script\n",
    "is_python_script = '__file__' in globals()\n",
    "\n",
    "# evaluate below if run as a python script\n",
    "if is_python_script:\n",
    "    from argparse import ArgumentParser\n",
    "    parser = ArgumentParser()\n",
    "\n",
    "    parser.add_argument('--input_file', type=str, required=True, help='Path to input TSV file containing sentences with predicted group mentions.')\n",
    "    parser.add_argument('--sentence_text_col', type=str, default='sentence_text', help='Name of the column containing the sentence text.')\n",
    "    parser.add_argument('--mention_text_col', type=str, default='text', help='Name of the column containing the mention text.')\n",
    "    parser.add_argument('--group_mention_types', type=str, required=True, help='Comma-separated list of group mention types to classify (e.g., \"social group\").')\n",
    "    parser.add_argument('--group_mention_type_col', type=str, default='label', help='Name of the column containing the group mention type labels.')\n",
    "    \n",
    "    parser.add_argument('--model_path', type=str, required=True, help='Path to the pre-trained SetFit model for classification.')\n",
    "    parser.add_argument('--use_span_embeddings', action='store_true', help='Whether to use custom SeFitForSpanClassification Trainer instead of mention and text concatenation or mention-only strategies')\n",
    "    parser.add_argument('--concat_strategy', type=str, choices=[None, 'prefix', 'suffix'], default=None, help='If not None, concatenate the mention text as prefix or suffix to the context text using --concat_sep_token')\n",
    "    parser.add_argument('--concat_sep_token', type=str, default=': ', help='Separator token to use when concatenating mention text to context text')\n",
    "    parser.add_argument('--batch_size', type=int, default=64, help='Batch size for inference.')\n",
    "\n",
    "    parser.add_argument('--output_file', type=str, required=True, help='Path to output TSV file to save predictions.')\n",
    "\n",
    "    parser.add_argument('--test', action='store_true', help='If set, run in test mode with a smaller subset of data.')\n",
    "    parser.add_argument('--verbose', action='store_true', help='If set, print verbose output during processing.')\n",
    "    \n",
    "    args = parser.parse_args()\n",
    "else:\n",
    "\n",
    "    from types import SimpleNamespace\n",
    "\n",
    "    args = SimpleNamespace()\n",
    "\n",
    "    args.input_file = './../../../data/labeled/manifesto_sentences_predicted_group_mentions_spans.tsv'\n",
    "    args.sentence_text_col = 'sentence_text'\n",
    "    args.mention_text_col = 'text'\n",
    "    args.group_mention_types = 'social group'\n",
    "    args.group_mention_type_col = 'label'\n",
    "\n",
    "    args.model_path = './../../../models/all-mpnet-base-v2_economic-attributes-classifier'\n",
    "    # args.model_path = './../../../models/all-mpnet-base-v2_noneconomic-attributes-classifier'\n",
    "    args.use_span_embeddings = False # or True\n",
    "    args.concat_strategy = None # 'prefix', 'suffix' or None\n",
    "    args.concat_sep_token = ': '  # separator token for prefix/suffix concatenation\n",
    "\n",
    "    args.batch_size = 64\n",
    "\n",
    "    args.output_file = './../../../data/labeled/manifesto_sentences_predicted_social_group_mentions_with_economic_attributes_classifications.tsv'\n",
    "    # args.output_file = './../../../data/labeled/manifesto_sentences_predicted_social_group_mentions_with_noneconomic_attributes_classifications.tsv'\n",
    "\n",
    "    args.test = False\n",
    "    args.verbose = True\n",
    "\n",
    "    args.group_mention_types = [t.strip() for t in args.group_mention_types.split(',')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import regex\n",
    "\n",
    "import torch\n",
    "from setfit import SetFitModel\n",
    "from src.finetuning.setfit_extensions import SetFitModelForSpanClassification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model\n",
      "using device: cuda:0\n"
     ]
    }
   ],
   "source": [
    "if args.verbose: print(f'Loading model')\n",
    "device = 'cuda:0' if torch.cuda.is_available() else 'mps' if torch.backends.mps.is_available() else 'cpu'\n",
    "device = torch.device(device)\n",
    "if args.verbose: print('using device:', str(device))\n",
    "\n",
    "classifier = SetFitModelForSpanClassification.from_pretrained(args.model_path) if args.use_span_embeddings else SetFitModel.from_pretrained(args.model_path)\n",
    "classifier.to(device);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import torch\n",
    "# from setfit import SetFitModel\n",
    "\n",
    "# # model_name = \"hauke-licht/{model_name}\"\n",
    "# device = \"cuda\" if torch.cuda.is_available() else \"mps\" if torch.backends.mps.is_available() else \"cpu\"\n",
    "# classifier = SetFitModel.from_pretrained(model_name, device=device)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1 0 0 0 0 0]\n",
      " [0 0 0 0 0 1]\n",
      " [0 0 0 1 1 0]]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[['economic__class_membership'],\n",
       " ['economic__occupation_profession'],\n",
       " ['economic__employment_status', 'economic__income_wealth_economic_status']]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "# Example texts\n",
    "texts = [\"working class people\", \"highly-educated professionals\", \"people without a stable job\"]\n",
    "\n",
    "# Get predictions\n",
    "predictions = classifier.predict(texts, as_numpy=True)\n",
    "print(predictions)\n",
    "\n",
    "[\n",
    "    [\n",
    "        classifier.id2label[l] \n",
    "        for l, p in enumerate(pred) if p==1\n",
    "    ]\n",
    "    for pred in predictions\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "processing 209351 texts\n"
     ]
    }
   ],
   "source": [
    "# read the input file\n",
    "sep = None\n",
    "if args.input_file.endswith('.tsv') or args.input_file.endswith('.tab'):\n",
    "    sep = '\\t'\n",
    "elif args.input_file.endswith('.csv'):\n",
    "    sep = ','\n",
    "else:\n",
    "    raise ValueError('input file must be a tab-separated (.tsv, .tab) or comma-separated (.csv) file')\n",
    "\n",
    "df = pd.read_csv(args.input_file, sep=sep)\n",
    "\n",
    "if args.group_mention_type_col:\n",
    "    df.rename(columns={args.group_mention_type_col: 'group_type'}, inplace=True)\n",
    "if args.group_mention_types:\n",
    "    df = df[df['group_type'].isin(args.group_mention_types)]\n",
    "\n",
    "if args.test:\n",
    "    n_ = args.batch_size*1000\n",
    "    if n_ < len(df):\n",
    "        df = df.sample(n=n_, random_state=42).reset_index(drop=True)\n",
    "\n",
    "if args.verbose: print(f'processing {len(df)} texts')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "if args.use_span_embeddings:\n",
    "    if \"span\" not in df.columns:\n",
    "    # using span embedding strategy\n",
    "        df['span'] = df.apply(lambda x: regex.search(regex.escape(x[args.mention_text_col]), x[args.sentence_text_col]).span(), axis=1)\n",
    "    df['input'] = classifier._normalize_inputs(texts=df[args.sentence_text_col], spans=df['span'])\n",
    "elif args.concat_strategy is None:\n",
    "    # default: just the mention text\n",
    "    df['input'] = df[args.mention_text_col]\n",
    "else:\n",
    "    # using concat strategy\n",
    "    sep_tok = classifier.model_body.tokenizer.sep_token if args.concat_sep_token is None else args.concat_sep_token\n",
    "    if args.concat_strategy == 'prefix':\n",
    "        df['input'] = df[args.mention_text_col] + sep_tok + df[args.sentence_text_col]\n",
    "    elif args.concat_strategy == 'suffix':\n",
    "        df['input'] = df[args.sentence_text_col] + sep_tok + df[args.mention_text_col]\n",
    "    else:\n",
    "        raise ValueError(f\"Unknown concat strategy: {args.concat_strategy}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d6c5466364414876b3411f14011b2b70",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/3272 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "preds = classifier.predict(df['input'].to_list(), batch_size=args.batch_size, as_numpy=True, use_labels=False, show_progress_bar=True)\n",
    "label_cols = list(classifier.label2id.keys())\n",
    "df[classifier.labels] = preds\n",
    "del df[\"input\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing mention-level predicted labels to ./../../../data/labeled/manifesto_sentences_predicted_social_group_mentions_with_noneconomic_attributes_classifications.tsv\n"
     ]
    }
   ],
   "source": [
    "if args.verbose: print(f'Writing mention-level predicted labels to {args.output_file}')\n",
    "df.to_csv(args.output_file, sep='\\t', index=False, encoding='utf-8')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "galtan_group_appeals",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
