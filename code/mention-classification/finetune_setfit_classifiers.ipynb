{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "552ec552",
   "metadata": {},
   "source": [
    "# Social group mention attribute category and attributes multilabel text classification\n",
    "\n",
    "We have collected human annotations that categorize mentions of social groups in party manifestos into the following (hierarchical) scheme of attribute dimensions and attribute classes:\n",
    "\n",
    "- economic attributes\n",
    "    - class membership\n",
    "    - ecology of group\n",
    "    - education level\n",
    "    - employment status\n",
    "    - income/wealth/economic status\n",
    "    - occupation/profession\n",
    "    - other\n",
    "- non-economic attributes:\n",
    "   - age\n",
    "   - crime\n",
    "   - ethnicity\n",
    "   - family\n",
    "   - gender/sexuality\n",
    "   - health\n",
    "   - nationality\n",
    "   - other\n",
    "   - place/location\n",
    "   - religion\n",
    "   - shared values/mentalities\n",
    "- universal\n",
    "\n",
    "In this notebook, we fine-tune a pre-trained sentence transformer model for multilabel classifiers using the `setfit` library to categorize into which attribute dimensions social group mentions belong."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3af7f258-5aaf-47c2-b81e-2f10fc349812",
   "metadata": {},
   "source": [
    "notebook based on https://github.com/huggingface/setfit/blob/main/notebooks/text-classification_multilabel.ipynb\n",
    "\n",
    "See also:\n",
    "\n",
    "- https://huggingface.co/docs/setfit/en/how_to/multilabel\n",
    "- https://github.com/huggingface/setfit/issues/413#issuecomment-1697751329"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c5604f73-f395-42cb-8082-9974a87ef9e9",
   "metadata": {},
   "source": [
    "## Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "50cfb2ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "70a859ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import regex\n",
    "\n",
    "import torch\n",
    "import datasets\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from utils.setfit import get_class_weights, model_init, TrainerForSpanClassification\n",
    "\n",
    "from transformers import AutoTokenizer, set_seed\n",
    "from setfit import TrainingArguments, Trainer\n",
    "\n",
    "from utils.metrics import *\n",
    "\n",
    "from pathlib import Path\n",
    "\n",
    "data_path = Path('../../data/annotations/group_mention_categorization')\n",
    "model_path = Path('../../models/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "101e20b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "SEED = 42\n",
    "set_seed(SEED)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "1c003a63",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_id = 'sentence-transformers/paraphrase-mpnet-base-v2'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e756be8-3b60-4c86-aa1b-7ef78289b8e2",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Preparing the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "8c55d2d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "fp = data_path / 'final_annotations.tsv'\n",
    "annotations = pd.read_csv(fp, sep='\\t')\n",
    "ignore = ['stance: ', 'universal: ']\n",
    "annotations.query(\"attribute_combination not in @ignore\", inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "cbb59179",
   "metadata": {},
   "outputs": [],
   "source": [
    "# gather attribute combinations with label=='Yes' at the mention level\n",
    "mentions_df = annotations.groupby(['mention_id', 'text', 'mention'])[['attribute_combination', 'label']].apply(lambda x: sorted(set(x.attribute_combination[x.label=='Yes']))).reset_index()\n",
    "mentions_df.rename(columns={0: 'attributes'}, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29159833",
   "metadata": {},
   "source": [
    "## Universal/econ/non-econ as three-way multilabel problem"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0697edf",
   "metadata": {},
   "source": [
    "### Prepare the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "2cd9da92",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "annotations.q_id.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "1424bdd7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# stack by category\n",
    "df = pd.concat([\n",
    "    annotations[annotations.q_id == 'economic_attributes'].groupby(['mention_id', 'text', 'mention', 'q_id']).agg({'label': lambda x: 'Yes' if (x=='Yes').any() else 'No'}).reset_index(),\n",
    "    annotations[annotations.q_id == 'non-economic_attributes'].groupby(['mention_id', 'text', 'mention', 'q_id']).agg({'label': lambda x: 'Yes' if (x=='Yes').any() else 'No'}).reset_index()\n",
    "])\n",
    "df.reset_index(drop=True, inplace=True)\n",
    "\n",
    "# get dimensions\n",
    "df.q_id = df.q_id.str.removesuffix('_attributes')\n",
    "features = df.q_id.unique().tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "7eaf1fff",
   "metadata": {},
   "outputs": [],
   "source": [
    "# reshape to wide format\n",
    "df = df.pivot_table(index=['mention_id', 'text', 'mention'], columns='q_id', values='label', aggfunc='last').reset_index()\n",
    "df = df.rename_axis(None, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "e6555528",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: consider dropping this and using it implicitly (when classifier sees/predicts both dims as 'No')\n",
    "df['universal'] = 'No'\n",
    "df.loc[(df[features]=='No').all(axis=1), 'universal'] = 'Yes'\n",
    "features.append('universal')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "0153b62c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# keep only fully gold-labeled examples\n",
    "df = df[df[features].isna().sum(axis=1) == 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "1636bcf4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "economic  non-economic  universal\n",
       "No        Yes           No           327\n",
       "Yes       No            No           161\n",
       "No        No            Yes           59\n",
       "Yes       Yes           No            53\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[features].value_counts(dropna=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "0785075b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # all-No examples\n",
    "# # TODO: make this part of conolsitation \n",
    "# df[(df[features]=='No').all(axis=1)]\n",
    "\n",
    "# # discard \n",
    "# tmp = tmp[~(tmp[features]=='No').all(axis=1)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "e2e1909a",
   "metadata": {},
   "outputs": [],
   "source": [
    "label2id = {'No': 0, 'Yes': 1}\n",
    "id2label = {v: k for k, v in label2id.items()}\n",
    "df.loc[:,features] = df.loc[:,features].apply(lambda x: x.map(label2id))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "06cfd8b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['labels'] = df.loc[:,features].apply(list, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "80bac800",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "economic        0.356667\n",
       "non-economic    0.633333\n",
       "universal       0.098333\n",
       "dtype: object"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[features].mean(axis=0)\n",
    "# strong label class imbalance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "7faca004",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained(model_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "69912139",
   "metadata": {},
   "outputs": [],
   "source": [
    "USE_SPAN_EMBEDDING = False\n",
    "if not USE_SPAN_EMBEDDING:\n",
    "    # using concat strategy\n",
    "    sep_tok = tokenizer.sep_token \n",
    "    df['input'] = df.mention + sep_tok + df.text \n",
    "    max_length_ = max(tokenizer(df.input.to_list(), truncation=False, padding=False, return_length=True).length)\n",
    "    cols = ['input', 'labels']\n",
    "    cols_mapping = {\"input\": \"text\", \"labels\": \"label\"}\n",
    "else:\n",
    "    # using span embedding strategy\n",
    "    df['span'] = df.apply(lambda x: regex.search(regex.escape(x.mention), x.text).span(), axis=1)\n",
    "    max_length_ = max(tokenizer(df.text.to_list(), truncation=False, padding=False, return_length=True).length)\n",
    "    cols = ['text', 'span', 'labels']\n",
    "    cols_mapping = {'text': 'text', 'span': 'span', 'labels': 'label'}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4936057f",
   "metadata": {},
   "source": [
    "### split the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "55f623ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['signature'] = df[features].apply(lambda r: '; '.join([f for f in features if r[f]==1]), axis=1)\n",
    "# set signatures with < 10 obs to None\n",
    "df['signature'] = df['signature'].where(df['signature'].isin(df['signature'].value_counts()[df['signature'].value_counts() >= 10].index), '_')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "0b53c639",
   "metadata": {},
   "outputs": [],
   "source": [
    "trn, tst = train_test_split(range(len(df)), test_size=0.25, random_state=SEED, stratify=df.signature)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "c3227e78",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = datasets.DatasetDict({\n",
    "    'train': datasets.Dataset.from_pandas(df.iloc[trn][cols], preserve_index=False),\n",
    "    'test': datasets.Dataset.from_pandas(df.iloc[tst][cols], preserve_index=False)\n",
    "})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e1702b55",
   "metadata": {},
   "source": [
    "### Prepare fine-tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "130f6664",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.19142408, 0.10813781, 0.70043811])"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "feats = df.iloc[trn][features].to_numpy()\n",
    "class_weights = get_class_weights(feats, multitarget=True)\n",
    "class_weights = class_weights.astype(float)\n",
    "class_weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "c2242313",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{0: 'economic', 1: 'non-economic', 2: 'universal'}"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "id2label = {i: l for i, l in enumerate(features)}\n",
    "label2id = {l: i for i, l in enumerate(features)}\n",
    "id2label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "f60340a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sentence_transformers.losses import ContrastiveLoss\n",
    "model_name = 'social-group-mention-attribute-dimension-classifier-v2'\n",
    "model_dir = os.path.join(model_path, model_name)\n",
    "\n",
    "training_args = TrainingArguments(\n",
    "    output_dir=model_dir,\n",
    "    batch_size=(32, 8),\n",
    "    max_length=max_length_,\n",
    "    num_epochs=(1, 7),\n",
    "    max_steps=150,\n",
    "    end_to_end=True,\n",
    "    loss=ContrastiveLoss,\n",
    "    # samples_per_label=2,\n",
    "    # use_amp=True,\n",
    "    report_to='none',\n",
    "    seed=SEED\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "9f800dc2",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Applying column mapping to the training dataset\n",
      "Applying column mapping to the evaluation dataset\n",
      "Map: 100%|██████████| 450/450 [00:00<00:00, 44909.03 examples/s]\n"
     ]
    }
   ],
   "source": [
    "from utils.metrics import compute_metrics_multilabel\n",
    "\n",
    "trainer_class = TrainerForSpanClassification if USE_SPAN_EMBEDDING else Trainer\n",
    "trainer = trainer_class(\n",
    "    model_init=lambda: model_init(\n",
    "        model_name=model_id,\n",
    "        id2label=id2label,\n",
    "        multitarget_strategy='one-vs-rest',\n",
    "        class_weights=class_weights,\n",
    "        use_span_embedding=USE_SPAN_EMBEDDING,\n",
    "        # device=device\n",
    "    ),\n",
    "    metric=lambda p, t: compute_metrics_multilabel(p, t, id2label),\n",
    "    args=training_args,\n",
    "    train_dataset=dataset['train'],\n",
    "    eval_dataset=dataset['test'],\n",
    "    column_mapping=cols_mapping\n",
    ")\n",
    "\n",
    "# for deterministic results\n",
    "trainer._args.seed = SEED\n",
    "trainer.st_trainer.args.seed = SEED\n",
    "trainer.st_trainer.args.data_seed = SEED\n",
    "trainer.st_trainer.args.full_determinism = True"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "72e49ed2",
   "metadata": {},
   "source": [
    "### Fine-tune"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "3a169b14",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "***** Running training *****\n",
      "  Num unique pairs = 4800\n",
      "  Batch size = 32\n",
      "  Num epochs = 1\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='150' max='150' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [150/150 00:17, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.125900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>50</td>\n",
       "      <td>0.050000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>100</td>\n",
       "      <td>0.028300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>150</td>\n",
       "      <td>0.026300</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch: 100%|██████████| 7/7 [00:15<00:00,  2.22s/it]\n"
     ]
    }
   ],
   "source": [
    "trainer.train()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f903ff2e",
   "metadata": {},
   "source": [
    "### Evaluate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "661f37b5",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "***** Running evaluation *****\n"
     ]
    }
   ],
   "source": [
    "metrics = trainer.evaluate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "c839e9fe",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>f1</th>\n",
       "      <th>precision</th>\n",
       "      <th>recall</th>\n",
       "      <th>support</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>macro</th>\n",
       "      <td>0.858621</td>\n",
       "      <td>0.901381</td>\n",
       "      <td>0.822928</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>economic</th>\n",
       "      <td>0.846154</td>\n",
       "      <td>0.862745</td>\n",
       "      <td>0.830189</td>\n",
       "      <td>53.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>non-economic</th>\n",
       "      <td>0.914894</td>\n",
       "      <td>0.924731</td>\n",
       "      <td>0.905263</td>\n",
       "      <td>95.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>universal</th>\n",
       "      <td>0.814815</td>\n",
       "      <td>0.916667</td>\n",
       "      <td>0.733333</td>\n",
       "      <td>15.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                    f1  precision    recall  support\n",
       "macro         0.858621   0.901381  0.822928      NaN\n",
       "economic      0.846154   0.862745  0.830189     53.0\n",
       "non-economic  0.914894   0.924731  0.905263     95.0\n",
       "universal     0.814815   0.916667  0.733333     15.0"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "res = pd.DataFrame(metrics, index=[0]).T.reset_index().rename(columns={'index': 'metric', 0: 'value'})\n",
    "res[['metric', 'category']] = res.metric.str.split('_', expand=True)\n",
    "res = res.pivot(index='category', columns='metric', values='value')\n",
    "# remove index names\n",
    "res.columns.name = None\n",
    "res.index.name = None\n",
    "res.loc[['macro']+features]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e307ede4",
   "metadata": {},
   "source": [
    "## error analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "7ab4766c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(150, 3)"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "probs = trainer.model.predict_proba(dataset['test']['input'], as_numpy=True)\n",
    "preds = np.where(probs > 0.5, 1, 0)\n",
    "preds.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "19bc5470",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "12"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# sanity check: any universal and other attributes? (not allowed)\n",
    "idxs = np.where(np.logical_and(preds[:, 0]==1, preds[:, 1:].sum(axis=1)>0))[0]\n",
    "len(idxs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "e23a4b9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_input(x):\n",
    "  # text, mention = x.split(tokenizer.sep_token)\n",
    "  # span = regex.search(regex.escape(mention), text).span()\n",
    "  return x.split(sep_tok)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "cb4034af",
   "metadata": {},
   "outputs": [],
   "source": [
    "errors_df = [] \n",
    "for attribute, attribute_id in label2id.items():\n",
    "    errors = preds != dataset['test']['labels']\n",
    "    idxs = np.where(errors[:, attribute_id])[0]\n",
    "\n",
    "    tmp = pd.DataFrame([parse_input(x) for x in dataset['test'].select(idxs)['input']], columns=['mention', 'text'])\n",
    "    tmp['attribute'] = attribute\n",
    "    tmp['label'] = np.array(dataset['test'].select(idxs)['labels'])[:, attribute_id]\n",
    "    tmp['pred'] = preds[idxs, attribute_id]\n",
    "    errors_df.append(tmp)\n",
    "\n",
    "errors_df = pd.concat(errors_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "63e9996c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1meconomic\u001b[0m: \"false positives\"\n",
      "  - Tax reductions will be granted to \u001b[30m\u001b[43mpersons with disabilities of Group 1 and 2\u001b[0m.\n",
      "  - The Greens demand that \u001b[30m\u001b[43mthe multinationals based in Switzerland\u001b[0m assume their responsibility for sustainable global development according to their size and do not go into their own pockets.\n",
      "  - The separation on the joint energy companies of \u001b[30m\u001b[43mthe nationals\u001b[0m should not come to account.\n",
      "  - The RPS has shown that it is the only political force that really exposes corruption and ties to \u001b[30m\u001b[43mthe mafia\u001b[0m at the high levels of power.\n",
      "\n",
      "\u001b[1meconomic\u001b[0m: \"false negatives\"\n",
      "  - Our aim will be to introduce a statutory duty on local authorities to provide nursery education, as soon as possible, for \u001b[30m\u001b[43mall pre-school children\u001b[0m whose parents wish it.\n",
      "  - Companies which looked inwards to Whitehall are now listening to their customers and \u001b[30m\u001b[43mshareholders\u001b[0m.\n",
      "  - Only \u001b[30m\u001b[43mthose who are transparently informed\u001b[0m can choose sustainable, fair and healthy products and services.\n",
      "  - By putting children first, and choosing to ensure every child has enough to thrive, New Zealand can design its economy to work for everyone, not just \u001b[30m\u001b[43ma few\u001b[0m.\n",
      "\n",
      "\u001b[1mnon-economic\u001b[0m: \"false positives\"\n",
      "  - To live better today means to live green: to live in harmony with ourselves, with \u001b[30m\u001b[43mour fellow human beings\u001b[0m and with the rest of nature.\n",
      "  - \u001b[30m\u001b[43mFamilial\u001b[0m farms must be guaranteed adequate opportunities for production without quota restrictions.\n",
      "  - Rather, it is about promoting \u001b[30m\u001b[43mpeople either of origin in a structured education\u001b[0m system according to their talents as best possible.\n",
      "  - Many of \u001b[30m\u001b[43mthe exotic self-employed\u001b[0m are also a market disturbing element.\n",
      "\n",
      "\u001b[1mnon-economic\u001b[0m: \"false negatives\"\n",
      "  - We do not even exist to repeat in green the old vices of parties that have been spent on the distance between \u001b[30m\u001b[43mthose who support them\u001b[0m and those who lead them, specialized in promising now and denying later, in seducing and disappointing, in making power at the expense of intrigue and money (preferably the State).\n",
      "  - \u001b[30m\u001b[43mA professional group that sees the enormous insecurity of the nation\u001b[0m.\n",
      "  - The RPS has shown that it is the only political force that really exposes corruption and ties to \u001b[30m\u001b[43mthe mafia\u001b[0m at the high levels of power.\n",
      "  - On all other points, the Progress Party freely sets \u001b[30m\u001b[43mits supporters\u001b[0m, but it is highlighted that the overwhelming majority of the Party agrees with the following views:\n",
      "\n",
      "\u001b[1muniversal\u001b[0m: \"false positives\"\n",
      "  - The national risk fund will be transferred to the county level, in proportion to \u001b[30m\u001b[43mthe county population\u001b[0m.\n",
      "\n",
      "\u001b[1muniversal\u001b[0m: \"false negatives\"\n",
      "  - To live better today means to live green: to live in harmony with ourselves, with \u001b[30m\u001b[43mour fellow human beings\u001b[0m and with the rest of nature.\n",
      "  - \u001b[30m\u001b[43mDynamic communities\u001b[0m are creating opportunities for young Canadians and young Canadians.\n",
      "  - Whether unemployment affects \u001b[30m\u001b[43mone person\u001b[0m or people from one’s family or surroundings.\n",
      "  - \u001b[30m\u001b[43mFamilial\u001b[0m farms must be guaranteed adequate opportunities for production without quota restrictions.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "highlight = lambda text, mention: text.replace(mention, '\\u001B[30m\\u001B[43m'+mention+'\\033[0m')\n",
    "\n",
    "for (a, t, p), subdf in errors_df.groupby(['attribute', 'label', 'pred']):\n",
    "    error_type = 'false positives' if t==0 else 'false negatives'\n",
    "    # print attribute name in bold\n",
    "    print(f'\\033[1m{a}\\033[0m: \"{error_type}\"')\n",
    "    for i, row in subdf.sample(n=min(4, len(subdf)), random_state=42    ).iterrows():\n",
    "        print(f\"  - {highlight(row['text'], row['mention'])}\")\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bfb8e4b8",
   "metadata": {},
   "source": [
    "## Save the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "9593ff4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import shutil\n",
    "shutil.rmtree(model_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "c40a8fa3",
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer.model.save_pretrained(model_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "ee71cba6",
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer.model.to('cpu');\n",
    "del trainer"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "76f7c0ea",
   "metadata": {},
   "source": [
    "## granular attribute classification problem"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e84aaaf",
   "metadata": {},
   "source": [
    "### Economic attributes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6660aa59",
   "metadata": {},
   "source": [
    "#### Prepare the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "89adda42",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['class membership',\n",
       " 'ecology of group',\n",
       " 'education level',\n",
       " 'employment status',\n",
       " 'income/wealth/economic status',\n",
       " 'occupation/profession']"
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = annotations.query(\"attribute=='economic' and category!='other'\")\n",
    "features = df.category.unique().tolist()\n",
    "features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "b7c193c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# pivot labels for attribute_combination to columns using mention_id, text, and mention as id vars\n",
    "df = df.pivot_table(index=['mention_id', 'text', 'mention'], columns='category', values='label', aggfunc='last').reset_index()\n",
    "df = df.rename_axis(None, axis=1)\n",
    "\n",
    "# NOTE: only apply for multi-dim classification\n",
    "# # keep only fully gold-labeled examples\n",
    "# df = df[df[features].isna().sum(axis=1) == 0]\n",
    "# df = df[~(df[features]=='No').all(axis=1)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "986e8d08",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "600"
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.mention_id.unique().shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "902ef45c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# one-hot encode labels\n",
    "label2id = {'No': 0, 'Yes': 1}\n",
    "id2label = {0: 'No', 1: 'Yes'}\n",
    "df.loc[:,features] = df.loc[:,features].apply(lambda x: x.map(label2id))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "8fc60224",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "class membership                 23\n",
       "ecology of group                 17\n",
       "education level                  22\n",
       "employment status                31\n",
       "income/wealth/economic status    44\n",
       "occupation/profession            98\n",
       "dtype: object"
      ]
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cnts = df[features].sum(axis=0)\n",
    "cnts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "7d55e49c",
   "metadata": {},
   "outputs": [],
   "source": [
    "drop_these = cnts[cnts < 10].index.tolist()\n",
    "for f in drop_these:\n",
    "    features.remove(f)\n",
    "df = df[['mention_id', 'text', 'mention'] + features]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "42f79c1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.loc[:, 'labels'] = df.loc[:,features].apply(list, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "adbe2b7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained(model_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "id": "f2db1e28",
   "metadata": {},
   "outputs": [],
   "source": [
    "STRATEGY = 'concat'  # 'mention'\n",
    "if STRATEGY == 'span':\n",
    "    # using span embedding strategy\n",
    "    df['span'] = df.apply(lambda x: regex.search(regex.escape(x.mention), x.text).span(), axis=1)\n",
    "    max_length_ = max(tokenizer(df.text.to_list(), truncation=False, padding=False, return_length=True).length)\n",
    "    cols = ['text', 'span', 'labels']\n",
    "    cols_mapping = {'text': 'text', 'span': 'span', 'labels': 'label'}\n",
    "else:\n",
    "    if STRATEGY == 'concat':\n",
    "        # using concat strategy\n",
    "        sep_tok = tokenizer.sep_token\n",
    "        df['input'] = df.mention + sep_tok + df.text\n",
    "    elif STRATEGY == 'mention':\n",
    "        # using concat strategy\n",
    "        df.loc[:, 'input'] = df.mention\n",
    "    else:\n",
    "        raise ValueError(f\"Unknown strategy: {STRATEGY}\")\n",
    "    max_length_ = max(tokenizer(df.input.to_list(), truncation=False, padding=False, return_length=True).length)\n",
    "    cols = ['input', 'labels']\n",
    "    cols_mapping = {\"input\": \"text\", \"labels\": \"label\"}    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "693f88b2",
   "metadata": {},
   "source": [
    "#### split the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "id": "482bc4e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['signature'] = df[features].apply(lambda r: '; '.join([f for f in features if r[f]==1]), axis=1)\n",
    "df['signature'] = df['signature'].where(df['signature'].isin(df['signature'].value_counts()[df['signature'].value_counts() >= 10].index), '_')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "id": "fd7b63d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "trn, tst = train_test_split(range(len(df)), test_size=0.25, random_state=SEED, stratify=df.signature)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "id": "8a1bc4fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = datasets.DatasetDict({\n",
    "    'train': datasets.Dataset.from_pandas(df.iloc[trn][cols], preserve_index=False),\n",
    "    'test': datasets.Dataset.from_pandas(df.iloc[tst][cols], preserve_index=False)\n",
    "})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4df8c220",
   "metadata": {},
   "source": [
    "#### Prepare fine-tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "id": "2805040b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.20441921, 0.28959388, 0.20441921, 0.15109246, 0.1022096 ,\n",
       "       0.04826565])"
      ]
     },
     "execution_count": 113,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "feats = df.iloc[trn][features].to_numpy()\n",
    "class_weights = get_class_weights(feats, multitarget=True)\n",
    "class_weights = class_weights.astype(float)\n",
    "class_weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "id": "7d70cc0f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{0: 'class membership',\n",
       " 1: 'ecology of group',\n",
       " 2: 'education level',\n",
       " 3: 'employment status',\n",
       " 4: 'income/wealth/economic status',\n",
       " 5: 'occupation/profession'}"
      ]
     },
     "execution_count": 114,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "id2label = {i: l for i, l in enumerate(features)}\n",
    "label2id = {l: i for i, l in enumerate(features)}\n",
    "id2label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "id": "bcc1c99d",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name = 'social-group-mention-econ-attributes-classifier'\n",
    "model_dir = os.path.join(model_path, model_name)\n",
    "\n",
    "training_args = TrainingArguments(\n",
    "    output_dir=model_dir,\n",
    "    batch_size=(32, 8),\n",
    "    max_length=max_length_,\n",
    "    num_epochs=(1, 7),\n",
    "    max_steps=150,\n",
    "    # max_steps=-1,\n",
    "    end_to_end=True,\n",
    "    loss=ContrastiveLoss,\n",
    "    # samples_per_label=2,\n",
    "    # use_amp=True,\n",
    "    report_to='none',\n",
    "    seed=SEED\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "id": "17db26f3",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Applying column mapping to the training dataset\n",
      "Applying column mapping to the evaluation dataset\n",
      "Map: 100%|██████████| 450/450 [00:00<00:00, 55356.55 examples/s]\n"
     ]
    }
   ],
   "source": [
    "from utils.metrics import compute_metrics_multilabel\n",
    "\n",
    "trainer_class = TrainerForSpanClassification if STRATEGY=='span' else Trainer\n",
    "trainer = trainer_class(\n",
    "    model_init=lambda: model_init(\n",
    "        model_name=model_id,\n",
    "        id2label=id2label,\n",
    "        multitarget_strategy='one-vs-rest',\n",
    "        class_weights=class_weights,\n",
    "        use_span_embedding=STRATEGY=='span',\n",
    "    ),\n",
    "    metric=lambda p, t: compute_metrics_multilabel(p, t, id2label),\n",
    "    args=training_args,\n",
    "    train_dataset=dataset['train'],\n",
    "    eval_dataset=dataset['test'],\n",
    "    column_mapping=cols_mapping\n",
    ")\n",
    "\n",
    "# for deterministic results\n",
    "trainer._args.seed = SEED\n",
    "trainer.st_trainer.args.seed = SEED\n",
    "trainer.st_trainer.args.data_seed = SEED\n",
    "trainer.st_trainer.args.full_determinism = True"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "039c1376",
   "metadata": {},
   "source": [
    "#### Fine-tune"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "id": "3bffa749",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "***** Running training *****\n",
      "  Num unique pairs = 4800\n",
      "  Batch size = 32\n",
      "  Num epochs = 1\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='150' max='150' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [150/150 00:18, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.143800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>50</td>\n",
       "      <td>0.049500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>100</td>\n",
       "      <td>0.024800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>150</td>\n",
       "      <td>0.017200</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch: 100%|██████████| 7/7 [00:15<00:00,  2.23s/it]\n"
     ]
    }
   ],
   "source": [
    "trainer.train()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5bdc817",
   "metadata": {},
   "source": [
    "#### Evaluate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "id": "c4d0e8d3",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "***** Running evaluation *****\n"
     ]
    }
   ],
   "source": [
    "metrics = trainer.evaluate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "id": "691d26a6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>f1</th>\n",
       "      <th>precision</th>\n",
       "      <th>recall</th>\n",
       "      <th>support</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>macro</th>\n",
       "      <td>0.684371</td>\n",
       "      <td>0.757428</td>\n",
       "      <td>0.646261</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>class membership</th>\n",
       "      <td>0.444444</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>6.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ecology of group</th>\n",
       "      <td>0.545455</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.600000</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>education level</th>\n",
       "      <td>0.800000</td>\n",
       "      <td>0.800000</td>\n",
       "      <td>0.800000</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>employment status</th>\n",
       "      <td>0.875000</td>\n",
       "      <td>0.875000</td>\n",
       "      <td>0.875000</td>\n",
       "      <td>8.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>income/wealth/economic status</th>\n",
       "      <td>0.625000</td>\n",
       "      <td>0.833333</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>10.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>occupation/profession</th>\n",
       "      <td>0.816327</td>\n",
       "      <td>0.869565</td>\n",
       "      <td>0.769231</td>\n",
       "      <td>26.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                     f1  precision    recall  support\n",
       "macro                          0.684371   0.757428  0.646261      NaN\n",
       "class membership               0.444444   0.666667  0.333333      6.0\n",
       "ecology of group               0.545455   0.500000  0.600000      5.0\n",
       "education level                0.800000   0.800000  0.800000      5.0\n",
       "employment status              0.875000   0.875000  0.875000      8.0\n",
       "income/wealth/economic status  0.625000   0.833333  0.500000     10.0\n",
       "occupation/profession          0.816327   0.869565  0.769231     26.0"
      ]
     },
     "execution_count": 119,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "res = pd.DataFrame(metrics, index=[0]).T.reset_index().rename(columns={'index': 'metric', 0: 'value'})\n",
    "res[['metric', 'category']] = res.metric.str.split('_', expand=True)\n",
    "res = res.pivot(index='category', columns='metric', values='value')\n",
    "# remove index names\n",
    "res.columns.name = None\n",
    "res.index.name = None\n",
    "res.loc[['macro']+features]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "id": "aadd3c66",
   "metadata": {},
   "outputs": [],
   "source": [
    "if STRATEGY == 'span':\n",
    "    parse_example = lambda x: (x['text'], tuple(x['span']))\n",
    "    examples = list(map(parse_example, dataset['test'].select_columns(['text', 'span']).to_list()))\n",
    "    preds = trainer.model.predict(examples, as_numpy=True)\n",
    "    errors_df = pd.DataFrame(examples, columns=['text', 'span'])\n",
    "    errors_df['mention'] = errors_df.apply(lambda x: x['text'][slice(*x['span'])], axis=1)\n",
    "    del errors_df['span']\n",
    "else:\n",
    "    # probs = trainer.model.predict_proba(dataset['test']['input'], as_numpy=True)\n",
    "    # preds = np.where(probs > 0.5, 1, 0)\n",
    "    preds = trainer.model.predict(dataset['test']['input'], as_numpy=True)\n",
    "    errors_df = pd.DataFrame(dataset['test']['input'], columns=['mention'])\n",
    "    if STRATEGY == 'concat':\n",
    "        errors_df[['mention', 'text']] = errors_df.mention.str.split(sep_tok, expand=True)\n",
    "errors_df['label'] = dataset['test']['labels']\n",
    "errors_df['pred'] = list(map(list, preds))\n",
    "errors_df['category'] = [features]*len(errors_df)\n",
    "errors_df = errors_df.explode(['label', 'pred', 'category'])\n",
    "errors_df = errors_df.explode(['label', 'pred', 'category'])\n",
    "errors_df = errors_df.query(\"label!=pred\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "id": "9e14a551",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1mclass membership\u001b[0m: \"false positives\"\n",
      "  - This tax would only affect \u001b[30m\u001b[43mthe wealthiest 6 per cent of New Zealanders\u001b[0m.\n",
      "\n",
      "\u001b[1mclass membership\u001b[0m: \"false negatives\"\n",
      "  - \u001b[30m\u001b[43mPowerful cliques behind and within the old parties\u001b[0m are heading towards the Great Coalition.\n",
      "  - \u001b[30m\u001b[43mPeople who started with goods carried across the border in suitcases and from field beds on the streets, from small consulting firms and service workshops, gradually built shops, wholesalers, factories, corporations and today give jobs to dozens of people: workers\u001b[0m.\n",
      "  - Too many \u001b[30m\u001b[43mordinary people\u001b[0m know this.\n",
      "  - A real support for \u001b[30m\u001b[43mordinary people\u001b[0m.\n",
      "\n",
      "\u001b[1mecology of group\u001b[0m: \"false positives\"\n",
      "  - \u001b[30m\u001b[43mThe people who represent this ecological mindset\u001b[0m can be found in the environmental movement, among technological innovators, in organizations and political parties.\n",
      "  - Work with provincial and territorial governments to ensure workplace accommodations, medical accessibility and treatments, access to buildings and other public areas, social support systems and adequate monetary assistance for \u001b[30m\u001b[43mpeople with environmental sensitivities\u001b[0m.\n",
      "  - The environmental impact of intensive agriculture should be reduced through direct payments to \u001b[30m\u001b[43mfarmers\u001b[0m.\n",
      "\n",
      "\u001b[1mecology of group\u001b[0m: \"false negatives\"\n",
      "  - Make a plan to support different sectors and \u001b[30m\u001b[43mgroups of people in their transition from the fossil economy\u001b[0m.\n",
      "  - Only \u001b[30m\u001b[43mthose who are transparently informed\u001b[0m can choose sustainable, fair and healthy products and services.\n",
      "\n",
      "\u001b[1meducation level\u001b[0m: \"false positives\"\n",
      "  - The inevitable bill must be paid by \u001b[30m\u001b[43mthose who have done well in the last 5 years\u001b[0m.\n",
      "\n",
      "\u001b[1meducation level\u001b[0m: \"false negatives\"\n",
      "  - \u001b[30m\u001b[43mStudents with children\u001b[0m have great difficulties bringing the economy together.\n",
      "\n",
      "\u001b[1memployment status\u001b[0m: \"false positives\"\n",
      "  - The problem of foreigners in Flanders is primarily caused by \u001b[30m\u001b[43mthe host workers\u001b[0m.\n",
      "\n",
      "\u001b[1memployment status\u001b[0m: \"false negatives\"\n",
      "  - \u001b[30m\u001b[43mPeople who started with goods carried across the border in suitcases and from field beds on the streets, from small consulting firms and service workshops, gradually built shops, wholesalers, factories, corporations and today give jobs to dozens of people: workers\u001b[0m.\n",
      "\n",
      "\u001b[1mincome/wealth/economic status\u001b[0m: \"false positives\"\n",
      "  - From \u001b[30m\u001b[43mshareholders and managers who merely measure the performance of companies to the short-term profit\u001b[0m.\n",
      "\n",
      "\u001b[1mincome/wealth/economic status\u001b[0m: \"false negatives\"\n",
      "  - The State should provide credit and training to \u001b[30m\u001b[43mlandless people who wish to enter agriculture\u001b[0m.\n",
      "  - The inevitable bill must be paid by \u001b[30m\u001b[43mthose who have done well in the last 5 years\u001b[0m.\n",
      "  - By putting children first, and choosing to ensure every child has enough to thrive, New Zealand can design its economy to work for everyone, not just \u001b[30m\u001b[43ma few\u001b[0m.\n",
      "  - It will emphatically not apply to \u001b[30m\u001b[43mowner-occupiers\u001b[0m.\n",
      "\n",
      "\u001b[1moccupation/profession\u001b[0m: \"false positives\"\n",
      "  - \u001b[30m\u001b[43mHigher vocational education students\u001b[0m are entitled to the OV student card.\n",
      "  - The State should provide credit and training to \u001b[30m\u001b[43mlandless people who wish to enter agriculture\u001b[0m.\n",
      "  - Failure first affects students from disadvantaged socioeconomic backgrounds, as well as \u001b[30m\u001b[43mthose attending technical and professional education\u001b[0m.\n",
      "\n",
      "\u001b[1moccupation/profession\u001b[0m: \"false negatives\"\n",
      "  - The rights are always first and foremost for \u001b[30m\u001b[43mthe author\u001b[0m, not the producer.\n",
      "  - Make a plan to support different sectors and \u001b[30m\u001b[43mgroups of people in their transition from the fossil economy\u001b[0m.\n",
      "  - From \u001b[30m\u001b[43mshareholders and managers who merely measure the performance of companies to the short-term profit\u001b[0m.\n",
      "  - Remove \u001b[30m\u001b[43mthe moderators\u001b[0m.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for (c, t, p), subdf in errors_df.groupby(['category', 'label', 'pred']):\n",
    "    error_type = 'false positives' if t==0 else 'false negatives'\n",
    "    # print attribute name in bold\n",
    "    print(f'\\033[1m{c}\\033[0m: \"{error_type}\"')\n",
    "    for i, row in subdf.sample(n=min(4, len(subdf)), random_state=42    ).iterrows():\n",
    "        print(f\"  - {highlight(row['text'], row['mention'])}\")\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b61bf40",
   "metadata": {},
   "source": [
    "### non-economic attributes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "084e7ef5",
   "metadata": {},
   "source": [
    "#### Prepare the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "id": "308b63fe",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['age',\n",
       " 'crime',\n",
       " 'ethnicity',\n",
       " 'family',\n",
       " 'gender/sexuality',\n",
       " 'health',\n",
       " 'nationality',\n",
       " 'place/location',\n",
       " 'religion',\n",
       " 'shared values/mentalities']"
      ]
     },
     "execution_count": 136,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = annotations.query(\"attribute=='non-economic' and category!='other'\")\n",
    "features = df.category.unique().tolist()\n",
    "features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "id": "b9d78d1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# pivot labels for attribute_combination to columns using mention_id, text, and mention as id vars\n",
    "df = df.pivot_table(index=['mention_id', 'text', 'mention'], columns='category', values='label', aggfunc='last').reset_index()\n",
    "df = df.rename_axis(None, axis=1)\n",
    "\n",
    "# NOTE: only apply for multi-dim classification\n",
    "# # keep only fully gold-labeled examples\n",
    "# df = df[df[features].isna().sum(axis=1) == 0]\n",
    "# df = df[~(df[features]=='No').all(axis=1)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "id": "7301734a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "600"
      ]
     },
     "execution_count": 138,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.mention_id.unique().shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "id": "9e22748c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# one-hot encode labels\n",
    "label2id = {'No': 0, 'Yes': 1}\n",
    "id2label = {0: 'No', 1: 'Yes'}\n",
    "df.loc[:,features] = df.loc[:,features].apply(lambda x: x.map(label2id))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "id": "46180f9f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "age                          65\n",
       "crime                        30\n",
       "ethnicity                    34\n",
       "family                       50\n",
       "gender/sexuality             48\n",
       "health                       31\n",
       "nationality                  74\n",
       "place/location               17\n",
       "religion                     25\n",
       "shared values/mentalities    87\n",
       "dtype: object"
      ]
     },
     "execution_count": 140,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cnts = df[features].sum(axis=0)\n",
    "cnts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "id": "f855b03a",
   "metadata": {},
   "outputs": [],
   "source": [
    "drop_these = cnts[cnts < 10].index.tolist()\n",
    "for f in drop_these:\n",
    "    features.remove(f)\n",
    "df = df[['mention_id', 'text', 'mention'] + features]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "id": "4bbf56c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.loc[:, 'labels'] = df.loc[:,features].apply(list, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "id": "5adb023f",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained(model_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "id": "639f2c63",
   "metadata": {},
   "outputs": [],
   "source": [
    "STRATEGY = 'concat'  # 'mention'\n",
    "if STRATEGY == 'span':\n",
    "    # using span embedding strategy\n",
    "    df['span'] = df.apply(lambda x: regex.search(regex.escape(x.mention), x.text).span(), axis=1)\n",
    "    max_length_ = max(tokenizer(df.text.to_list(), truncation=False, padding=False, return_length=True).length)\n",
    "    cols = ['text', 'span', 'labels']\n",
    "    cols_mapping = {'text': 'text', 'span': 'span', 'labels': 'label'}\n",
    "else:\n",
    "    if STRATEGY == 'concat':\n",
    "        # using concat strategy\n",
    "        sep_tok = tokenizer.sep_token\n",
    "        df['input'] = df.mention + sep_tok + df.text\n",
    "    elif STRATEGY == 'mention':\n",
    "        # using concat strategy\n",
    "        df.loc[:, 'input'] = df.mention\n",
    "    else:\n",
    "        raise ValueError(f\"Unknown strategy: {STRATEGY}\")\n",
    "    max_length_ = max(tokenizer(df.input.to_list(), truncation=False, padding=False, return_length=True).length)\n",
    "    cols = ['input', 'labels']\n",
    "    cols_mapping = {\"input\": \"text\", \"labels\": \"label\"}    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e4d8f77",
   "metadata": {},
   "source": [
    "#### split the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "id": "51cb1d2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['signature'] = df[features].apply(lambda r: '; '.join([f for f in features if r[f]==1]), axis=1)\n",
    "df['signature'] = df['signature'].where(df['signature'].isin(df['signature'].value_counts()[df['signature'].value_counts() >= 10].index), '_')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "id": "31aef185",
   "metadata": {},
   "outputs": [],
   "source": [
    "trn, tst = train_test_split(range(len(df)), test_size=0.25, random_state=SEED, stratify=df.signature)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "id": "6263bcd8",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = datasets.DatasetDict({\n",
    "    'train': datasets.Dataset.from_pandas(df.iloc[trn][cols], preserve_index=False),\n",
    "    'test': datasets.Dataset.from_pandas(df.iloc[tst][cols], preserve_index=False)\n",
    "})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "554cf033",
   "metadata": {},
   "source": [
    "#### Prepare fine-tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "id": "b6bed566",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.0571124 , 0.12460887, 0.10153315, 0.06853488, 0.07614986,\n",
       "       0.1096558 , 0.04809465, 0.21087655, 0.16125853, 0.04217531])"
      ]
     },
     "execution_count": 148,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "feats = df.iloc[trn][features].to_numpy()\n",
    "class_weights = get_class_weights(feats, multitarget=True)\n",
    "class_weights = class_weights.astype(float)\n",
    "class_weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "id": "07f715d4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{0: 'age',\n",
       " 1: 'crime',\n",
       " 2: 'ethnicity',\n",
       " 3: 'family',\n",
       " 4: 'gender/sexuality',\n",
       " 5: 'health',\n",
       " 6: 'nationality',\n",
       " 7: 'place/location',\n",
       " 8: 'religion',\n",
       " 9: 'shared values/mentalities'}"
      ]
     },
     "execution_count": 149,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "id2label = {i: l for i, l in enumerate(features)}\n",
    "label2id = {l: i for i, l in enumerate(features)}\n",
    "id2label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "id": "edd9a986",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name = 'social-group-mention-nonecon-attributes-classifier'\n",
    "model_dir = os.path.join(model_path, model_name)\n",
    "\n",
    "training_args = TrainingArguments(\n",
    "    output_dir=model_dir,\n",
    "    batch_size=(32, 8),\n",
    "    max_length=max_length_,\n",
    "    num_epochs=(1, 7),\n",
    "    max_steps=150,\n",
    "    # max_steps=-1,\n",
    "    end_to_end=True,\n",
    "    loss=ContrastiveLoss,\n",
    "    # samples_per_label=2,\n",
    "    # use_amp=True,\n",
    "    report_to='none',\n",
    "    seed=SEED\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "id": "0534b2b2",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Applying column mapping to the training dataset\n",
      "Applying column mapping to the evaluation dataset\n",
      "Map: 100%|██████████| 450/450 [00:00<00:00, 58346.06 examples/s]\n"
     ]
    }
   ],
   "source": [
    "from utils.metrics import compute_metrics_multilabel\n",
    "\n",
    "trainer_class = TrainerForSpanClassification if STRATEGY=='span' else Trainer\n",
    "trainer = trainer_class(\n",
    "    model_init=lambda: model_init(\n",
    "        model_name=model_id,\n",
    "        id2label=id2label,\n",
    "        multitarget_strategy='one-vs-rest',\n",
    "        class_weights=class_weights,\n",
    "        use_span_embedding=STRATEGY=='span',\n",
    "    ),\n",
    "    metric=lambda p, t: compute_metrics_multilabel(p, t, id2label),\n",
    "    args=training_args,\n",
    "    train_dataset=dataset['train'],\n",
    "    eval_dataset=dataset['test'],\n",
    "    column_mapping=cols_mapping\n",
    ")\n",
    "\n",
    "# for deterministic results\n",
    "trainer._args.seed = SEED\n",
    "trainer.st_trainer.args.seed = SEED\n",
    "trainer.st_trainer.args.data_seed = SEED\n",
    "trainer.st_trainer.args.full_determinism = True"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef5421dc",
   "metadata": {},
   "source": [
    "#### Fine-tune"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "id": "def95a54",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "***** Running training *****\n",
      "  Num unique pairs = 4800\n",
      "  Batch size = 32\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  Num epochs = 1\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='150' max='150' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [150/150 00:18, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.130500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>50</td>\n",
       "      <td>0.047900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>100</td>\n",
       "      <td>0.019800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>150</td>\n",
       "      <td>0.014500</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch: 100%|██████████| 7/7 [00:15<00:00,  2.23s/it]\n"
     ]
    }
   ],
   "source": [
    "trainer.train()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "00c50cac",
   "metadata": {},
   "source": [
    "#### Evaluate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "id": "5099a90b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "***** Running evaluation *****\n"
     ]
    }
   ],
   "source": [
    "metrics = trainer.evaluate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "id": "d345b80f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>f1</th>\n",
       "      <th>precision</th>\n",
       "      <th>recall</th>\n",
       "      <th>support</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>macro</th>\n",
       "      <td>0.772882</td>\n",
       "      <td>0.944689</td>\n",
       "      <td>0.706230</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>age</th>\n",
       "      <td>0.800000</td>\n",
       "      <td>0.923077</td>\n",
       "      <td>0.705882</td>\n",
       "      <td>17.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>crime</th>\n",
       "      <td>0.800000</td>\n",
       "      <td>0.857143</td>\n",
       "      <td>0.750000</td>\n",
       "      <td>8.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ethnicity</th>\n",
       "      <td>0.875000</td>\n",
       "      <td>0.777778</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>7.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>family</th>\n",
       "      <td>0.823529</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.700000</td>\n",
       "      <td>10.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>gender/sexuality</th>\n",
       "      <td>0.956522</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.916667</td>\n",
       "      <td>12.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>health</th>\n",
       "      <td>0.909091</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.833333</td>\n",
       "      <td>6.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>nationality</th>\n",
       "      <td>0.740741</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.588235</td>\n",
       "      <td>17.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>place/location</th>\n",
       "      <td>0.400000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.250000</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>religion</th>\n",
       "      <td>0.941176</td>\n",
       "      <td>0.888889</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>8.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>shared values/mentalities</th>\n",
       "      <td>0.482759</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.318182</td>\n",
       "      <td>22.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                 f1  precision    recall  support\n",
       "macro                      0.772882   0.944689  0.706230      NaN\n",
       "age                        0.800000   0.923077  0.705882     17.0\n",
       "crime                      0.800000   0.857143  0.750000      8.0\n",
       "ethnicity                  0.875000   0.777778  1.000000      7.0\n",
       "family                     0.823529   1.000000  0.700000     10.0\n",
       "gender/sexuality           0.956522   1.000000  0.916667     12.0\n",
       "health                     0.909091   1.000000  0.833333      6.0\n",
       "nationality                0.740741   1.000000  0.588235     17.0\n",
       "place/location             0.400000   1.000000  0.250000      4.0\n",
       "religion                   0.941176   0.888889  1.000000      8.0\n",
       "shared values/mentalities  0.482759   1.000000  0.318182     22.0"
      ]
     },
     "execution_count": 154,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "res = pd.DataFrame(metrics, index=[0]).T.reset_index().rename(columns={'index': 'metric', 0: 'value'})\n",
    "res[['metric', 'category']] = res.metric.str.split('_', expand=True)\n",
    "res = res.pivot(index='category', columns='metric', values='value')\n",
    "# remove index names\n",
    "res.columns.name = None\n",
    "res.index.name = None\n",
    "res.loc[['macro']+features]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "id": "417d35c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "if STRATEGY == 'span':\n",
    "    parse_example = lambda x: (x['text'], tuple(x['span']))\n",
    "    examples = list(map(parse_example, dataset['test'].select_columns(['text', 'span']).to_list()))\n",
    "    preds = trainer.model.predict(examples, as_numpy=True)\n",
    "    errors_df = pd.DataFrame(examples, columns=['text', 'span'])\n",
    "    errors_df['mention'] = errors_df.apply(lambda x: x['text'][slice(*x['span'])], axis=1)\n",
    "    del errors_df['span']\n",
    "else:\n",
    "    # probs = trainer.model.predict_proba(dataset['test']['input'], as_numpy=True)\n",
    "    # preds = np.where(probs > 0.5, 1, 0)\n",
    "    preds = trainer.model.predict(dataset['test']['input'], as_numpy=True)\n",
    "    errors_df = pd.DataFrame(dataset['test']['input'], columns=['mention'])\n",
    "    if STRATEGY == 'concat':\n",
    "        errors_df[['mention', 'text']] = errors_df.mention.str.split(sep_tok, expand=True)\n",
    "errors_df['label'] = dataset['test']['labels']\n",
    "errors_df['pred'] = list(map(list, preds))\n",
    "errors_df['category'] = [features]*len(errors_df)\n",
    "errors_df = errors_df.explode(['label', 'pred', 'category'])\n",
    "errors_df = errors_df.explode(['label', 'pred', 'category'])\n",
    "errors_df = errors_df.query(\"label!=pred\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "id": "f14ab53c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1mage\u001b[0m: \"false positives\"\n",
      "  - \u001b[30m\u001b[43mToday’s society\u001b[0m is in a transitional phase between the industrial society and the knowledge society.\n",
      "\n",
      "\u001b[1mage\u001b[0m: \"false negatives\"\n",
      "  - It is also important that \u001b[30m\u001b[43meach child, as an individual\u001b[0m, can develop their life project according to their capabilities, skills and wishes.\n",
      "  - \u001b[30m\u001b[43mYoung people who don't want education now - but maybe later\u001b[0m\n",
      "  - A third of \u001b[30m\u001b[43myoung people in Slovakia\u001b[0m are unemployed after graduation.\n",
      "  - The elderly are \u001b[30m\u001b[43mindependent, active and confident citizens who want to actively use, expand and pass on their experiences and knowledge\u001b[0m.\n",
      "\n",
      "\u001b[1mcrime\u001b[0m: \"false positives\"\n",
      "  - Do not submit to \u001b[30m\u001b[43mthe betrayers of your promises\u001b[0m.\n",
      "\n",
      "\u001b[1mcrime\u001b[0m: \"false negatives\"\n",
      "  - The Federal Republic must acknowledge its responsibility to the victims of fascism and recognize the compensation demands of all the victims of the Nazi, especially the Roma and Sinti, the Jewish people, the homosexuals, the forced sterilized, the survivors of the \"ethanasia\" actions, the resistance fighters and \u001b[30m\u001b[43mthe so-called associalists\u001b[0m.\n",
      "  - The CDU and CSU join forces in the fight against \u001b[30m\u001b[43msmuggling gangs\u001b[0m and asylum abuse to ensure the comprehensive enforcement of the Asylum Seeker Benefits Act in all municipalities.\n",
      "\n",
      "\u001b[1methnicity\u001b[0m: \"false positives\"\n",
      "  - So, too, are the backgrounds, traditions and contributions of \u001b[30m\u001b[43mwhite national, ethnic, religious and regional communities\u001b[0m ignored.\n",
      "  - In this direction, we propose the creation of unified social and political bodies with the prospect of abolishing all separate conceptions, which separate \u001b[30m\u001b[43mpeople based on their national or religious characteristics\u001b[0m.\n",
      "\n",
      "\u001b[1mfamily\u001b[0m: \"false negatives\"\n",
      "  - In the future - the amount of pensions depends not only on the taxes paid by themselves, but also \u001b[30m\u001b[43mthe children\u001b[0m.\n",
      "  - And we will set out a strategy with the goal of ensuring that the great majority of patients can access talking therapies within 28 days, and that \u001b[30m\u001b[43mall children\u001b[0m who need it can access school-based counselling.\n",
      "  - Complete revision of the return of land to their true owners or \u001b[30m\u001b[43mtheir heirs\u001b[0m.\n",
      "\n",
      "\u001b[1mgender/sexuality\u001b[0m: \"false negatives\"\n",
      "  - We live in \u001b[30m\u001b[43ma society that is ruled by men\u001b[0m.\n",
      "\n",
      "\u001b[1mhealth\u001b[0m: \"false negatives\"\n",
      "  - In addition, caregivers should be allowed to take 10 days a year to take special care of \u001b[30m\u001b[43ma person to be cared for\u001b[0m.\n",
      "\n",
      "\u001b[1mnationality\u001b[0m: \"false negatives\"\n",
      "  - In this direction, we propose the creation of unified social and political bodies with the prospect of abolishing all separate conceptions, which separate \u001b[30m\u001b[43mpeople based on their national or religious characteristics\u001b[0m.\n",
      "  - The elderly are \u001b[30m\u001b[43mindependent, active and confident citizens who want to actively use, expand and pass on their experiences and knowledge\u001b[0m.\n",
      "  - A third of \u001b[30m\u001b[43myoung people in Slovakia\u001b[0m are unemployed after graduation.\n",
      "  - Women and \u001b[30m\u001b[43mpeople with migrant backgrounds\u001b[0m are already engaged in firefighters and aid organisations.\n",
      "\n",
      "\u001b[1mplace/location\u001b[0m: \"false negatives\"\n",
      "  - Our country has always welcomed \u001b[30m\u001b[43mpeople from other regions\u001b[0m – just as Germans have found a new home in other countries of the world.\n",
      "  - So, too, are the backgrounds, traditions and contributions of \u001b[30m\u001b[43mwhite national, ethnic, religious and regional communities\u001b[0m ignored.\n",
      "  - We will give patients and \u001b[30m\u001b[43mlocal GPs\u001b[0m the right to choose the hospital or care provider that is right for them.\n",
      "\n",
      "\u001b[1mreligion\u001b[0m: \"false positives\"\n",
      "  - So, too, are the backgrounds, traditions and contributions of \u001b[30m\u001b[43mwhite national, ethnic, religious and regional communities\u001b[0m ignored.\n",
      "\n",
      "\u001b[1mshared values/mentalities\u001b[0m: \"false negatives\"\n",
      "  - It consists of scientists elected by their peers and \u001b[30m\u001b[43mrepresentatives of associations aimed at safeguarding wildlife or respecting animal rights\u001b[0m.\n",
      "  - We will hold accountable those who engage in or enable violent or other illegal activity targeting religious minorities, including by directing the federal government to address the growing and violent threat of white supremacist, \u001b[30m\u001b[43mneo-Nazi\u001b[0m and anti-government groups.\n",
      "  - \u001b[30m\u001b[43mUnemployed persons who do not want to work\u001b[0m will lose their insurance.\n",
      "  - \u001b[30m\u001b[43mYoung people who don't want education now - but maybe later\u001b[0m\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for (c, t, p), subdf in errors_df.groupby(['category', 'label', 'pred']):\n",
    "    error_type = 'false positives' if t==0 else 'false negatives'\n",
    "    # print attribute name in bold\n",
    "    print(f'\\033[1m{c}\\033[0m: \"{error_type}\"')\n",
    "    for i, row in subdf.sample(n=min(4, len(subdf)), random_state=42    ).iterrows():\n",
    "        print(f\"  - {highlight(row['text'], row['mention'])}\")\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27d45dd0",
   "metadata": {},
   "source": [
    "## Stance"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7281fa38",
   "metadata": {},
   "source": [
    "### Prepare the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d39cc7ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "tmp = df[df.attribute==\"stance\"]\n",
    "tmp = tmp[['mention_id', 'text', 'mention', 'label']].drop_duplicates()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40974d39",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "label\n",
       "Positive    242\n",
       "Negative     34\n",
       "Neutral      23\n",
       "Unsure        1\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tmp['label'].value_counts(dropna=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d77e4ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "tmp = tmp[tmp.label != 'Unsure']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16e31de9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{0: 'Positive', 1: 'Neutral', 2: 'Negative'}"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "323e7173",
   "metadata": {},
   "outputs": [],
   "source": [
    "id2label = dict(enumerate(tmp.label.unique()))\n",
    "label2id = {l: i for i, l in id2label.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74f48f0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "tmp.loc[:,'labels'] = tmp.label.map(label2id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb0fddde",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained(base_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a609fa3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# using concat strategy\n",
    "tmp['input'] = tmp.text + tokenizer.sep_token + tmp.mention \n",
    "max_length_ = max(tokenizer(tmp.input.to_list(), truncation=False, padding=False, return_length=True).length)\n",
    "cols = ['input', 'labels']\n",
    "cols_mapping = {\"input\": \"text\", \"labels\": \"label\"}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4be40617",
   "metadata": {},
   "source": [
    "### split the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c11471c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "trn, tst = train_test_split(range(len(tmp)), test_size=0.25, random_state=SEED, stratify=tmp.label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa4c4839",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = datasets.DatasetDict({\n",
    "    'train': datasets.Dataset.from_pandas(tmp.iloc[trn][cols], preserve_index=False),\n",
    "    'test': datasets.Dataset.from_pandas(tmp.iloc[tst][cols], preserve_index=False)\n",
    "})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "87e43845",
   "metadata": {},
   "source": [
    "### Prepare fine-tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7d3c791",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.0537386 , 0.57215805, 0.37410334])"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train = np.array(dataset['train']['labels'])\n",
    "class_weights = get_class_weights(y_train)\n",
    "class_weights = class_weights.astype(float)\n",
    "class_weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e971bbc",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_id = 'social-group-mention-stance-classifier'\n",
    "model_dir = os.path.join(model_path, model_id)\n",
    "\n",
    "training_args = TrainingArguments(\n",
    "    output_dir=model_dir,\n",
    "    batch_size=(32, 4),\n",
    "    max_length=max_length_,\n",
    "    num_epochs=(0, 15),\n",
    "    max_steps=-1,\n",
    "    end_to_end=True,\n",
    "    # loss=CosineSimilarityLoss,\n",
    "    # samples_per_label=2,\n",
    "    # use_amp=True,\n",
    "    report_to='none',\n",
    "    seed=SEED\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d22a4b0",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Applying column mapping to the training dataset\n",
      "Applying column mapping to the evaluation dataset\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d0d8c3e6405e429793f2ce72373fe020",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/224 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from utils.metrics import compute_metrics_multiclass\n",
    "\n",
    "# trainer = TrainerForSpanClassification(\n",
    "trainer = Trainer(\n",
    "    model_init=lambda: model_init(\n",
    "        model_name=base_model,\n",
    "        id2label=id2label,\n",
    "        # multitarget_strategy='one-vs-rest',\n",
    "        class_weights=class_weights,\n",
    "        use_span_embedding=False,#True,\n",
    "        device='mps'\n",
    "    ),\n",
    "    metric=lambda p, t: compute_metrics_multiclass(p, t, id2label),\n",
    "    args=training_args,\n",
    "    train_dataset=dataset['train'],\n",
    "    eval_dataset=dataset['test'],\n",
    "    column_mapping=cols_mapping\n",
    ")\n",
    "\n",
    "# for deterministic results\n",
    "trainer._args.seed = SEED\n",
    "trainer.st_trainer.args.seed = SEED\n",
    "trainer.st_trainer.args.data_seed = SEED\n",
    "trainer.st_trainer.args.full_determinism = True"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "87c06bd9",
   "metadata": {},
   "source": [
    "### Fine-tune"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ad7b804",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "***** Running training *****\n",
      "  Num unique pairs = 33950\n",
      "  Batch size = 32\n",
      "  Num epochs = 0\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1e9aad7b54d349358c30290a10017c16",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'train_runtime': 0.0053, 'train_samples_per_second': 0.0, 'train_steps_per_second': 0.0, 'train_loss': 0.0, 'epoch': 0}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5d3154141ad649d49d8e776f93b9061a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch:   0%|          | 0/15 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "813206c049e0428ebdfd475d6fc24c79",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Iteration:   0%|          | 0/56 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the current cell or a previous cell. \n",
      "\u001b[1;31mPlease review the code in the cell(s) to identify a possible cause of the failure. \n",
      "\u001b[1;31mClick <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "trainer.train()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1cf4519f",
   "metadata": {},
   "source": [
    "### Evaluate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8f56430",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "***** Running evaluation *****\n"
     ]
    }
   ],
   "source": [
    "metrics = trainer.evaluate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8a6c260",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>f1</th>\n",
       "      <th>precision</th>\n",
       "      <th>recall</th>\n",
       "      <th>support</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>macro</th>\n",
       "      <td>0.903006</td>\n",
       "      <td>0.957418</td>\n",
       "      <td>0.859259</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>universal</th>\n",
       "      <td>0.888889</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.800000</td>\n",
       "      <td>15.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>economic</th>\n",
       "      <td>0.927273</td>\n",
       "      <td>0.910714</td>\n",
       "      <td>0.944444</td>\n",
       "      <td>54.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>non-economic</th>\n",
       "      <td>0.892857</td>\n",
       "      <td>0.961538</td>\n",
       "      <td>0.833333</td>\n",
       "      <td>60.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                    f1  precision    recall  support\n",
       "macro         0.903006   0.957418  0.859259      NaN\n",
       "universal     0.888889   1.000000  0.800000     15.0\n",
       "economic      0.927273   0.910714  0.944444     54.0\n",
       "non-economic  0.892857   0.961538  0.833333     60.0"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "res = pd.DataFrame(metrics, index=[0]).T.reset_index().rename(columns={'index': 'metric', 0: 'value'})\n",
    "res[['metric', 'category']] = res.metric.str.split('_', expand=True)\n",
    "res = res.pivot(index='category', columns='metric', values='value')\n",
    "# remove index names\n",
    "res.columns.name = None\n",
    "res.index.name = None\n",
    "res.loc[['macro']+features]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "299c71b1",
   "metadata": {},
   "source": [
    "## error analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1ea7622",
   "metadata": {},
   "outputs": [],
   "source": [
    "probs = trainer.model.predict_proba(dataset['test']['input'], as_numpy=True)\n",
    "preds = np.where(probs > 0.5, 1, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d0e295d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# sanity check: any universal and other attributes? (not allowed)\n",
    "idxs = np.where(np.logical_and(preds[:, 0]==1, preds[:, 1:].sum(axis=1)>0))[0]\n",
    "len(idxs)\n",
    "# okay!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0512fa5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_input(x):\n",
    "  # text, mention = x.split(tokenizer.sep_token)\n",
    "  # span = regex.search(regex.escape(mention), text).span()\n",
    "  return x.split(tokenizer.sep_token)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65c9b77c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>mention</th>\n",
       "      <th>attribute</th>\n",
       "      <th>label</th>\n",
       "      <th>pred</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Party for living people.</td>\n",
       "      <td>living people</td>\n",
       "      <td>universal</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>x Businesses should pay a normal share of thei...</td>\n",
       "      <td>society</td>\n",
       "      <td>universal</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Young people need places where they can develo...</td>\n",
       "      <td>groups</td>\n",
       "      <td>universal</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>In a continuously technologically improving so...</td>\n",
       "      <td>a continuously technologically improving society</td>\n",
       "      <td>economic</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>A society where wealth is not measured in cons...</td>\n",
       "      <td>A society where wealth is not measured in cons...</td>\n",
       "      <td>economic</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>x Businesses should pay a normal share of thei...</td>\n",
       "      <td>society</td>\n",
       "      <td>economic</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>The Greens propose to experiment with new ways...</td>\n",
       "      <td>those who are undergoing profound democratic r...</td>\n",
       "      <td>economic</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Children with a migrant background, children f...</td>\n",
       "      <td>children with a dependent or mentally ill parent</td>\n",
       "      <td>economic</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Elderly care and care should be of high qualit...</td>\n",
       "      <td>mentors</td>\n",
       "      <td>economic</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Young people who don't want education now - bu...</td>\n",
       "      <td>Young people who don't want education now - bu...</td>\n",
       "      <td>economic</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>We want to raise damages to individuals who ar...</td>\n",
       "      <td>individuals who are discriminated against by c...</td>\n",
       "      <td>economic</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>In 2010 alone, poor Bulgarians left more than ...</td>\n",
       "      <td>poor Bulgarians</td>\n",
       "      <td>non-economic</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>In a continuously technologically improving so...</td>\n",
       "      <td>a continuously technologically improving society</td>\n",
       "      <td>non-economic</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Many of the exotic self-employed are also a ma...</td>\n",
       "      <td>the exotic self-employed</td>\n",
       "      <td>non-economic</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>It is necessary to expand the lustration, to d...</td>\n",
       "      <td>secret collaborators</td>\n",
       "      <td>non-economic</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>It is from such sources that the truly signifi...</td>\n",
       "      <td>the socially disadvantaged</td>\n",
       "      <td>non-economic</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>A society where wealth is not measured in cons...</td>\n",
       "      <td>A society where wealth is not measured in cons...</td>\n",
       "      <td>non-economic</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>This is precisely why we need existential foun...</td>\n",
       "      <td>existential founders who want to realize their...</td>\n",
       "      <td>non-economic</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>It consists of scientists elected by their pee...</td>\n",
       "      <td>representatives of associations aimed at safeg...</td>\n",
       "      <td>non-economic</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>This includes low to medium income families wi...</td>\n",
       "      <td>low to medium income families with children</td>\n",
       "      <td>non-economic</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>This is a big task that remains before Sloveni...</td>\n",
       "      <td>the declared or living knowledge society</td>\n",
       "      <td>non-economic</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>Young people need places where they can develo...</td>\n",
       "      <td>groups</td>\n",
       "      <td>non-economic</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>We want to raise damages to individuals who ar...</td>\n",
       "      <td>individuals who are discriminated against by c...</td>\n",
       "      <td>non-economic</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                 text  \\\n",
       "0                            Party for living people.   \n",
       "1   x Businesses should pay a normal share of thei...   \n",
       "2   Young people need places where they can develo...   \n",
       "0   In a continuously technologically improving so...   \n",
       "1   A society where wealth is not measured in cons...   \n",
       "2   x Businesses should pay a normal share of thei...   \n",
       "3   The Greens propose to experiment with new ways...   \n",
       "4   Children with a migrant background, children f...   \n",
       "5   Elderly care and care should be of high qualit...   \n",
       "6   Young people who don't want education now - bu...   \n",
       "7   We want to raise damages to individuals who ar...   \n",
       "0   In 2010 alone, poor Bulgarians left more than ...   \n",
       "1   In a continuously technologically improving so...   \n",
       "2   Many of the exotic self-employed are also a ma...   \n",
       "3   It is necessary to expand the lustration, to d...   \n",
       "4   It is from such sources that the truly signifi...   \n",
       "5   A society where wealth is not measured in cons...   \n",
       "6   This is precisely why we need existential foun...   \n",
       "7   It consists of scientists elected by their pee...   \n",
       "8   This includes low to medium income families wi...   \n",
       "9   This is a big task that remains before Sloveni...   \n",
       "10  Young people need places where they can develo...   \n",
       "11  We want to raise damages to individuals who ar...   \n",
       "\n",
       "                                              mention     attribute  label  \\\n",
       "0                                       living people     universal      1   \n",
       "1                                             society     universal      1   \n",
       "2                                              groups     universal      1   \n",
       "0    a continuously technologically improving society      economic      0   \n",
       "1   A society where wealth is not measured in cons...      economic      0   \n",
       "2                                             society      economic      0   \n",
       "3   those who are undergoing profound democratic r...      economic      0   \n",
       "4    children with a dependent or mentally ill parent      economic      1   \n",
       "5                                             mentors      economic      1   \n",
       "6   Young people who don't want education now - bu...      economic      1   \n",
       "7   individuals who are discriminated against by c...      economic      0   \n",
       "0                                     poor Bulgarians  non-economic      1   \n",
       "1    a continuously technologically improving society  non-economic      1   \n",
       "2                            the exotic self-employed  non-economic      1   \n",
       "3                                secret collaborators  non-economic      1   \n",
       "4                          the socially disadvantaged  non-economic      0   \n",
       "5   A society where wealth is not measured in cons...  non-economic      1   \n",
       "6   existential founders who want to realize their...  non-economic      1   \n",
       "7   representatives of associations aimed at safeg...  non-economic      1   \n",
       "8         low to medium income families with children  non-economic      1   \n",
       "9            the declared or living knowledge society  non-economic      1   \n",
       "10                                             groups  non-economic      0   \n",
       "11  individuals who are discriminated against by c...  non-economic      1   \n",
       "\n",
       "    pred  \n",
       "0      0  \n",
       "1      0  \n",
       "2      0  \n",
       "0      1  \n",
       "1      1  \n",
       "2      1  \n",
       "3      1  \n",
       "4      0  \n",
       "5      0  \n",
       "6      0  \n",
       "7      1  \n",
       "0      0  \n",
       "1      0  \n",
       "2      0  \n",
       "3      0  \n",
       "4      1  \n",
       "5      0  \n",
       "6      0  \n",
       "7      0  \n",
       "8      0  \n",
       "9      0  \n",
       "10     1  \n",
       "11     0  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "errors_df = [] \n",
    "for attribute, attribute_id in label2id.items():\n",
    "    errors = preds != dataset['test']['labels']\n",
    "    idxs = np.where(errors[:, attribute_id])[0]\n",
    "\n",
    "    tmp = pd.DataFrame([parse_input(x) for x in dataset['test'].select(idxs)['input']], columns=['text', 'mention'])\n",
    "    tmp['attribute'] = attribute\n",
    "    tmp['label'] = np.array(dataset['test'].select(idxs)['labels'])[:, attribute_id]\n",
    "    tmp['pred'] = preds[idxs, attribute_id]\n",
    "    errors_df.append(tmp)\n",
    "\n",
    "errors_df = pd.concat(errors_df)\n",
    "errors_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61a60370",
   "metadata": {},
   "source": [
    "## Save the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a055f45",
   "metadata": {},
   "outputs": [],
   "source": [
    "import shutil\n",
    "shutil.rmtree(model_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12a80278",
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer.model.save_pretrained(model_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1e41913",
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer.model.to('cpu');\n",
    "del trainer"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "galtan_group_appeals",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
