{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "552ec552",
   "metadata": {},
   "source": [
    "# Social group mention attribute category and attributes multilabel text classification\n",
    "\n",
    "We have collected human annotations that categorize mentions of social groups in party manifestos into the following (hierarchical) scheme of attribute dimensions and attribute classes:\n",
    "\n",
    "- economic attributes\n",
    "    - class membership\n",
    "    - ecology of group\n",
    "    - education level\n",
    "    - employment status\n",
    "    - income/wealth/economic status\n",
    "    - occupation/profession\n",
    "    - other\n",
    "- non-economic attributes:\n",
    "   - age\n",
    "   - crime\n",
    "   - ethnicity\n",
    "   - family\n",
    "   - gender/sexuality\n",
    "   - health\n",
    "   - nationality\n",
    "   - other\n",
    "   - place/location\n",
    "   - religion\n",
    "   - shared values/mentalities\n",
    "- universal\n",
    "\n",
    "In this notebook, we fine-tune a pre-trained sentence transformer model for multilabel classifiers using the `setfit` library to categorize into which attribute dimensions social group mentions belong."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3af7f258-5aaf-47c2-b81e-2f10fc349812",
   "metadata": {},
   "source": [
    "notebook based on https://github.com/huggingface/setfit/blob/main/notebooks/text-classification_multilabel.ipynb\n",
    "\n",
    "See also:\n",
    "\n",
    "- https://huggingface.co/docs/setfit/en/how_to/multilabel\n",
    "- https://github.com/huggingface/setfit/issues/413#issuecomment-1697751329"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c5604f73-f395-42cb-8082-9974a87ef9e9",
   "metadata": {},
   "source": [
    "## Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "50cfb2ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('../../code/mention-classification')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "70a859ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import regex\n",
    "\n",
    "import torch\n",
    "import datasets\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from utils.setfit import get_class_weights, model_init, TrainerForSpanClassification\n",
    "\n",
    "from transformers import AutoTokenizer, set_seed\n",
    "from setfit import TrainingArguments, Trainer\n",
    "\n",
    "from utils.metrics import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "101e20b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "SEED = 42\n",
    "set_seed(SEED)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "1c003a63",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_path = '../../models'\n",
    "base_model = os.path.join(model_path, 'paraphrase-mpnet-base-v2-social-group-mention-attributes-embedding')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e756be8-3b60-4c86-aa1b-7ef78289b8e2",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Preparing the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "0095eab9",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_path = '../../data/annotations/group_mention_categorization'\n",
    "fp = os.path.join(data_path, 'consolidated_annotations.tsv')\n",
    "df = pd.read_csv(fp, sep='\\t')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29159833",
   "metadata": {},
   "source": [
    "## Universal/econ/non-econ as three-way multilabel problem"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0697edf",
   "metadata": {},
   "source": [
    "### Prepare the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "44b1d72c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# stack by category\n",
    "tmp = pd.concat([\n",
    "    df[df.q_id == 'universal_attributes'].drop(columns=['category']),\n",
    "    df[df.q_id == 'economic_attributes'].groupby(['mention_id', 'text', 'mention', 'q_id']).agg({'label': lambda x: 'Yes' if (x=='Yes').any() else 'No'}).reset_index(),\n",
    "    df[df.q_id == 'non-economic_attributes'].groupby(['mention_id', 'text', 'mention', 'q_id']).agg({'label': lambda x: 'Yes' if (x=='Yes').any() else 'No'}).reset_index()\n",
    "])\n",
    "tmp.reset_index(drop=True, inplace=True)\n",
    "\n",
    "# get dimensions\n",
    "tmp.q_id = tmp.q_id.str.removesuffix('_attributes')\n",
    "features = tmp.q_id.unique().tolist()\n",
    "\n",
    "# reshape to wide format\n",
    "tmp = tmp.pivot(index=['mention_id', 'text', 'mention'], columns='q_id', values='label').reset_index()\n",
    "tmp = tmp.rename_axis(None, axis=1)\n",
    "\n",
    "# keep only fully gold-labeled examples\n",
    "tmp = tmp[tmp[features].isna().sum(axis=1) == 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "602401ce",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "universal  economic  non-economic\n",
       "No         No        Yes             192\n",
       "           Yes       No              144\n",
       "                     Yes              56\n",
       "Yes        No        No               55\n",
       "No         No        No                2\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tmp[features].value_counts(dropna=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "c7eb3316",
   "metadata": {},
   "outputs": [],
   "source": [
    "tmp = tmp[~(tmp[features]=='No').all(axis=1)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "abe59829",
   "metadata": {},
   "outputs": [],
   "source": [
    "label2id = {'No': 0, 'Yes': 1}\n",
    "id2label = {0: 'No', 1: 'Yes'}\n",
    "tmp.loc[:,features] = tmp.loc[:,features].apply(lambda x: x.map(label2id))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "9490dab8",
   "metadata": {},
   "outputs": [],
   "source": [
    "tmp['labels'] = tmp.loc[:,features].apply(list, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "25c7de5d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "universal       0.123043\n",
       "economic        0.447427\n",
       "non-economic     0.55481\n",
       "dtype: object"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tmp[features].mean(axis=0)\n",
    "# strong label class imbalance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "7faca004",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained(base_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "69912139",
   "metadata": {},
   "outputs": [],
   "source": [
    "# using concat strategy\n",
    "tmp['input'] = tmp.text + tokenizer.sep_token + tmp.mention \n",
    "max_length_ = max(tokenizer(tmp.input.to_list(), truncation=False, padding=False, return_length=True).length)\n",
    "cols = ['input', 'labels']\n",
    "cols_mapping = {\"input\": \"text\", \"labels\": \"label\"}\n",
    "\n",
    "# # using span embedding strategy\n",
    "# tmp['span'] = tmp.apply(lambda x: regex.search(regex.escape(x.mention), x.text).span(), axis=1)\n",
    "# max_length_ = max(tokenizer(tmp.text.to_list(), truncation=False, padding=False, return_length=True).length)\n",
    "# cols = ['text', 'span', 'labels']\n",
    "# cols_mapping = {'text': 'text', 'span': 'span', 'labels': 'label'}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4936057f",
   "metadata": {},
   "source": [
    "### split the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "0b53c639",
   "metadata": {},
   "outputs": [],
   "source": [
    "trn, tst = train_test_split(range(len(tmp)), test_size=0.25, random_state=SEED)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "c3227e78",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = datasets.DatasetDict({\n",
    "    'train': datasets.Dataset.from_pandas(tmp.iloc[trn][cols], preserve_index=False),\n",
    "    'test': datasets.Dataset.from_pandas(tmp.iloc[tst][cols], preserve_index=False)\n",
    "})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e1702b55",
   "metadata": {},
   "source": [
    "### Prepare fine-tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "130f6664",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.67261321, 0.18427759, 0.14310919])"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "feats = tmp.iloc[trn][features].to_numpy()\n",
    "class_weights = get_class_weights(feats, multitarget=True)\n",
    "class_weights = class_weights.astype(float)\n",
    "class_weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "c2242313",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{0: 'universal', 1: 'economic', 2: 'non-economic'}"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "id2label = {i: l for i, l in enumerate(features)}\n",
    "label2id = {l: i for i, l in enumerate(features)}\n",
    "id2label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "f60340a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_id = 'social-group-mention-attribute-dimension-classifier'\n",
    "model_dir = os.path.join(model_path, model_id)\n",
    "\n",
    "training_args = TrainingArguments(\n",
    "    output_dir=model_dir,\n",
    "    batch_size=(32, 4),\n",
    "    max_length=max_length_,\n",
    "    num_epochs=(0, 15),\n",
    "    max_steps=-1,\n",
    "    end_to_end=True,\n",
    "    # loss=CosineSimilarityLoss,\n",
    "    # samples_per_label=2,\n",
    "    # use_amp=True,\n",
    "    report_to='none',\n",
    "    seed=SEED\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "9f800dc2",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Applying column mapping to the training dataset\n",
      "Applying column mapping to the evaluation dataset\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "Map: 100%|██████████| 335/335 [00:00<00:00, 26033.72 examples/s]\n"
     ]
    }
   ],
   "source": [
    "from utils.metrics import compute_metrics_multilabel\n",
    "\n",
    "# trainer = TrainerForSpanClassification(\n",
    "trainer = Trainer(\n",
    "    model_init=lambda: model_init(\n",
    "        model_name=base_model,\n",
    "        id2label=id2label,\n",
    "        multitarget_strategy='one-vs-rest',\n",
    "        class_weights=class_weights,\n",
    "        use_span_embedding=False,#True,\n",
    "        device='mps'\n",
    "    ),\n",
    "    metric=lambda p, t: compute_metrics_multilabel(p, t, id2label),\n",
    "    args=training_args,\n",
    "    train_dataset=dataset['train'],\n",
    "    eval_dataset=dataset['test'],\n",
    "    column_mapping=cols_mapping\n",
    ")\n",
    "\n",
    "# for deterministic results\n",
    "trainer._args.seed = SEED\n",
    "trainer.st_trainer.args.seed = SEED\n",
    "trainer.st_trainer.args.data_seed = SEED\n",
    "trainer.st_trainer.args.full_determinism = True"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "72e49ed2",
   "metadata": {},
   "source": [
    "### Fine-tune"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "3a169b14",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "***** Running training *****\n",
      "  Num unique pairs = 75454\n",
      "  Batch size = 32\n",
      "  Num epochs = 0\n",
      "0it [00:00, ?it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'train_runtime': 0.0021, 'train_samples_per_second': 0.0, 'train_steps_per_second': 0.0, 'train_loss': 0.0, 'epoch': 0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch: 100%|██████████| 15/15 [05:24<00:00, 21.61s/it]\n"
     ]
    }
   ],
   "source": [
    "trainer.train()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f903ff2e",
   "metadata": {},
   "source": [
    "### Evaluate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "661f37b5",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "***** Running evaluation *****\n"
     ]
    }
   ],
   "source": [
    "metrics = trainer.evaluate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "c839e9fe",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>f1</th>\n",
       "      <th>precision</th>\n",
       "      <th>recall</th>\n",
       "      <th>support</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>macro</th>\n",
       "      <td>0.903006</td>\n",
       "      <td>0.957418</td>\n",
       "      <td>0.859259</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>universal</th>\n",
       "      <td>0.888889</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.800000</td>\n",
       "      <td>15.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>economic</th>\n",
       "      <td>0.927273</td>\n",
       "      <td>0.910714</td>\n",
       "      <td>0.944444</td>\n",
       "      <td>54.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>non-economic</th>\n",
       "      <td>0.892857</td>\n",
       "      <td>0.961538</td>\n",
       "      <td>0.833333</td>\n",
       "      <td>60.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                    f1  precision    recall  support\n",
       "macro         0.903006   0.957418  0.859259      NaN\n",
       "universal     0.888889   1.000000  0.800000     15.0\n",
       "economic      0.927273   0.910714  0.944444     54.0\n",
       "non-economic  0.892857   0.961538  0.833333     60.0"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "res = pd.DataFrame(metrics, index=[0]).T.reset_index().rename(columns={'index': 'metric', 0: 'value'})\n",
    "res[['metric', 'category']] = res.metric.str.split('_', expand=True)\n",
    "res = res.pivot(index='category', columns='metric', values='value')\n",
    "# remove index names\n",
    "res.columns.name = None\n",
    "res.index.name = None\n",
    "res.loc[['macro']+features]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e307ede4",
   "metadata": {},
   "source": [
    "## error analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "7ab4766c",
   "metadata": {},
   "outputs": [],
   "source": [
    "probs = trainer.model.predict_proba(dataset['test']['input'], as_numpy=True)\n",
    "preds = np.where(probs > 0.5, 1, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "19bc5470",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# sanity check: any universal and other attributes? (not allowed)\n",
    "idxs = np.where(np.logical_and(preds[:, 0]==1, preds[:, 1:].sum(axis=1)>0))[0]\n",
    "len(idxs)\n",
    "# okay!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "e23a4b9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_input(x):\n",
    "  # text, mention = x.split(tokenizer.sep_token)\n",
    "  # span = regex.search(regex.escape(mention), text).span()\n",
    "  return x.split(tokenizer.sep_token)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "cb4034af",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>mention</th>\n",
       "      <th>attribute</th>\n",
       "      <th>label</th>\n",
       "      <th>pred</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Party for living people.</td>\n",
       "      <td>living people</td>\n",
       "      <td>universal</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>x Businesses should pay a normal share of thei...</td>\n",
       "      <td>society</td>\n",
       "      <td>universal</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Young people need places where they can develo...</td>\n",
       "      <td>groups</td>\n",
       "      <td>universal</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>In a continuously technologically improving so...</td>\n",
       "      <td>a continuously technologically improving society</td>\n",
       "      <td>economic</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>A society where wealth is not measured in cons...</td>\n",
       "      <td>A society where wealth is not measured in cons...</td>\n",
       "      <td>economic</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>x Businesses should pay a normal share of thei...</td>\n",
       "      <td>society</td>\n",
       "      <td>economic</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>The Greens propose to experiment with new ways...</td>\n",
       "      <td>those who are undergoing profound democratic r...</td>\n",
       "      <td>economic</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Children with a migrant background, children f...</td>\n",
       "      <td>children with a dependent or mentally ill parent</td>\n",
       "      <td>economic</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Elderly care and care should be of high qualit...</td>\n",
       "      <td>mentors</td>\n",
       "      <td>economic</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Young people who don't want education now - bu...</td>\n",
       "      <td>Young people who don't want education now - bu...</td>\n",
       "      <td>economic</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>We want to raise damages to individuals who ar...</td>\n",
       "      <td>individuals who are discriminated against by c...</td>\n",
       "      <td>economic</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>In 2010 alone, poor Bulgarians left more than ...</td>\n",
       "      <td>poor Bulgarians</td>\n",
       "      <td>non-economic</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>In a continuously technologically improving so...</td>\n",
       "      <td>a continuously technologically improving society</td>\n",
       "      <td>non-economic</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Many of the exotic self-employed are also a ma...</td>\n",
       "      <td>the exotic self-employed</td>\n",
       "      <td>non-economic</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>It is necessary to expand the lustration, to d...</td>\n",
       "      <td>secret collaborators</td>\n",
       "      <td>non-economic</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>It is from such sources that the truly signifi...</td>\n",
       "      <td>the socially disadvantaged</td>\n",
       "      <td>non-economic</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>A society where wealth is not measured in cons...</td>\n",
       "      <td>A society where wealth is not measured in cons...</td>\n",
       "      <td>non-economic</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>This is precisely why we need existential foun...</td>\n",
       "      <td>existential founders who want to realize their...</td>\n",
       "      <td>non-economic</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>It consists of scientists elected by their pee...</td>\n",
       "      <td>representatives of associations aimed at safeg...</td>\n",
       "      <td>non-economic</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>This includes low to medium income families wi...</td>\n",
       "      <td>low to medium income families with children</td>\n",
       "      <td>non-economic</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>This is a big task that remains before Sloveni...</td>\n",
       "      <td>the declared or living knowledge society</td>\n",
       "      <td>non-economic</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>Young people need places where they can develo...</td>\n",
       "      <td>groups</td>\n",
       "      <td>non-economic</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>We want to raise damages to individuals who ar...</td>\n",
       "      <td>individuals who are discriminated against by c...</td>\n",
       "      <td>non-economic</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                 text  \\\n",
       "0                            Party for living people.   \n",
       "1   x Businesses should pay a normal share of thei...   \n",
       "2   Young people need places where they can develo...   \n",
       "0   In a continuously technologically improving so...   \n",
       "1   A society where wealth is not measured in cons...   \n",
       "2   x Businesses should pay a normal share of thei...   \n",
       "3   The Greens propose to experiment with new ways...   \n",
       "4   Children with a migrant background, children f...   \n",
       "5   Elderly care and care should be of high qualit...   \n",
       "6   Young people who don't want education now - bu...   \n",
       "7   We want to raise damages to individuals who ar...   \n",
       "0   In 2010 alone, poor Bulgarians left more than ...   \n",
       "1   In a continuously technologically improving so...   \n",
       "2   Many of the exotic self-employed are also a ma...   \n",
       "3   It is necessary to expand the lustration, to d...   \n",
       "4   It is from such sources that the truly signifi...   \n",
       "5   A society where wealth is not measured in cons...   \n",
       "6   This is precisely why we need existential foun...   \n",
       "7   It consists of scientists elected by their pee...   \n",
       "8   This includes low to medium income families wi...   \n",
       "9   This is a big task that remains before Sloveni...   \n",
       "10  Young people need places where they can develo...   \n",
       "11  We want to raise damages to individuals who ar...   \n",
       "\n",
       "                                              mention     attribute  label  \\\n",
       "0                                       living people     universal      1   \n",
       "1                                             society     universal      1   \n",
       "2                                              groups     universal      1   \n",
       "0    a continuously technologically improving society      economic      0   \n",
       "1   A society where wealth is not measured in cons...      economic      0   \n",
       "2                                             society      economic      0   \n",
       "3   those who are undergoing profound democratic r...      economic      0   \n",
       "4    children with a dependent or mentally ill parent      economic      1   \n",
       "5                                             mentors      economic      1   \n",
       "6   Young people who don't want education now - bu...      economic      1   \n",
       "7   individuals who are discriminated against by c...      economic      0   \n",
       "0                                     poor Bulgarians  non-economic      1   \n",
       "1    a continuously technologically improving society  non-economic      1   \n",
       "2                            the exotic self-employed  non-economic      1   \n",
       "3                                secret collaborators  non-economic      1   \n",
       "4                          the socially disadvantaged  non-economic      0   \n",
       "5   A society where wealth is not measured in cons...  non-economic      1   \n",
       "6   existential founders who want to realize their...  non-economic      1   \n",
       "7   representatives of associations aimed at safeg...  non-economic      1   \n",
       "8         low to medium income families with children  non-economic      1   \n",
       "9            the declared or living knowledge society  non-economic      1   \n",
       "10                                             groups  non-economic      0   \n",
       "11  individuals who are discriminated against by c...  non-economic      1   \n",
       "\n",
       "    pred  \n",
       "0      0  \n",
       "1      0  \n",
       "2      0  \n",
       "0      1  \n",
       "1      1  \n",
       "2      1  \n",
       "3      1  \n",
       "4      0  \n",
       "5      0  \n",
       "6      0  \n",
       "7      1  \n",
       "0      0  \n",
       "1      0  \n",
       "2      0  \n",
       "3      0  \n",
       "4      1  \n",
       "5      0  \n",
       "6      0  \n",
       "7      0  \n",
       "8      0  \n",
       "9      0  \n",
       "10     1  \n",
       "11     0  "
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "errors_df = [] \n",
    "for attribute, attribute_id in label2id.items():\n",
    "    errors = preds != dataset['test']['labels']\n",
    "    idxs = np.where(errors[:, attribute_id])[0]\n",
    "\n",
    "    tmp = pd.DataFrame([parse_input(x) for x in dataset['test'].select(idxs)['input']], columns=['text', 'mention'])\n",
    "    tmp['attribute'] = attribute\n",
    "    tmp['label'] = np.array(dataset['test'].select(idxs)['labels'])[:, attribute_id]\n",
    "    tmp['pred'] = preds[idxs, attribute_id]\n",
    "    errors_df.append(tmp)\n",
    "\n",
    "errors_df = pd.concat(errors_df)\n",
    "errors_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bfb8e4b8",
   "metadata": {},
   "source": [
    "## Save the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "9593ff4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import shutil\n",
    "shutil.rmtree(model_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "c40a8fa3",
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer.model.save_pretrained(model_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "ee71cba6",
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer.model.to('cpu');\n",
    "del trainer"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "76f7c0ea",
   "metadata": {},
   "source": [
    "## granular attribute classification problem"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "084e7ef5",
   "metadata": {},
   "source": [
    "### Prepare the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "10b91b7f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['economic: class membership',\n",
       " 'economic: ecology of group',\n",
       " 'economic: education level',\n",
       " 'economic: employment status',\n",
       " 'economic: income/wealth/economic status',\n",
       " 'economic: occupation/profession',\n",
       " 'economic: other',\n",
       " 'non-economic: age',\n",
       " 'non-economic: crime',\n",
       " 'non-economic: ethnicity',\n",
       " 'non-economic: family',\n",
       " 'non-economic: gender/sexuality',\n",
       " 'non-economic: health',\n",
       " 'non-economic: nationality',\n",
       " 'non-economic: other',\n",
       " 'non-economic: place/location',\n",
       " 'non-economic: religion',\n",
       " 'non-economic: shared values/mentalities',\n",
       " 'universal']"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tmp = df[df.q_id!='stance']\n",
    "\n",
    "tmp.loc[:, 'attribute_combination'] = tmp.attribute_combination.str.removesuffix(': ')\n",
    "\n",
    "features = tmp.attribute_combination.unique().tolist()\n",
    "\n",
    "# pivot labels for attribute_combination to columns using mention_id, text, and mention as id vars\n",
    "tmp = tmp.pivot(index=['mention_id', 'text', 'mention'], columns='attribute_combination', values='label').reset_index()\n",
    "tmp = tmp.rename_axis(None, axis=1)\n",
    "\n",
    "# keep only fully gold-labeled examples\n",
    "tmp = tmp[tmp[features].isna().sum(axis=1) == 0]\n",
    "tmp = tmp[~(tmp[features]=='No').all(axis=1)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "bbab1c59",
   "metadata": {},
   "outputs": [],
   "source": [
    "# one-hot encode labels\n",
    "label2id = {'No': 0, 'Yes': 1}\n",
    "id2label = {0: 'No', 1: 'Yes'}\n",
    "tmp.loc[:,features] = tmp.loc[:,features].apply(lambda x: x.map(label2id))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "1736cf8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "cnts = tmp[features].sum(axis=0)\n",
    "drop_these = cnts[cnts <= 4].index.tolist()\n",
    "for f in drop_these:\n",
    "    features.remove(f)\n",
    "\n",
    "tmp = tmp[['mention_id', 'text', 'mention'] + features]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "9384428c",
   "metadata": {},
   "outputs": [],
   "source": [
    "tmp.loc[:, 'labels'] = tmp.loc[:,features].apply(list, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "fea21c1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained(base_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "039afdf0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# using concat strategy\n",
    "tmp.loc[:, 'input'] = tmp.text + tokenizer.sep_token + tmp.mention \n",
    "max_length_ = max(tokenizer(tmp.input.to_list(), truncation=False, padding=False, return_length=True).length)\n",
    "cols = ['input', 'labels']\n",
    "cols_mapping = {\"input\": \"text\", \"labels\": \"label\"}\n",
    "\n",
    "# # using span embedding strategy\n",
    "# tmp['span'] = tmp.apply(lambda x: regex.search(regex.escape(x.mention), x.text).span(), axis=1)\n",
    "# max_length_ = max(tokenizer(tmp.text.to_list(), truncation=False, padding=False, return_length=True).length)\n",
    "# cols = ['text', 'span', 'labels']\n",
    "# cols_mapping = {'text': 'text', 'span': 'span', 'labels': 'label'}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d379f31",
   "metadata": {},
   "outputs": [],
   "source": [
    "tmp['signature'] = tmp[features].apply(lambda r: '; '.join([f for f in features if r[f]==1]), axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f3e61714",
   "metadata": {},
   "source": [
    "### split the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "6e20c554",
   "metadata": {},
   "outputs": [],
   "source": [
    "trn, tst = train_test_split(range(len(tmp)), test_size=0.25, random_state=SEED)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "edfe8ab1",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = datasets.DatasetDict({\n",
    "    'train': datasets.Dataset.from_pandas(tmp.iloc[trn][cols], preserve_index=False),\n",
    "    'test': datasets.Dataset.from_pandas(tmp.iloc[tst][cols], preserve_index=False)\n",
    "})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "67466189",
   "metadata": {},
   "source": [
    "### Prepare fine-tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "9e822ace",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.03643279, 0.05725153, 0.07286558, 0.02428853, 0.02504754,\n",
       "       0.01292776, 0.01512305, 0.08905793, 0.1335869 , 0.02671738,\n",
       "       0.10019017, 0.05343476, 0.01541387, 0.10019017, 0.20038035,\n",
       "       0.01705365, 0.02003803])"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "feats = tmp.iloc[trn][features].to_numpy()\n",
    "class_weights = get_class_weights(feats, multitarget=True)\n",
    "class_weights = class_weights.astype(float)\n",
    "class_weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "86657d58",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{0: 'economic: class membership',\n",
       " 1: 'economic: ecology of group',\n",
       " 2: 'economic: education level',\n",
       " 3: 'economic: employment status',\n",
       " 4: 'economic: income/wealth/economic status',\n",
       " 5: 'economic: occupation/profession',\n",
       " 6: 'non-economic: age',\n",
       " 7: 'non-economic: crime',\n",
       " 8: 'non-economic: ethnicity',\n",
       " 9: 'non-economic: family',\n",
       " 10: 'non-economic: gender/sexuality',\n",
       " 11: 'non-economic: health',\n",
       " 12: 'non-economic: nationality',\n",
       " 13: 'non-economic: place/location',\n",
       " 14: 'non-economic: religion',\n",
       " 15: 'non-economic: shared values/mentalities',\n",
       " 16: 'universal'}"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "id2label = {i: l for i, l in enumerate(features)}\n",
    "label2id = {l: i for i, l in enumerate(features)}\n",
    "id2label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "022ce1e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_id = 'social-group-mention-attributes-classifier'\n",
    "model_dir = os.path.join(model_path, model_id)\n",
    "\n",
    "training_args = TrainingArguments(\n",
    "    output_dir=model_dir,\n",
    "    batch_size=(32, 4),\n",
    "    max_length=max_length_,\n",
    "    num_epochs=(0, 15),\n",
    "    max_steps=-1,\n",
    "    end_to_end=True,\n",
    "    # loss=CosineSimilarityLoss,\n",
    "    # samples_per_label=2,\n",
    "    # use_amp=True,\n",
    "    report_to='none',\n",
    "    seed=SEED\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "a86ac80a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Applying column mapping to the training dataset\n",
      "Applying column mapping to the evaluation dataset\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "Map: 100%|██████████| 335/335 [00:00<00:00, 13817.95 examples/s]\n"
     ]
    }
   ],
   "source": [
    "from utils.metrics import compute_metrics_multilabel\n",
    "\n",
    "# trainer = TrainerForSpanClassification(\n",
    "trainer = Trainer(\n",
    "    model_init=lambda: model_init(\n",
    "        model_name=base_model,\n",
    "        id2label=id2label,\n",
    "        multitarget_strategy='one-vs-rest',\n",
    "        class_weights=class_weights,\n",
    "        use_span_embedding=False,#True,\n",
    "        device='mps'\n",
    "    ),\n",
    "    metric=lambda p, t: compute_metrics_multilabel(p, t, id2label),\n",
    "    args=training_args,\n",
    "    train_dataset=dataset['train'],\n",
    "    eval_dataset=dataset['test'],\n",
    "    column_mapping=cols_mapping\n",
    ")\n",
    "\n",
    "# for deterministic results\n",
    "trainer._args.seed = SEED\n",
    "trainer.st_trainer.args.seed = SEED\n",
    "trainer.st_trainer.args.data_seed = SEED\n",
    "trainer.st_trainer.args.full_determinism = True"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0769f96c",
   "metadata": {},
   "source": [
    "### Fine-tune"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "3bd9015d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "***** Running training *****\n",
      "  Num unique pairs = 105492\n",
      "  Batch size = 32\n",
      "  Num epochs = 0\n",
      "0it [00:00, ?it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'train_runtime': 0.0027, 'train_samples_per_second': 0.0, 'train_steps_per_second': 0.0, 'train_loss': 0.0, 'epoch': 0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch: 100%|██████████| 15/15 [09:48<00:00, 39.25s/it]\n"
     ]
    }
   ],
   "source": [
    "trainer.train()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c859a019",
   "metadata": {},
   "source": [
    "### Evaluate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "c601c2cc",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "***** Running evaluation *****\n"
     ]
    }
   ],
   "source": [
    "metrics = trainer.evaluate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "3f2c98dc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>f1</th>\n",
       "      <th>precision</th>\n",
       "      <th>recall</th>\n",
       "      <th>support</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>macro</th>\n",
       "      <td>0.093395</td>\n",
       "      <td>0.159804</td>\n",
       "      <td>0.079132</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>economic: class membership</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>6.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>economic: ecology of group</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>economic: education level</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>economic: employment status</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>13.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>economic: income/wealth/economic status</th>\n",
       "      <td>0.250000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.142857</td>\n",
       "      <td>14.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>economic: occupation/profession</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>23.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>non-economic: age</th>\n",
       "      <td>0.916667</td>\n",
       "      <td>0.916667</td>\n",
       "      <td>0.916667</td>\n",
       "      <td>12.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>non-economic: crime</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>6.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>non-economic: ethnicity</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>non-economic: family</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>9.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>non-economic: gender/sexuality</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>non-economic: health</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>6.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>non-economic: nationality</th>\n",
       "      <td>0.421053</td>\n",
       "      <td>0.800000</td>\n",
       "      <td>0.285714</td>\n",
       "      <td>14.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>non-economic: place/location</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>non-economic: religion</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>non-economic: shared values/mentalities</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>22.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>universal</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>15.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               f1  precision    recall  \\\n",
       "macro                                    0.093395   0.159804  0.079132   \n",
       "economic: class membership               0.000000   0.000000  0.000000   \n",
       "economic: ecology of group               0.000000   0.000000  0.000000   \n",
       "economic: education level                0.000000   0.000000  0.000000   \n",
       "economic: employment status              0.000000   0.000000  0.000000   \n",
       "economic: income/wealth/economic status  0.250000   1.000000  0.142857   \n",
       "economic: occupation/profession          0.000000   0.000000  0.000000   \n",
       "non-economic: age                        0.916667   0.916667  0.916667   \n",
       "non-economic: crime                      0.000000   0.000000  0.000000   \n",
       "non-economic: ethnicity                  0.000000   0.000000  0.000000   \n",
       "non-economic: family                     0.000000   0.000000  0.000000   \n",
       "non-economic: gender/sexuality           0.000000   0.000000  0.000000   \n",
       "non-economic: health                     0.000000   0.000000  0.000000   \n",
       "non-economic: nationality                0.421053   0.800000  0.285714   \n",
       "non-economic: place/location             0.000000   0.000000  0.000000   \n",
       "non-economic: religion                   0.000000   0.000000  0.000000   \n",
       "non-economic: shared values/mentalities  0.000000   0.000000  0.000000   \n",
       "universal                                0.000000   0.000000  0.000000   \n",
       "\n",
       "                                         support  \n",
       "macro                                        NaN  \n",
       "economic: class membership                   6.0  \n",
       "economic: ecology of group                   3.0  \n",
       "economic: education level                    3.0  \n",
       "economic: employment status                 13.0  \n",
       "economic: income/wealth/economic status     14.0  \n",
       "economic: occupation/profession             23.0  \n",
       "non-economic: age                           12.0  \n",
       "non-economic: crime                          6.0  \n",
       "non-economic: ethnicity                      1.0  \n",
       "non-economic: family                         9.0  \n",
       "non-economic: gender/sexuality               3.0  \n",
       "non-economic: health                         6.0  \n",
       "non-economic: nationality                   14.0  \n",
       "non-economic: place/location                 3.0  \n",
       "non-economic: religion                       1.0  \n",
       "non-economic: shared values/mentalities     22.0  \n",
       "universal                                   15.0  "
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "res = pd.DataFrame(metrics, index=[0]).T.reset_index().rename(columns={'index': 'metric', 0: 'value'})\n",
    "res[['metric', 'category']] = res.metric.str.split('_', expand=True)\n",
    "res = res.pivot(index='category', columns='metric', values='value')\n",
    "# remove index names\n",
    "res.columns.name = None\n",
    "res.index.name = None\n",
    "res.loc[['macro']+features]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "20d5494c",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_true = np.array(dataset['test']['labels'])\n",
    "y_pred = np.where(trainer.model.predict_proba(dataset['test']['input'], as_numpy=True) > 0.5, 1, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "66801dea",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'macro_granular': {'f1': 0.09339525283797728,\n",
       "  'precision': 0.15980392156862747,\n",
       "  'recall': 0.07913165266106442},\n",
       " 'economic: class membership': {'f1': 0.0,\n",
       "  'precision': 0.0,\n",
       "  'recall': 0.0,\n",
       "  'support': 6},\n",
       " 'economic: ecology of group': {'f1': 0.0,\n",
       "  'precision': 0.0,\n",
       "  'recall': 0.0,\n",
       "  'support': 3},\n",
       " 'economic: education level': {'f1': 0.0,\n",
       "  'precision': 0.0,\n",
       "  'recall': 0.0,\n",
       "  'support': 3},\n",
       " 'economic: employment status': {'f1': 0.0,\n",
       "  'precision': 0.0,\n",
       "  'recall': 0.0,\n",
       "  'support': 13},\n",
       " 'economic: income/wealth/economic status': {'f1': 0.25,\n",
       "  'precision': 1.0,\n",
       "  'recall': 0.14285714285714285,\n",
       "  'support': 14},\n",
       " 'economic: occupation/profession': {'f1': 0.0,\n",
       "  'precision': 0.0,\n",
       "  'recall': 0.0,\n",
       "  'support': 23},\n",
       " 'non-economic: age': {'f1': 0.9166666666666666,\n",
       "  'precision': 0.9166666666666666,\n",
       "  'recall': 0.9166666666666666,\n",
       "  'support': 12},\n",
       " 'non-economic: crime': {'f1': 0.0,\n",
       "  'precision': 0.0,\n",
       "  'recall': 0.0,\n",
       "  'support': 6},\n",
       " 'non-economic: ethnicity': {'f1': 0.0,\n",
       "  'precision': 0.0,\n",
       "  'recall': 0.0,\n",
       "  'support': 1},\n",
       " 'non-economic: family': {'f1': 0.0,\n",
       "  'precision': 0.0,\n",
       "  'recall': 0.0,\n",
       "  'support': 9},\n",
       " 'non-economic: gender/sexuality': {'f1': 0.0,\n",
       "  'precision': 0.0,\n",
       "  'recall': 0.0,\n",
       "  'support': 3},\n",
       " 'non-economic: health': {'f1': 0.0,\n",
       "  'precision': 0.0,\n",
       "  'recall': 0.0,\n",
       "  'support': 6},\n",
       " 'non-economic: nationality': {'f1': 0.42105263157894735,\n",
       "  'precision': 0.8,\n",
       "  'recall': 0.2857142857142857,\n",
       "  'support': 14},\n",
       " 'non-economic: place/location': {'f1': 0.0,\n",
       "  'precision': 0.0,\n",
       "  'recall': 0.0,\n",
       "  'support': 3},\n",
       " 'non-economic: religion': {'f1': 0.0,\n",
       "  'precision': 0.0,\n",
       "  'recall': 0.0,\n",
       "  'support': 1},\n",
       " 'non-economic: shared values/mentalities': {'f1': 0.0,\n",
       "  'precision': 0.0,\n",
       "  'recall': 0.0,\n",
       "  'support': 22},\n",
       " 'universal': {'f1': 0.0, 'precision': 0.0, 'recall': 0.0, 'support': 15}}"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#def compute_metrics_hierarchical_multilabel(y_pred, y_true, id2label, label_sep=': '):\n",
    "# y_true, y_pred = np.array(y_true), np.array(y_pred)\n",
    "# granularly\n",
    "granular_scores = {}\n",
    "for i, l in id2label.items():\n",
    "    p, r, f1, _ = precision_recall_fscore_support(y_true[:, i], y_pred[:, i], average='binary', zero_division=0.0)\n",
    "    granular_scores[l] = {'f1': f1, 'precision': p, 'recall': r, 'support': np.sum(y_true[:, i])}\n",
    "macros = {m: np.mean([d[m] for d in granular_scores.values()]) for m in ['f1', 'precision', 'recall']}\n",
    "granular_scores = {'macro_granular': macros} | granular_scores\n",
    "granular_scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca23a30b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# coarse\n",
    "granular2coarse = {i: l.split(label_sep)[0] for i, l in id2label.items()}\n",
    "coarse_cats = set(granular2coarse.values())\n",
    "y_true = [granular2coarse[i] for i in y_true]\n",
    "y_pred = [granular2coarse[i] for i in y_pred]\n",
    "p, r, f1, _ = precision_recall_fscore_support(y_true, y_pred, average=None, zero_division=0.0)\n",
    "coarse_scores = {}\n",
    "coarse_scores['macro_coarse'] = {'f1': np.mean(f1), 'precision': np.mean(p), 'recall': np.mean(r)}\n",
    "for i, l in coarse_cats:\n",
    "    coarse_scores[l] = {'f1': f1[i], 'precision': p[i], 'recall': r[i]}\n",
    "# flatten\n",
    "scores = coarse_scores | granular_scores\n",
    "scores = {f'{m}_{l}': v for l, d in scores.items() for m, v in d.items()}\n",
    "return scores"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "galtan_group_appeals",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
